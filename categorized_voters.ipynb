{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are trained on different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from hpsklearn import svc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"spacy-twitter\")\n",
    "\n",
    "def embed_dataset(dataset_text):\n",
    "    encoded = np.array([nlp(text).vector for text in dataset_text])\n",
    "    return encoded.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    dataset = pd.read_csv(f'datasets/{name}.csv')\n",
    "    dataset.rename(columns = {\"Unnamed: 0\":\"entry\"}, inplace=True)\n",
    "    dataset['e_text'] = embed_dataset(dataset['text'])\n",
    "    return dataset\n",
    "\n",
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models  \n",
    "\n",
    "SVMs trained on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import svc\n",
    "\n",
    "def optimize_model(model, X_train, y_train):\n",
    "    mod = HyperoptEstimator(classifier=model,\n",
    "                            preprocessing=[],\n",
    "                            max_evals=20,\n",
    "                            trial_timeout=120,\n",
    "                            verbose=False,\n",
    "                            n_jobs=-1)\n",
    "    mod.fit(X_train, y_train, random_state=42)\n",
    "    #print(mod.best_model())\n",
    "    return mod\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    print(\"Accuracy:\", float(\"{0:.2f}\".format(acc_mod*100)), \"%\")\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    print(\"F1:\", float(\"{0:.2f}\".format(f1_mod*100)), \"%\")\n",
    "    cm = confusion_matrix(y_test, pred_y)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "    disp.plot()\n",
    "    plt.show() \n",
    "\n",
    "def optimize_model_v2(search_space, objective, evals):\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn = objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=evals,\n",
    "        timeout=120,\n",
    "        trials=trials\n",
    "    )\n",
    "    set_params = space_eval(search_space, best_params)\n",
    "    score = trials.best_trial['result']['loss']\n",
    "    return set_params, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple datasets\n",
    "confidence_threshold = 0.2\n",
    "size_threshold = 50\n",
    "train_set = pheme\n",
    "\n",
    "def train_svms(dataset, confidence_threshold, size_threshold, train_set):\n",
    "    file_name = f\"{dataset}_cats/{dataset}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    trained_svms = {}\n",
    "    for key in data.keys():\n",
    "        svm_name = f\"svm_{key}\"\n",
    "        cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "        if len(cat_entries) < size_threshold:\n",
    "            print(f\"Skipped category: {key} due to low numbers\")\n",
    "            continue\n",
    "        all_in_cat = train_set.filter(axis=0, items=cat_entries)\n",
    "        X_train = all_in_cat.drop('target', axis=1)\n",
    "        y_train = all_in_cat['target']\n",
    "        #print(np.unique(all_in_cat[\"target\"]))\n",
    "        if (len(np.unique(all_in_cat[\"target\"])) <= 1):\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        try:\n",
    "            svm = optimize_model(svc(name=svm_name, random_state=42, probability=True), X_train_text, y_train)\n",
    "        except:\n",
    "            print(f\"error training {key} svm, skipping\")\n",
    "            continue\n",
    "        trained_svms[key] = svm\n",
    "        print(f\"Created SVM trained in category: {key}\")\n",
    "    return trained_svms\n",
    "\n",
    "#trained_svms = train_svms(\"pheme\", confidence_threshold, size_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_list = [svc(name=\"name\", random_state=42, probability=True), knn(), etc]\n",
    "import warnings\n",
    "\n",
    "def train_models(dataset, confidence_threshold, size_threshold, train_set, model_list):\n",
    "    file_name = f\"{dataset}_cats/{dataset}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    trained_models = {}\n",
    "    for key in data.keys():\n",
    "        cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "        if len(cat_entries) < size_threshold:\n",
    "            print(f\"Skipped category: {key} due to low numbers\")\n",
    "            continue\n",
    "        all_in_cat = train_set.filter(axis=0, items=cat_entries)\n",
    "        X = all_in_cat.drop('target', axis=1)\n",
    "        y = all_in_cat['target']\n",
    "        try:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
    "        except:\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "        if (len(np.unique(y)) <= 1):\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        X_val_text = np.array([text for text in X_val['e_text']])\n",
    "        trained_models[key] = {}\n",
    "        for model_name, search_space, mod in model_list:\n",
    "            def objective(search_space):\n",
    "                warnings.filterwarnings('ignore')\n",
    "                model = mod.set_params(**search_space)\n",
    "                model.fit(X_train_text, y_train)\n",
    "                y_pred = model.predict(X_val_text)\n",
    "                accuracy = accuracy_score(y_val, y_pred)\n",
    "                return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "            try:\n",
    "                params, score = optimize_model_v2(search_space, objective, 300)\n",
    "                mod.set_params(**params)\n",
    "                mod.fit(X_train_text, y_train)\n",
    "                #mod = m.best_model()['learner'].fit(X_train_text, y_train)\n",
    "                #mod = model.fit(X_train_text, y_train)\n",
    "            except:\n",
    "                print(f\"Error training {model_name} in category {key}, skipping\")\n",
    "                continue\n",
    "            trained_models[key][model_name] = mod\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Subjects 2754 2754\n",
      "News 362 362\n",
      "Arts & Entertainment 354 354\n",
      "People & Society 219 219\n",
      "Law & Government 388 388\n",
      "Online Communities 115 115\n",
      "Books & Literature 5 5\n",
      "Reference 14 14\n",
      "Jobs & Education 5 5\n",
      "Health 29 29\n",
      "Business & Industrial 3 3\n",
      "Autos & Vehicles 0 0\n",
      "Food & Drink 3 3\n",
      "Travel & Transportation 103 103\n",
      "Hobbies & Leisure 5 5\n",
      "Games 0 0\n",
      "Pets & Animals 2 2\n",
      "Sports 41 41\n",
      "Beauty & Fitness 1 1\n",
      "Science 0 0\n",
      "Computers & Electronics 4 4\n",
      "Shopping 2 2\n",
      "Internet & Telecom 1 1\n",
      "Adult 0 0\n",
      "Finance 0 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"pheme_cats/pheme_categories_organised.json\"\n",
    "f = open(file_name)\n",
    "data = json.load(f)\n",
    "\n",
    "confidence_threshold = 0.5\n",
    "for key in data.keys():\n",
    "    entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "    all_in_cat = pheme.filter(axis=0, items=entries)\n",
    "    t = 0\n",
    "    f=0\n",
    "    for e in all_in_cat[\"target\"]:\n",
    "        if e:\n",
    "            t += 1\n",
    "        else:\n",
    "            f += 1\n",
    "    print(key, len(entries), len(all_in_cat))\n",
    "    #print(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SVMS\n",
    "def predict_points(trained_svms, test_cats, test_data):\n",
    "    test_points = test_data\n",
    "    test_file_name = test_cats\n",
    "    f = open(test_file_name)\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    final_predictions = []\n",
    "    final_predictions2 = []\n",
    "    for i in tqdm(range(len(test_points))):\n",
    "        point = test_points.iloc[i]\n",
    "        point_text = np.array([text for text in point['e_text']])\n",
    "        topics = test_data[str(point[\"entry\"])]\n",
    "        topic_weights = {}\n",
    "        for topic in topics:\n",
    "            main_topic = topic.split(\"/\")[1]\n",
    "            if topics[topic] < confidence_threshold or main_topic not in trained_svms.keys():\n",
    "                continue\n",
    "            if main_topic in topic_weights:\n",
    "                topic_weights[main_topic] += topics[topic]\n",
    "            else:\n",
    "                topic_weights[main_topic] = topics[topic]\n",
    "        #print(topic_weights) \n",
    "        model_predictions = []\n",
    "        for topic in topic_weights:\n",
    "            model = trained_svms[topic]\n",
    "            pred = model.predict(point_text.reshape(1,-1))\n",
    "            model_predictions.append((pred[0], topic_weights[topic]))\n",
    "            #model_predictions.append((pred[0], 1))\n",
    "        #print(model_predictions)\n",
    "        true_mark = 0\n",
    "        false_mark = 0\n",
    "        for pred, score in model_predictions:    \n",
    "            if pred == True:\n",
    "                true_mark += score\n",
    "            else:\n",
    "                false_mark += score\n",
    "        #print(mark)\n",
    "        if (true_mark > false_mark):\n",
    "            final_predictions.append(True)\n",
    "        else:\n",
    "            final_predictions.append(False)\n",
    "        max = 0\n",
    "        final_pred = True\n",
    "        for pred, score in model_predictions:\n",
    "            if score > max:\n",
    "                final_pred = pred\n",
    "        final_predictions2.append(final_pred)\n",
    "    return final_predictions, final_predictions2\n",
    "             \n",
    "def check_score(test, pred):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE MODELS\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def hard_vote(model_predictions):\n",
    "    category_votes = []\n",
    "    for category in model_predictions.keys():\n",
    "        predictions = model_predictions[category]\n",
    "        vote = 0\n",
    "        for pred, model, weight in predictions:\n",
    "            if pred == True:\n",
    "                vote += 1\n",
    "            else:\n",
    "                vote -= 1\n",
    "            \"\"\"if pred[0][0] < pred[0][1]:\n",
    "                vote += 1\n",
    "            else: vote -= 1 \"\"\"\n",
    "        if vote > 0:\n",
    "            category_votes.append((category, True, weight))\n",
    "        else:\n",
    "            category_votes.append((category, False, weight))\n",
    "    score = 0\n",
    "    for category, vote, weight in category_votes:\n",
    "        if vote == True: score += weight\n",
    "        else: score -= weight\n",
    "    if score > 0: return True\n",
    "    else: return False\n",
    "\n",
    "def soft_vote(model_predictions):\n",
    "    category_votes = []\n",
    "    for category in model_predictions.keys():\n",
    "        predictions = model_predictions[category]\n",
    "        max_vote = [True, 0, \"\", 0]\n",
    "        for pred, model, weight in predictions:\n",
    "            false_weight = pred[0][0]\n",
    "            true_weight = pred[0][1]\n",
    "            if false_weight < true_weight:\n",
    "                vote = [True, true_weight, model, weight]\n",
    "            else:\n",
    "                vote = [False, false_weight, model, weight]\n",
    "            category_votes.append(vote)\n",
    "    score = 0\n",
    "    for pred, confidence, model, weight in category_votes:\n",
    "        vote_weight = (0.5*confidence + 1*weight)\n",
    "        if pred == True: score += vote_weight\n",
    "        else: score -= vote_weight\n",
    "    if score > 0: return True\n",
    "    else: return False\n",
    "\n",
    "def predict_points_mutiple_models(trained_models, test_cats, test_data):\n",
    "    test_points = test_data\n",
    "    test_file_name = test_cats\n",
    "    f = open(test_file_name)\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    final_predictions_hard = []\n",
    "    final_predictions_soft = []\n",
    "    for i in tqdm(range(len(test_points))):\n",
    "        point = test_points.iloc[i]\n",
    "        point_text = np.array([text for text in point['e_text']])\n",
    "        topics = test_data[str(point[\"entry\"])]\n",
    "        topic_weights = {}\n",
    "        for topic in topics:\n",
    "            main_topic = topic.split(\"/\")[1]\n",
    "            if topics[topic] < confidence_threshold or main_topic not in trained_models.keys():\n",
    "                continue\n",
    "            if main_topic in topic_weights:\n",
    "                topic_weights[main_topic] += topics[topic]\n",
    "            else:\n",
    "                topic_weights[main_topic] = topics[topic]\n",
    "        model_predictions = {}\n",
    "        for topic in topic_weights:\n",
    "            models = trained_models[topic]\n",
    "            model_predictions[topic] = []\n",
    "            #estimators = []\n",
    "            for model in models:\n",
    "                #estimators.append(model, models[model])\n",
    "                mod = models[model]\n",
    "                pred = mod.predict(point_text.reshape(1,-1))\n",
    "                model_predictions[topic].append((pred, model, topic_weights[topic]))\n",
    "            #clf = VotingClassifier(estimators, voting=\"hard\")\n",
    "        #vote\n",
    "        prediction_hard = hard_vote(model_predictions)\n",
    "        #prediction_soft = soft_vote(model_predictions)\n",
    "        final_predictions_hard.append(prediction_hard)\n",
    "        #final_predictions_soft.append(prediction_soft)\n",
    "    return final_predictions_hard, final_predictions_soft\n",
    "\n",
    "def check_score(test, pred):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    #cm = confusion_matrix(test, pred)\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "    #disp.plot()\n",
    "    #plt.show() \n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))   \n",
    "\n",
    "#a,b = predict_points_mutiple_models(models, \"pheme_categories.json\", X_val)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SVMS\n",
    "def get_results(train_dataset, confidence_threshold, size_threshold, train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    train_set = pd.concat([X_train, y_train], axis=1)\n",
    "    svms = train_svms(train_dataset, confidence_threshold, size_threshold, train_set)\n",
    "\n",
    "    results = []\n",
    "    train_cats = f\"{train_dataset}_categories.json\"\n",
    "    predictions1, predictions2 = predict_points(svms, train_cats, X_val)\n",
    "    results.append(check_score(predictions1, y_val))\n",
    "    \n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_cat_file = f\"{test_cat}_categories.json\"\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_target = test_set[\"target\"]\n",
    "        predictions1, predictions2 = predict_points(svms, test_cat_file, test_data)\n",
    "        results.append((test_name, check_score(predictions1, test_target)))\n",
    "    return results\n",
    "\n",
    "def run_tests(tests, confidence_threshold, size_threshold):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_results(train[1], confidence_threshold, size_threshold, train[0], t)))\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE MODELS\n",
    "def get_results_multi(train_dataset, confidence_threshold, size_threshold, train, tests, model_list): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    train_set = pd.concat([X_train, y_train], axis=1)\n",
    "    models = train_models(train_dataset, confidence_threshold, size_threshold, train_set, model_list)\n",
    "\n",
    "    results = []\n",
    "    train_cats = f\"{train_dataset}_categories.json\"\n",
    "    predictions_hard, predictions_soft = predict_points_mutiple_models(models, train_cats, X_val)\n",
    "    results.append((check_score(predictions_hard, y_val)))\n",
    "    \n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_cat_file = f\"{test_cat}_categories.json\"\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_target = test_set[\"target\"]\n",
    "        predictions_hard, predictions_soft = predict_points_mutiple_models(models, test_cat_file, test_data)\n",
    "        results.append((test_name, check_score(predictions_hard, test_target)))\n",
    "    return results, models\n",
    "\n",
    "def run_tests_multi(tests, confidence_threshold, size_threshold, model_list):\n",
    "    test_results = []\n",
    "    trained_models = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        results, models = get_results_multi(train[1], confidence_threshold, size_threshold, train[0], t, model_list)\n",
    "        test_results.append((train[2], results))\n",
    "        trained_models.append(models)\n",
    "    return test_results, trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import svc, logistic_regression, k_neighbors_classifier, random_forest_classifier, gaussian_nb, mlp_classifier, sgd_classifier\n",
    "sgd_loss = hp.choice(\"loss\", {'hinge', 'squared_error', 'epsilon_insensitive', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'log_loss'})\n",
    "\n",
    "model_list = [\n",
    "    (\"SVC\", svc(\"SVC\", random_state=42, probability=True)),\n",
    "    (\"KNN\", k_neighbors_classifier(\"knn\")),\n",
    "    (\"Logistic Regression\", logistic_regression(\"LR\", random_state=42, solver=\"saga\", penalty=hp.choice(\"penalty\", {None, \"l1\", \"l2\"}))),\n",
    "    (\"Random Forest\", random_forest_classifier(\"Random Forest\", random_state=42)),\n",
    "    (\"MLP\", mlp_classifier(\"MLP\", random_state=42)),\n",
    "    (\"Gaussian NB\", gaussian_nb(\"GNB\")),\n",
    "    (\"SGD\", sgd_classifier(\"SGD\", loss=sgd_loss, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM_search_space={  \n",
    "                'C': hp.lognormal('C', 0, 1),\n",
    "                'kernel':hp.choice('kernel', [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "                'coef0':hp.uniform('coef0', 0.0, 1.0),\n",
    "                'shrinking':hp.choice('shrinking', [True, False]),\n",
    "                'tol':hp.loguniform('tol', np.log(1e-5), np.log(1e-2)),\n",
    "                'degree':hp.choice('degree', [1, 2, 3, 4, 5]),\n",
    "                'gamma':hp.choice('gamma', [\"scale\", \"auto\"]),\n",
    "                }\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_search_space={\n",
    "                \"n_neighbors\":hp.choice('n_neighbors', np.arange(1, 16, dtype=int)),\n",
    "                \"algorithm\":hp.choice(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "                \"metric\": hp.choice(\"metric\", [\"cityblock\", \"l1\", \"l2\", \"minkowski\", \"euclidean\", \"manhattan\"]),\n",
    "                \"p\":hp.uniform(\"p\", 1, 5)\n",
    "                }\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "LR_search_space={\n",
    "                'C': hp.lognormal('C', 0, 1),\n",
    "                'penalty':hp.choice('p_saga',['elasticnet','l1','l2',None]),\n",
    "                'tol': hp.loguniform('tol',-13,-1),\n",
    "                'l1_ratio': hp.uniform('l1_ratio',0,1)\n",
    "                }\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_search_space={  'n_estimators':hp.randint('n_estimators',200,1000),\n",
    "                'max_depth': hp.randint('max_depth',10,200),                      \n",
    "                'min_samples_split':hp.uniform('min_samples_split',0,1),   \n",
    "                'min_samples_leaf':hp.randint('min_samples_leaf',1,10),            \n",
    "                'criterion':hp.choice('criterion',['gini','entropy']),               \n",
    "                'max_features':hp.choice('max_features',['sqrt', 'log2']) }\n",
    "\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_search_space={\n",
    "                'activation':hp.choice('activation', [\"identity\",\"logistic\",\"tanh\",\"relu\"]),\n",
    "                'solver':hp.choice('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "                'alpha':hp.uniform(\"alpha\", 1e-4, 0.01),\n",
    "                'learning_rate':hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "                'learning_rate_init':hp.uniform(\"learning_rate_init\", 1e-4, 0.1),\n",
    "                'power_t':hp.uniform('power_t', 0.1, 0.9),\n",
    "                'tol':hp.uniform('tol', 1e-4, 0.01),\n",
    "                'momentum':hp.uniform('momentum', 0.8, 1.0),\n",
    "                'early_stopping':hp.choice('early_stopping', [True, False]),\n",
    "                'beta_1':hp.uniform(\"beta_1\", 0.8, 1.0),\n",
    "                'beta_2':hp.uniform(\"beta_2\", 0.95, 1.0),\n",
    "                'epsilon':hp.uniform(\"epsilon\", 1e-9, 1e-5)\n",
    "                }\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_search_space={\n",
    "                'var_smoothing': 10**-9\n",
    "                }\n",
    "\n",
    "# SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD_search_space={\n",
    "                'loss':hp.choice('loss',[\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\", \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"]),\n",
    "                'penalty':hp.choice(\"penalty\", [\"l2\", \"l1\", \"elasticnet\", None]),\n",
    "                'alpha':hp.loguniform(\"alpha\", np.log(1e-6), np.log(1e-1)),\n",
    "                \"l1_ratio\":hp.loguniform(\"l1_ratio\", np.log(1e-7), np.log(1)),\n",
    "                \"tol\":hp.loguniform(\"tol\", np.log(1e-5), np.log(1e-2)),\n",
    "                'learning_rate':hp.choice(\"learning_rate\",  [\"optimal\", \"invscaling\", \"constant\", \"adaptive\"]),\n",
    "                'eta0':hp.loguniform(\"eta0\", np.log(1e-5), np.log(1e-1))\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_v2 = [\n",
    "    (\"SVM\", SVM_search_space, SVC(random_state=42)),\n",
    "    (\"KNN\", KNN_search_space, KNeighborsClassifier(n_jobs=-1)),\n",
    "    (\"Logistic Regression\", LR_search_space, LogisticRegression(solver=\"saga\", max_iter=1000, random_state=42, n_jobs=-1)),\n",
    "    (\"Random Forest\", RF_search_space, RandomForestClassifier()),\n",
    "    (\"MLP\", MLP_search_space, MLPClassifier()),\n",
    "    (\"Gaussian NB\", NB_search_space, GaussianNB()),\n",
    "    (\"SGD\", SGD_search_space, SGDClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")\n",
    "twitter15 = twitter.iloc[:1491]\n",
    "twitter16 = twitter.iloc[1491:]\n",
    "weibo = get_dataset(\"weibo\")\n",
    "weibo = weibo.drop([1933, 3564])\n",
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n",
    "tests2 = [[pheme, \"pheme\", \"PHEME\"], [twitter, \"twitter\", \"twitterfull\"], [weibo, \"weibo\", \"WEIBO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/300 [02:00<09:06,  2.22s/trial, best loss: -0.8220108695652174]\n",
      " 90%|█████████ | 270/300 [02:00<00:13,  2.25trial/s, best loss: -0.8084239130434783]\n",
      " 80%|███████▉  | 239/300 [02:01<00:30,  1.97trial/s, best loss: -0.7894021739130435]\n",
      "  8%|▊         | 23/300 [02:08<25:45,  5.58s/trial, best loss: -0.7758152173913043]\n",
      " 36%|███▌      | 108/300 [02:00<03:33,  1.11s/trial, best loss: -0.8328804347826086]\n",
      "100%|██████████| 300/300 [00:03<00:00, 84.37trial/s, best loss: -0.7459239130434783]\n",
      "100%|██████████| 300/300 [01:55<00:00,  2.59trial/s, best loss: -0.7948369565217391]\n",
      "100%|██████████| 300/300 [01:43<00:00,  2.89trial/s, best loss: -0.8540145985401459]\n",
      "100%|██████████| 300/300 [01:08<00:00,  4.35trial/s, best loss: -0.7858880778588808]\n",
      " 46%|████▌     | 138/300 [02:01<02:23,  1.13trial/s, best loss: -0.7907542579075426]\n",
      " 10%|▉         | 29/300 [02:04<19:27,  4.31s/trial, best loss: -0.8199513381995134]\n",
      " 44%|████▍     | 133/300 [02:00<02:31,  1.10trial/s, best loss: -0.8467153284671532]\n",
      "100%|██████████| 300/300 [00:01<00:00, 155.66trial/s, best loss: -0.7639902676399026]\n",
      "100%|██████████| 300/300 [01:55<00:00,  2.61trial/s, best loss: -0.7907542579075426]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.62trial/s, best loss: -0.9]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.76trial/s, best loss: -0.8470588235294118]\n",
      " 97%|█████████▋| 291/300 [02:00<00:03,  2.41trial/s, best loss: -0.8705882352941177]\n",
      " 20%|██        | 60/300 [02:01<08:04,  2.02s/trial, best loss: -0.8647058823529412]\n",
      "100%|██████████| 300/300 [01:07<00:00,  4.43trial/s, best loss: -0.9]\n",
      "100%|██████████| 300/300 [00:01<00:00, 205.79trial/s, best loss: -0.8117647058823529]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.48trial/s, best loss: -0.888235294117647]\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.17trial/s, best loss: -0.8933333333333333]\n",
      "100%|██████████| 300/300 [00:18<00:00, 15.95trial/s, best loss: -0.9066666666666666]\n",
      "100%|██████████| 300/300 [01:31<00:00,  3.27trial/s, best loss: -0.8933333333333333]\n",
      " 22%|██▏       | 67/300 [02:01<07:01,  1.81s/trial, best loss: -0.8666666666666667]\n",
      "100%|██████████| 300/300 [01:09<00:00,  4.30trial/s, best loss: -0.9066666666666666]\n",
      "100%|██████████| 300/300 [00:01<00:00, 252.44trial/s, best loss: -0.7933333333333333]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.58trial/s, best loss: -0.8933333333333333]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.27trial/s, best loss: -0.8207547169811321]\n",
      "100%|██████████| 300/300 [00:28<00:00, 10.58trial/s, best loss: -0.7877358490566038]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.69trial/s, best loss: -0.8066037735849056]\n",
      " 20%|██        | 60/300 [02:00<08:01,  2.01s/trial, best loss: -0.7783018867924528]\n",
      "100%|██████████| 300/300 [01:33<00:00,  3.21trial/s, best loss: -0.8018867924528302]\n",
      "100%|██████████| 300/300 [00:01<00:00, 210.80trial/s, best loss: -0.7169811320754716]\n",
      "100%|██████████| 300/300 [01:28<00:00,  3.38trial/s, best loss: -0.7830188679245284]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.76trial/s, best loss: -0.8777777777777778]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.93trial/s, best loss: -0.8777777777777778]\n",
      "100%|██████████| 300/300 [01:44<00:00,  2.87trial/s, best loss: -0.8722222222222222]\n",
      " 23%|██▎       | 68/300 [02:02<06:56,  1.80s/trial, best loss: -0.8444444444444444]\n",
      "100%|██████████| 300/300 [01:05<00:00,  4.58trial/s, best loss: -0.8833333333333333]\n",
      "100%|██████████| 300/300 [00:01<00:00, 228.32trial/s, best loss: -0.7611111111111111]\n",
      "100%|██████████| 300/300 [00:32<00:00,  9.21trial/s, best loss: -0.8722222222222222]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.60trial/s, best loss: -0.92]\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.63trial/s, best loss: -0.82]\n",
      "100%|██████████| 300/300 [01:33<00:00,  3.22trial/s, best loss: -0.88]\n",
      " 36%|███▋      | 109/300 [02:00<03:30,  1.10s/trial, best loss: -0.82]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.55trial/s, best loss: -0.92]\n",
      "100%|██████████| 300/300 [00:00<00:00, 301.49trial/s, best loss: -0.78]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.38trial/s, best loss: -0.9]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:54<00:00, 23.65it/s]\n",
      "100%|██████████| 2308/2308 [01:23<00:00, 27.81it/s]\n",
      "100%|██████████| 4662/4662 [01:36<00:00, 48.22it/s]\n",
      " 33%|███▎      | 1/3 [58:10<1:56:21, 3490.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:06<00:00, 46.64trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:12<00:00, 24.54trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.95trial/s, best loss: -0.8448275862068966]\n",
      " 39%|███▊      | 116/300 [02:00<03:10,  1.04s/trial, best loss: -0.7413793103448276]\n",
      "100%|██████████| 300/300 [00:42<00:00,  7.07trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:01<00:00, 297.97trial/s, best loss: -0.7413793103448276]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.36trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:07<00:00, 37.92trial/s, best loss: -0.8266666666666667]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.80trial/s, best loss: -0.8133333333333334]\n",
      " 80%|████████  | 240/300 [02:00<00:30,  2.00trial/s, best loss: -0.72]\n",
      " 31%|███       | 93/300 [02:01<04:29,  1.30s/trial, best loss: -0.8133333333333334]\n",
      "100%|██████████| 300/300 [00:37<00:00,  7.95trial/s, best loss: -0.8133333333333334]\n",
      "100%|██████████| 300/300 [00:01<00:00, 295.53trial/s, best loss: -0.68]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.41trial/s, best loss: -0.76]\n",
      "100%|██████████| 300/300 [00:07<00:00, 39.22trial/s, best loss: -0.7972972972972973]\n",
      "100%|██████████| 300/300 [00:10<00:00, 28.93trial/s, best loss: -0.7567567567567568]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.27trial/s, best loss: -0.7972972972972973]\n",
      " 34%|███▎      | 101/300 [02:00<03:56,  1.19s/trial, best loss: -0.7702702702702703]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.39trial/s, best loss: -0.7972972972972973]\n",
      "100%|██████████| 300/300 [00:01<00:00, 283.38trial/s, best loss: -0.7027027027027027]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.27trial/s, best loss: -0.7972972972972973]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.00trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:17<00:00, 17.48trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [01:38<00:00,  3.04trial/s, best loss: -0.8068965517241379]\n",
      " 18%|█▊        | 54/300 [02:00<09:08,  2.23s/trial, best loss: -0.7793103448275862]\n",
      "100%|██████████| 300/300 [00:57<00:00,  5.21trial/s, best loss: -0.8551724137931035]\n",
      "100%|██████████| 300/300 [00:01<00:00, 237.17trial/s, best loss: -0.6689655172413793]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.72trial/s, best loss: -0.8413793103448276]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      " 13%|█▎        | 40/300 [02:28<16:08,  3.72s/trial, best loss: -0.7857142857142857]  \n",
      "100%|██████████| 300/300 [00:19<00:00, 15.62trial/s, best loss: -0.8116883116883117]\n",
      " 60%|█████▉    | 179/300 [02:00<01:21,  1.48trial/s, best loss: -0.7532467532467533]\n",
      " 16%|█▌        | 47/300 [02:00<10:46,  2.56s/trial, best loss: -0.7467532467532467]\n",
      "100%|██████████| 300/300 [01:39<00:00,  3.03trial/s, best loss: -0.7987012987012987]\n",
      "100%|██████████| 300/300 [00:01<00:00, 246.27trial/s, best loss: -0.6883116883116883]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.37trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.36trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:08<00:00, 37.45trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:43<00:00,  6.96trial/s, best loss: -0.8222222222222222]\n",
      " 46%|████▌     | 138/300 [02:00<02:20,  1.15trial/s, best loss: -0.7333333333333333]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.76trial/s, best loss: -0.7555555555555555]\n",
      "100%|██████████| 300/300 [00:00<00:00, 300.34trial/s, best loss: -0.5333333333333333]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.70trial/s, best loss: -0.7777777777777778]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:11<00:00, 41.44it/s]\n",
      "100%|██████████| 6425/6425 [02:53<00:00, 36.93it/s]\n",
      "100%|██████████| 4662/4662 [00:54<00:00, 85.86it/s] \n",
      " 67%|██████▋   | 2/3 [1:34:31<45:19, 2719.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:12<00:00, 23.21trial/s, best loss: -0.8014705882352942]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.69trial/s, best loss: -0.7720588235294118]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.09trial/s, best loss: -0.7941176470588235]\n",
      " 22%|██▏       | 67/300 [02:01<07:02,  1.81s/trial, best loss: -0.8161764705882353]\n",
      "100%|██████████| 300/300 [01:48<00:00,  2.77trial/s, best loss: -0.8014705882352942]\n",
      "100%|██████████| 300/300 [00:01<00:00, 249.40trial/s, best loss: -0.6470588235294118]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.90trial/s, best loss: -0.8014705882352942]\n",
      "100%|██████████| 300/300 [00:09<00:00, 33.19trial/s, best loss: -0.872093023255814]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.94trial/s, best loss: -0.813953488372093]\n",
      " 93%|█████████▎| 280/300 [02:00<00:08,  2.32trial/s, best loss: -0.813953488372093]\n",
      " 32%|███▏      | 97/300 [02:00<04:12,  1.24s/trial, best loss: -0.813953488372093]\n",
      "100%|██████████| 300/300 [00:54<00:00,  5.49trial/s, best loss: -0.8953488372093024]\n",
      "100%|██████████| 300/300 [00:01<00:00, 287.48trial/s, best loss: -0.6395348837209303]\n",
      "100%|██████████| 300/300 [00:11<00:00, 25.92trial/s, best loss: -0.8372093023255814]\n",
      "Skipped category: Reference due to low numbers\n",
      "100%|██████████| 300/300 [00:04<00:00, 65.11trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:08<00:00, 37.46trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [01:13<00:00,  4.08trial/s, best loss: -0.8888888888888888]\n",
      " 38%|███▊      | 113/300 [02:00<03:18,  1.06s/trial, best loss: -0.8611111111111112]\n",
      "100%|██████████| 300/300 [00:50<00:00,  5.97trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:01<00:00, 279.54trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:08<00:00, 33.34trial/s, best loss: -0.9166666666666666]\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "100%|██████████| 300/300 [00:04<00:00, 60.95trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.81trial/s, best loss: -0.8055555555555556]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.65trial/s, best loss: -0.8888888888888888]\n",
      " 41%|████▏     | 124/300 [02:00<02:50,  1.03trial/s, best loss: -0.8055555555555556]\n",
      "100%|██████████| 300/300 [00:44<00:00,  6.69trial/s, best loss: -0.9444444444444444]\n",
      "100%|██████████| 300/300 [00:01<00:00, 208.53trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.94trial/s, best loss: -0.9166666666666666]\n",
      "Skipped category: Online Communities due to low numbers\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.09trial/s, best loss: -0.8924731182795699]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.72trial/s, best loss: -0.8387096774193549]\n",
      " 72%|███████▏  | 217/300 [02:00<00:45,  1.81trial/s, best loss: -0.8494623655913979]\n",
      " 24%|██▍       | 73/300 [02:01<06:18,  1.67s/trial, best loss: -0.9032258064516129]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.39trial/s, best loss: -0.8817204301075269]\n",
      "100%|██████████| 300/300 [00:01<00:00, 263.07trial/s, best loss: -0.7741935483870968]\n",
      "100%|██████████| 300/300 [00:39<00:00,  7.65trial/s, best loss: -0.8709677419354839]\n",
      "Skipped category: Science due to low numbers\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.36trial/s, best loss: -0.8623188405797102]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.98trial/s, best loss: -0.8405797101449275]\n",
      " 49%|████▉     | 148/300 [02:00<02:03,  1.23trial/s, best loss: -0.8478260869565217]\n",
      " 22%|██▏       | 65/300 [02:00<07:14,  1.85s/trial, best loss: -0.7971014492753623]\n",
      "100%|██████████| 300/300 [01:57<00:00,  2.55trial/s, best loss: -0.8913043478260869]\n",
      "100%|██████████| 300/300 [00:01<00:00, 222.90trial/s, best loss: -0.7608695652173914]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.65trial/s, best loss: -0.855072463768116]\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 300/300 [00:08<00:00, 37.13trial/s, best loss: -0.9]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.28trial/s, best loss: -0.8]\n",
      " 94%|█████████▍| 283/300 [02:00<00:07,  2.35trial/s, best loss: -0.8555555555555555]\n",
      " 27%|██▋       | 80/300 [02:00<05:30,  1.50s/trial, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [01:06<00:00,  4.52trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:01<00:00, 282.78trial/s, best loss: -0.7444444444444445]\n",
      "100%|██████████| 300/300 [00:17<00:00, 17.07trial/s, best loss: -0.8777777777777778]\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 933/933 [00:15<00:00, 58.84it/s]\n",
      "100%|██████████| 6425/6425 [03:50<00:00, 27.89it/s]\n",
      "100%|██████████| 2308/2308 [01:12<00:00, 31.97it/s]\n",
      "100%|██████████| 3/3 [2:18:06<00:00, 2762.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results1, models1 = run_tests_multi(tests2, 0.2, 200, model_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 277/300 [02:00<00:09,  2.31trial/s, best loss: -0.8119266055045872]\n",
      "100%|██████████| 300/300 [01:51<00:00,  2.70trial/s, best loss: -0.7706422018348624]\n",
      "100%|██████████| 300/300 [01:06<00:00,  4.51trial/s, best loss: -0.7729357798165137]\n",
      " 11%|█▏        | 34/300 [02:00<15:39,  3.53s/trial, best loss: -0.7935779816513762]\n",
      " 63%|██████▎   | 190/300 [02:00<01:09,  1.57trial/s, best loss: -0.7981651376146789]\n",
      "100%|██████████| 300/300 [00:01<00:00, 154.59trial/s, best loss: -0.7224770642201835]\n",
      "100%|██████████| 300/300 [01:50<00:00,  2.72trial/s, best loss: -0.7729357798165137]\n",
      "100%|██████████| 300/300 [00:05<00:00, 52.30trial/s, best loss: -0.8103448275862069]\n",
      "100%|██████████| 300/300 [00:08<00:00, 35.05trial/s, best loss: -0.7758620689655172]\n",
      "100%|██████████| 300/300 [00:38<00:00,  7.77trial/s, best loss: -0.8103448275862069]\n",
      " 42%|████▏     | 125/300 [02:01<02:50,  1.03trial/s, best loss: -0.7758620689655172]\n",
      "100%|██████████| 300/300 [00:50<00:00,  5.93trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [00:01<00:00, 267.46trial/s, best loss: -0.7758620689655172]\n",
      "100%|██████████| 300/300 [00:12<00:00, 24.04trial/s, best loss: -0.8448275862068966]\n",
      "100%|██████████| 300/300 [00:05<00:00, 58.12trial/s, best loss: -0.9298245614035088]\n",
      "100%|██████████| 300/300 [00:11<00:00, 25.47trial/s, best loss: -0.8947368421052632]\n",
      "100%|██████████| 300/300 [01:02<00:00,  4.80trial/s, best loss: -0.8947368421052632]\n",
      " 40%|████      | 120/300 [02:00<03:00,  1.00s/trial, best loss: -0.8947368421052632]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.31trial/s, best loss: -0.9298245614035088]\n",
      "100%|██████████| 300/300 [00:01<00:00, 273.84trial/s, best loss: -0.8771929824561403]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.26trial/s, best loss: -0.9298245614035088]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.73trial/s, best loss: -0.9714285714285714]\n",
      "100%|██████████| 300/300 [00:08<00:00, 35.37trial/s, best loss: -0.9714285714285714]\n",
      "100%|██████████| 300/300 [00:38<00:00,  7.76trial/s, best loss: -0.9714285714285714]\n",
      " 45%|████▌     | 135/300 [02:00<02:27,  1.12trial/s, best loss: -0.9714285714285714]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.35trial/s, best loss: -0.9714285714285714]\n",
      "100%|██████████| 300/300 [00:00<00:00, 306.95trial/s, best loss: -0.9714285714285714]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.69trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.53trial/s, best loss: -0.8484848484848485]\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.94trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.73trial/s, best loss: -0.8333333333333334]\n",
      " 31%|███▏      | 94/300 [02:00<04:23,  1.28s/trial, best loss: -0.7878787878787878]\n",
      "100%|██████████| 300/300 [00:39<00:00,  7.69trial/s, best loss: -0.8484848484848485]\n",
      "100%|██████████| 300/300 [00:00<00:00, 302.10trial/s, best loss: -0.7878787878787878]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.05trial/s, best loss: -0.8636363636363636]\n",
      "100%|██████████| 300/300 [00:03<00:00, 76.32trial/s, best loss: -0.9473684210526315]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.58trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.95trial/s, best loss: -0.9473684210526315]\n",
      " 56%|█████▌    | 167/300 [02:01<01:36,  1.38trial/s, best loss: -0.8947368421052632]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.97trial/s, best loss: -0.9473684210526315]\n",
      "100%|██████████| 300/300 [00:00<00:00, 317.93trial/s, best loss: -0.8421052631578947]\n",
      "100%|██████████| 300/300 [00:06<00:00, 43.67trial/s, best loss: -0.9473684210526315]\n",
      "Skipped category: Books & Literature due to class issues\n",
      "Skipped category: Reference due to class issues\n",
      "Skipped category: Jobs & Education due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.26trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 55.64trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.53trial/s, best loss: -1.0]\n",
      " 60%|██████    | 180/300 [02:00<01:20,  1.50trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:17<00:00, 17.11trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 327.80trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.80trial/s, best loss: -1.0]\n",
      "Skipped category: Business & Industrial due to class issues\n",
      "Skipped category: Autos & Vehicles due to class issues\n",
      "Skipped category: Food & Drink due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.31trial/s, best loss: -0.8823529411764706]\n",
      "100%|██████████| 300/300 [00:05<00:00, 51.18trial/s, best loss: -0.8235294117647058]\n",
      "100%|██████████| 300/300 [00:44<00:00,  6.71trial/s, best loss: -0.9411764705882353]\n",
      " 54%|█████▎    | 161/300 [02:00<01:44,  1.33trial/s, best loss: -0.8823529411764706]\n",
      "100%|██████████| 300/300 [00:31<00:00,  9.57trial/s, best loss: -0.9411764705882353]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.82trial/s, best loss: -0.8235294117647058]\n",
      "100%|██████████| 300/300 [00:08<00:00, 37.09trial/s, best loss: -0.9411764705882353]\n",
      "Skipped category: Hobbies & Leisure due to class issues\n",
      "Skipped category: Games due to class issues\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.40trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 55.96trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:17<00:00, 17.01trial/s, best loss: -0.875]\n",
      " 58%|█████▊    | 174/300 [02:00<01:27,  1.45trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.05trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 329.06trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.00trial/s, best loss: -1.0]\n",
      "Skipped category: Beauty & Fitness due to class issues\n",
      "Skipped category: Science due to class issues\n",
      "Skipped category: Computers & Electronics due to class issues\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Internet & Telecom due to class issues\n",
      "Skipped category: Adult due to class issues\n",
      "Skipped category: Finance due to class issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:41<00:00, 31.22it/s]\n",
      "100%|██████████| 2308/2308 [01:05<00:00, 35.21it/s]\n",
      "100%|██████████| 4662/4662 [01:11<00:00, 64.76it/s]\n",
      " 33%|███▎      | 1/3 [42:11<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:03<00:00, 76.24trial/s, best loss: -0.9629629629629629]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.67trial/s, best loss: -0.9259259259259259]\n",
      "100%|██████████| 300/300 [00:15<00:00, 18.90trial/s, best loss: -0.9259259259259259]\n",
      " 47%|████▋     | 140/300 [02:00<02:17,  1.16trial/s, best loss: -0.9629629629629629]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.31trial/s, best loss: -0.9629629629629629]\n",
      "100%|██████████| 300/300 [00:00<00:00, 316.71trial/s, best loss: -0.7407407407407407]\n",
      "100%|██████████| 300/300 [00:09<00:00, 32.84trial/s, best loss: -0.9629629629629629]\n",
      "100%|██████████| 300/300 [00:04<00:00, 69.83trial/s, best loss: -0.76]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.20trial/s, best loss: -0.84]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.87trial/s, best loss: -0.72]\n",
      " 49%|████▊     | 146/300 [02:01<02:07,  1.20trial/s, best loss: -0.76]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.12trial/s, best loss: -0.76]\n",
      "100%|██████████| 300/300 [00:00<00:00, 318.04trial/s, best loss: -0.68]\n",
      "100%|██████████| 300/300 [00:07<00:00, 40.77trial/s, best loss: -0.84]\n",
      "100%|██████████| 300/300 [00:03<00:00, 77.67trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.00trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.04trial/s, best loss: -0.8571428571428571]\n",
      " 53%|█████▎    | 160/300 [02:00<01:45,  1.33trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.02trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.89trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:07<00:00, 40.80trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:04<00:00, 63.85trial/s, best loss: -0.8604651162790697]\n",
      "100%|██████████| 300/300 [00:07<00:00, 42.54trial/s, best loss: -0.8837209302325582]\n",
      "100%|██████████| 300/300 [00:33<00:00,  9.06trial/s, best loss: -0.8837209302325582]\n",
      " 41%|████      | 123/300 [02:00<02:52,  1.02trial/s, best loss: -0.8372093023255814]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.72trial/s, best loss: -0.8604651162790697]\n",
      "100%|██████████| 300/300 [00:00<00:00, 303.54trial/s, best loss: -0.7674418604651163]\n",
      "100%|██████████| 300/300 [00:16<00:00, 18.39trial/s, best loss: -0.8837209302325582]\n",
      "100%|██████████| 300/300 [00:03<00:00, 76.90trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.47trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.09trial/s, best loss: -1.0]\n",
      " 54%|█████▍    | 162/300 [02:00<01:42,  1.35trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:27<00:00, 11.04trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 323.51trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:07<00:00, 39.69trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:09<00:00, 30.76trial/s, best loss: -0.8131868131868132]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.70trial/s, best loss: -0.7912087912087912]\n",
      "100%|██████████| 300/300 [00:53<00:00,  5.60trial/s, best loss: -0.7582417582417582]\n",
      " 28%|██▊       | 84/300 [02:01<05:12,  1.45s/trial, best loss: -0.7912087912087912]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.87trial/s, best loss: -0.7912087912087912]\n",
      "100%|██████████| 300/300 [00:01<00:00, 265.74trial/s, best loss: -0.7142857142857143]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.07trial/s, best loss: -0.7802197802197802]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.04trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:05<00:00, 51.20trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:13<00:00, 22.57trial/s, best loss: -0.8]\n",
      " 57%|█████▋    | 172/300 [02:00<01:29,  1.43trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.45trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 332.34trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.92trial/s, best loss: -0.8]\n",
      "Skipped category: Internet & Telecom due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.30trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 7\n",
      "\n",
      " 33%|███▎      | 1/3 [1:06:08<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<00:03, 90.21trial/s, best loss: -0.5]\n",
      "Error training KNN in category Computers & Electronics, skipping\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.03trial/s, best loss: -1.0]\n",
      " 60%|██████    | 180/300 [02:00<01:20,  1.49trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 33%|███▎      | 1/3 [1:08:19<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training MLP in category Computers & Electronics, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 341.15trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:04<00:00, 66.96trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.32trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 52.67trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:15<00:00, 18.93trial/s, best loss: -1.0]\n",
      " 55%|█████▌    | 166/300 [02:00<01:37,  1.38trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.82trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:01<00:00, 291.28trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.31trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.81trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:05<00:00, 58.02trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:13<00:00, 21.68trial/s, best loss: -0.6]\n",
      " 56%|█████▌    | 168/300 [02:00<01:34,  1.40trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.25trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.89trial/s, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.27trial/s, best loss: -0.8]\n",
      "Skipped category: Reference due to class issues\n",
      "Skipped category: Adult due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 86.46trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.91trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.34trial/s, best loss: -1.0]\n",
      " 62%|██████▏   | 185/300 [02:00<01:14,  1.54trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.93trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 308.62trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 53.31trial/s, best loss: -1.0]\n",
      "Skipped category: Books & Literature due to class issues\n",
      "Skipped category: Jobs & Education due to class issues\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.01trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:07<00:00, 42.61trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.54trial/s, best loss: -1.0]\n",
      " 56%|█████▌    | 167/300 [02:00<01:35,  1.39trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.12trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:01<00:00, 294.06trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.33trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 77.79trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 7\n",
      "\n",
      " 33%|███▎      | 1/3 [1:20:28<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<00:03, 92.19trial/s, best loss: -0.5]\n",
      "Error training KNN in category Beauty & Fitness, skipping\n",
      "100%|██████████| 300/300 [00:10<00:00, 28.67trial/s, best loss: -1.0]\n",
      " 61%|██████    | 182/300 [02:00<01:18,  1.51trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "\n",
      " 33%|███▎      | 1/3 [1:22:40<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:00<00:12, 24.00trial/s, best loss: -1.0]\n",
      "Error training MLP in category Beauty & Fitness, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 339.10trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:04<00:00, 68.33trial/s, best loss: -1.0]\n",
      "Skipped category: Autos & Vehicles due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.26trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 11, n_neighbors = 13\n",
      "\n",
      " 33%|███▎      | 1/3 [1:22:49<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<00:03, 96.54trial/s, best loss: -0.0]\n",
      "Error training KNN in category Science, skipping\n",
      "100%|██████████| 300/300 [00:12<00:00, 23.26trial/s, best loss: -0.6666666666666666]\n",
      " 61%|██████    | 183/300 [02:00<01:16,  1.52trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.60trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 317.12trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.93trial/s, best loss: -1.0]\n",
      "Skipped category: Finance due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.32trial/s, best loss: -0.3333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 11\n",
      "\n",
      " 33%|███▎      | 1/3 [1:25:33<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:00<00:02, 115.01trial/s, best loss: -0.3333333333333333]\n",
      "Error training KNN in category Travel & Transportation, skipping\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.62trial/s, best loss: -1.0]\n",
      " 57%|█████▋    | 170/300 [02:00<01:32,  1.41trial/s, best loss: -0.6666666666666666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 33%|███▎      | 1/3 [1:27:46<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training MLP in category Travel & Transportation, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 337.57trial/s, best loss: -0.3333333333333333]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.80trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 81.79trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 12\n",
      "\n",
      " 33%|███▎      | 1/3 [1:27:55<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<00:02, 101.29trial/s, best loss: -0.5]\n",
      "Error training KNN in category Hobbies & Leisure, skipping\n",
      "100%|██████████| 300/300 [00:09<00:00, 30.11trial/s, best loss: -0.5]\n",
      " 59%|█████▊    | 176/300 [02:00<01:24,  1.46trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 33%|███▎      | 1/3 [1:30:06<1:24:23, 2531.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:00<00:08, 36.19trial/s, best loss: -0.5]\n",
      "Error training MLP in category Hobbies & Leisure, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.68trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:04<00:00, 65.55trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 74.47trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.31trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.09trial/s, best loss: -0.9090909090909091]\n",
      " 56%|█████▋    | 169/300 [02:00<01:33,  1.41trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:17<00:00, 16.95trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 324.22trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.46trial/s, best loss: -1.0]\n",
      "Skipped category: Games due to class issues\n",
      "Skipped category: Home & Garden due to class issues\n",
      "Skipped category: Real Estate due to class issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:14<00:00, 30.86it/s]\n",
      "100%|██████████| 6425/6425 [03:35<00:00, 29.84it/s]\n",
      "100%|██████████| 4662/4662 [01:31<00:00, 51.04it/s]\n",
      " 67%|██████▋   | 2/3 [1:38:29<50:29, 3029.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 55.89trial/s, best loss: -0.8723404255319149]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.17trial/s, best loss: -0.851063829787234]\n",
      "100%|██████████| 300/300 [00:53<00:00,  5.62trial/s, best loss: -0.8297872340425532]\n",
      " 43%|████▎     | 129/300 [02:01<02:40,  1.06trial/s, best loss: -0.7446808510638298]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.29trial/s, best loss: -0.851063829787234]\n",
      "100%|██████████| 300/300 [00:00<00:00, 312.87trial/s, best loss: -0.5957446808510638]\n",
      "100%|██████████| 300/300 [00:11<00:00, 25.49trial/s, best loss: -0.8723404255319149]\n",
      "100%|██████████| 300/300 [00:04<00:00, 65.94trial/s, best loss: -0.9642857142857143]\n",
      "100%|██████████| 300/300 [00:07<00:00, 42.75trial/s, best loss: -0.9642857142857143]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.51trial/s, best loss: -0.9285714285714286]\n",
      " 41%|████▏     | 124/300 [02:00<02:50,  1.03trial/s, best loss: -0.8928571428571429]\n",
      "100%|██████████| 300/300 [00:28<00:00, 10.48trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:00<00:00, 311.66trial/s, best loss: -0.6428571428571429]\n",
      "100%|██████████| 300/300 [00:07<00:00, 37.64trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.02trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.72trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:12<00:00, 23.18trial/s, best loss: -0.7142857142857143]\n",
      " 58%|█████▊    | 173/300 [02:00<01:28,  1.44trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.10trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:01<00:00, 296.98trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:06<00:00, 43.15trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 67.39trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:07<00:00, 42.13trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:18<00:00, 15.80trial/s, best loss: -0.8333333333333334]\n",
      " 52%|█████▏    | 157/300 [02:00<01:49,  1.30trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.25trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.43trial/s, best loss: -0.7222222222222222]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.90trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.44trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 57.24trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.73trial/s, best loss: -1.0]\n",
      " 57%|█████▋    | 170/300 [02:00<01:31,  1.41trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.85trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.76trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.03trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 81.71trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 12\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:55:23<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:00<00:02, 98.88trial/s, best loss: -1.0]\n",
      "Error training KNN in category Games, skipping\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.32trial/s, best loss: -0.5]\n",
      " 60%|██████    | 180/300 [02:00<01:20,  1.49trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:57:34<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training MLP in category Games, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 342.15trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:04<00:00, 69.70trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.40trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:05<00:00, 50.27trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.84trial/s, best loss: -0.9090909090909091]\n",
      " 55%|█████▌    | 166/300 [02:00<01:36,  1.38trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.02trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:00<00:00, 330.28trial/s, best loss: -0.7272727272727273]\n",
      "100%|██████████| 300/300 [00:05<00:00, 52.02trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:03<00:00, 83.46trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.63trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.37trial/s, best loss: -0.9285714285714286]\n",
      " 52%|█████▏    | 156/300 [02:00<01:50,  1.30trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.21trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:00<00:00, 311.81trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:05<00:00, 51.97trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 78.77trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 11\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:04:03<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:00<00:04, 69.37trial/s, best loss: -1.0]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 300/300 [00:11<00:00, 27.06trial/s, best loss: -1.0]\n",
      " 60%|██████    | 180/300 [02:00<01:20,  1.49trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:06:15<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training MLP in category Online Communities, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 329.16trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.47trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 68.17trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:06<00:00, 43.48trial/s, best loss: -0.90625]\n",
      "100%|██████████| 300/300 [01:09<00:00,  4.30trial/s, best loss: -0.90625]\n",
      " 47%|████▋     | 141/300 [02:00<02:15,  1.17trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.13trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:00<00:00, 316.27trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:08<00:00, 34.78trial/s, best loss: -0.90625]\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.94trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 11, n_neighbors = 12\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:10:27<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:00<00:02, 126.95trial/s, best loss: -1.0]\n",
      "Error training KNN in category Science, skipping\n",
      "100%|██████████| 300/300 [00:12<00:00, 23.13trial/s, best loss: -1.0]\n",
      " 58%|█████▊    | 173/300 [02:00<01:28,  1.44trial/s, best loss: -0.6666666666666666]\n",
      "100%|██████████| 300/300 [00:28<00:00, 10.61trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 340.70trial/s, best loss: -0.6666666666666666]\n",
      "100%|██████████| 300/300 [00:04<00:00, 62.72trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:07<00:00, 40.83trial/s, best loss: -0.8860759493670886]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.74trial/s, best loss: -0.8734177215189873]\n",
      " 76%|███████▌  | 227/300 [02:00<00:38,  1.88trial/s, best loss: -0.8481012658227848]\n",
      " 28%|██▊       | 84/300 [02:01<05:11,  1.44s/trial, best loss: -0.8734177215189873]\n",
      "100%|██████████| 300/300 [01:04<00:00,  4.67trial/s, best loss: -0.8860759493670886]\n",
      "100%|██████████| 300/300 [00:01<00:00, 278.48trial/s, best loss: -0.759493670886076]\n",
      "100%|██████████| 300/300 [00:32<00:00,  9.26trial/s, best loss: -0.8481012658227848]\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.45trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.93trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:13<00:00, 22.05trial/s, best loss: -1.0]\n",
      " 56%|█████▌    | 167/300 [02:00<01:35,  1.39trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.24trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 323.40trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 49.96trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.21trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.57trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:16<00:00, 18.32trial/s, best loss: -0.75]\n",
      " 59%|█████▉    | 177/300 [02:00<01:23,  1.47trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.84trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.99trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:05<00:00, 57.64trial/s, best loss: -1.0]\n",
      "Skipped category: Real Estate due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.49trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:05<00:00, 50.00trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.33trial/s, best loss: -0.7777777777777778]\n",
      " 55%|█████▍    | 164/300 [02:00<01:39,  1.36trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.81trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 340.03trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.40trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:04<00:00, 71.85trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:08<00:00, 36.30trial/s, best loss: -0.8214285714285714]\n",
      "100%|██████████| 300/300 [01:12<00:00,  4.12trial/s, best loss: -0.75]\n",
      " 51%|█████     | 153/300 [02:00<01:55,  1.27trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.59trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:00<00:00, 304.04trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:07<00:00, 38.67trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.73trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.05trial/s, best loss: -0.7272727272727273]\n",
      "100%|██████████| 300/300 [00:23<00:00, 13.04trial/s, best loss: -0.8181818181818182]\n",
      " 57%|█████▋    | 172/300 [02:01<01:30,  1.42trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:33<00:00,  9.00trial/s, best loss: -0.8181818181818182]\n",
      "100%|██████████| 300/300 [00:00<00:00, 318.38trial/s, best loss: -0.6363636363636364]\n",
      "100%|██████████| 300/300 [00:06<00:00, 44.94trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.41trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 9, n_neighbors = 14\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:35:37<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:00<00:04, 70.40trial/s, best loss: -0.6666666666666666]\n",
      "Error training KNN in category Computers & Electronics, skipping\n",
      "100%|██████████| 300/300 [00:12<00:00, 23.89trial/s, best loss: -1.0]\n",
      " 58%|█████▊    | 175/300 [02:00<01:25,  1.45trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The test_size = 1 should be greater or equal to the number of classes = 2\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:37:51<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training MLP in category Computers & Electronics, skipping\n",
      "100%|██████████| 300/300 [00:00<00:00, 346.27trial/s, best loss: -0.6666666666666666]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.23trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 81.84trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 12, n_neighbors = 15\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:38:00<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/300 [00:00<00:02, 110.53trial/s, best loss: -1.0]\n",
      "Error training KNN in category Internet & Telecom, skipping\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.05trial/s, best loss: -1.0]\n",
      " 60%|█████▉    | 179/300 [02:00<01:21,  1.49trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.41trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 350.86trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 64.04trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 78.85trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 53.39trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.07trial/s, best loss: -0.875]\n",
      " 58%|█████▊    | 174/300 [02:00<01:27,  1.44trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.46trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 342.90trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:05<00:00, 55.23trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.62trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.01trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.51trial/s, best loss: -0.8333333333333334]\n",
      " 57%|█████▋    | 172/300 [02:00<01:29,  1.43trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.30trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:00<00:00, 337.31trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.77trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.26trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.20trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.63trial/s, best loss: -1.0]\n",
      " 58%|█████▊    | 173/300 [02:00<01:28,  1.44trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.25trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 313.32trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:06<00:00, 44.03trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.98trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:06<00:00, 49.69trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.48trial/s, best loss: -0.8333333333333334]\n",
      " 52%|█████▏    | 157/300 [02:00<01:49,  1.31trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:27<00:00, 11.04trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:00<00:00, 336.27trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:05<00:00, 51.19trial/s, best loss: -1.0]\n",
      "Skipped category: Adult due to class issues\n",
      "100%|██████████| 300/300 [00:03<00:00, 78.38trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 8\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:52:35<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Home & Garden, skipping\n",
      "100%|██████████| 300/300 [00:10<00:00, 27.29trial/s, best loss: -1.0]\n",
      " 60%|██████    | 180/300 [02:00<01:20,  1.50trial/s, best loss: -0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "\n",
      " 67%|██████▋   | 2/3 [2:54:48<50:29, 3029.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:00<00:18, 16.07trial/s, best loss: -1.0]\n",
      "Error training MLP in category Home & Garden, skipping\n",
      "100%|██████████| 300/300 [00:01<00:00, 286.00trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:04<00:00, 60.33trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:04<00:00, 67.15trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:08<00:00, 35.74trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.77trial/s, best loss: -0.8571428571428571]\n",
      " 54%|█████▍    | 162/300 [02:00<01:42,  1.34trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.23trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.70trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:04<00:00, 62.40trial/s, best loss: -1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 933/933 [00:11<00:00, 84.71it/s]\n",
      "100%|██████████| 6425/6425 [01:49<00:00, 58.54it/s]\n",
      "100%|██████████| 2308/2308 [00:53<00:00, 42.82it/s]\n",
      "100%|██████████| 3/3 [3:01:06<00:00, 3622.01s/it]\n"
     ]
    }
   ],
   "source": [
    "results2, models2 = run_tests_multi(tests2, 0.5, 0, model_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/300 [02:00<02:55,  1.01trial/s, best loss: -0.84]\n",
      " 68%|██████▊   | 204/300 [02:01<00:57,  1.67trial/s, best loss: -0.7953846153846154]\n",
      " 59%|█████▉    | 177/300 [02:00<01:23,  1.47trial/s, best loss: -0.7984615384615384]\n",
      " 11%|█▏        | 34/300 [02:05<16:23,  3.70s/trial, best loss: -0.8123076923076923]\n",
      " 63%|██████▎   | 190/300 [02:00<01:09,  1.58trial/s, best loss: -0.8323076923076923]\n",
      "100%|██████████| 300/300 [00:02<00:00, 100.47trial/s, best loss: -0.78]\n",
      " 63%|██████▎   | 189/300 [02:00<01:10,  1.57trial/s, best loss: -0.796923076923077]\n",
      " 13%|█▎        | 38/300 [10:46<1:14:14, 17.00s/trial, best loss: -0.7874396135265701]  \n",
      "100%|██████████| 300/300 [00:34<00:00,  8.75trial/s, best loss: -0.8019323671497585]\n",
      "100%|██████████| 300/300 [00:41<00:00,  7.19trial/s, best loss: -0.7971014492753623]\n",
      " 22%|██▏       | 67/300 [02:00<06:59,  1.80s/trial, best loss: -0.7729468599033816]\n",
      "100%|██████████| 300/300 [01:29<00:00,  3.34trial/s, best loss: -0.7971014492753623]\n",
      "100%|██████████| 300/300 [00:01<00:00, 212.28trial/s, best loss: -0.7681159420289855]\n",
      "100%|██████████| 300/300 [00:48<00:00,  6.19trial/s, best loss: -0.7971014492753623]\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.58trial/s, best loss: -0.9067796610169492]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.57trial/s, best loss: -0.8389830508474576]\n",
      "100%|██████████| 300/300 [01:05<00:00,  4.55trial/s, best loss: -0.8983050847457628]\n",
      " 25%|██▌       | 76/300 [02:01<05:59,  1.60s/trial, best loss: -0.8813559322033898]\n",
      "100%|██████████| 300/300 [01:42<00:00,  2.93trial/s, best loss: -0.9152542372881356]\n",
      "100%|██████████| 300/300 [00:01<00:00, 248.18trial/s, best loss: -0.8389830508474576]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.32trial/s, best loss: -0.8898305084745762]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.40trial/s, best loss: -0.9318181818181818]\n",
      "100%|██████████| 300/300 [00:11<00:00, 27.18trial/s, best loss: -0.9545454545454546]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.77trial/s, best loss: -0.9318181818181818]\n",
      " 26%|██▋       | 79/300 [02:00<05:35,  1.52s/trial, best loss: -0.9204545454545454]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.35trial/s, best loss: -0.9659090909090909]\n",
      "100%|██████████| 300/300 [00:01<00:00, 270.90trial/s, best loss: -0.9431818181818182]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.50trial/s, best loss: -0.9318181818181818]\n",
      "100%|██████████| 300/300 [00:16<00:00, 18.09trial/s, best loss: -0.8289473684210527]\n",
      "100%|██████████| 300/300 [00:17<00:00, 16.96trial/s, best loss: -0.7763157894736842]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.76trial/s, best loss: -0.7894736842105263]\n",
      " 19%|█▉        | 57/300 [02:00<08:31,  2.11s/trial, best loss: -0.75]\n",
      "100%|██████████| 300/300 [01:09<00:00,  4.34trial/s, best loss: -0.8157894736842105]\n",
      "100%|██████████| 300/300 [00:01<00:00, 241.70trial/s, best loss: -0.7236842105263158]\n",
      "100%|██████████| 300/300 [00:46<00:00,  6.44trial/s, best loss: -0.7894736842105263]\n",
      "100%|██████████| 300/300 [00:07<00:00, 39.43trial/s, best loss: -0.8910891089108911]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.84trial/s, best loss: -0.8811881188118812]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.69trial/s, best loss: -0.8811881188118812]\n",
      " 30%|██▉       | 89/300 [02:00<04:44,  1.35s/trial, best loss: -0.8811881188118812]\n",
      "100%|██████████| 300/300 [00:43<00:00,  6.94trial/s, best loss: -0.8910891089108911]\n",
      "100%|██████████| 300/300 [00:01<00:00, 268.40trial/s, best loss: -0.8811881188118812]\n",
      "100%|██████████| 300/300 [00:13<00:00, 22.62trial/s, best loss: -0.8910891089108911]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 76.55trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.01trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.33trial/s, best loss: -0.8333333333333334]\n",
      " 57%|█████▋    | 172/300 [02:00<01:29,  1.43trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.31trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:00<00:00, 300.92trial/s, best loss: -0.5]\n",
      "100%|██████████| 300/300 [00:05<00:00, 52.92trial/s, best loss: -0.9166666666666666]\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.20trial/s, best loss: -0.9032258064516129]\n",
      "100%|██████████| 300/300 [00:07<00:00, 41.42trial/s, best loss: -0.7419354838709677]\n",
      "100%|██████████| 300/300 [00:17<00:00, 16.84trial/s, best loss: -0.9354838709677419]\n",
      " 43%|████▎     | 128/300 [02:00<02:42,  1.06trial/s, best loss: -0.8387096774193549]\n",
      "100%|██████████| 300/300 [00:38<00:00,  7.80trial/s, best loss: -0.9032258064516129]\n",
      "100%|██████████| 300/300 [00:00<00:00, 300.51trial/s, best loss: -0.7741935483870968]\n",
      "100%|██████████| 300/300 [00:14<00:00, 21.09trial/s, best loss: -0.9032258064516129]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:35<00:00, 36.50it/s]\n",
      "100%|██████████| 2308/2308 [00:52<00:00, 43.62it/s]\n",
      "100%|██████████| 4662/4662 [01:14<00:00, 62.54it/s]\n",
      " 33%|███▎      | 1/3 [57:55<1:55:51, 3475.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 58.23trial/s, best loss: -0.8837209302325582]\n",
      "100%|██████████| 300/300 [00:07<00:00, 38.02trial/s, best loss: -0.8372093023255814]\n",
      "100%|██████████| 300/300 [00:41<00:00,  7.27trial/s, best loss: -0.8837209302325582]\n",
      " 38%|███▊      | 114/300 [02:00<03:16,  1.06s/trial, best loss: -0.8837209302325582]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.13trial/s, best loss: -0.8837209302325582]\n",
      "100%|██████████| 300/300 [00:00<00:00, 301.61trial/s, best loss: -0.7906976744186046]\n",
      "100%|██████████| 300/300 [00:08<00:00, 34.04trial/s, best loss: -0.9069767441860465]\n",
      "100%|██████████| 300/300 [00:05<00:00, 54.83trial/s, best loss: -0.7272727272727273]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.08trial/s, best loss: -0.7045454545454546]\n",
      "100%|██████████| 300/300 [01:46<00:00,  2.83trial/s, best loss: -0.7045454545454546]\n",
      " 42%|████▏     | 127/300 [02:00<02:43,  1.06trial/s, best loss: -0.6590909090909091]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.35trial/s, best loss: -0.7272727272727273]\n",
      "100%|██████████| 300/300 [00:00<00:00, 307.03trial/s, best loss: -0.45454545454545453]\n",
      "100%|██████████| 300/300 [00:11<00:00, 25.90trial/s, best loss: -0.7727272727272727]\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.17trial/s, best loss: -0.8636363636363636]\n",
      "100%|██████████| 300/300 [00:06<00:00, 44.30trial/s, best loss: -0.8409090909090909]\n",
      "100%|██████████| 300/300 [01:15<00:00,  3.96trial/s, best loss: -0.8636363636363636]\n",
      " 39%|███▉      | 118/300 [02:00<03:05,  1.02s/trial, best loss: -0.8636363636363636]\n",
      "100%|██████████| 300/300 [00:31<00:00,  9.38trial/s, best loss: -0.8863636363636364]\n",
      "100%|██████████| 300/300 [00:00<00:00, 315.24trial/s, best loss: -0.7954545454545454]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.05trial/s, best loss: -0.8863636363636364]\n",
      "100%|██████████| 300/300 [00:07<00:00, 40.61trial/s, best loss: -0.8444444444444444]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.07trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:40<00:00,  7.35trial/s, best loss: -0.8444444444444444]\n",
      " 26%|██▋       | 79/300 [02:00<05:37,  1.53s/trial, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:58<00:00,  5.15trial/s, best loss: -0.8444444444444444]\n",
      "100%|██████████| 300/300 [00:01<00:00, 281.75trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.85trial/s, best loss: -0.8444444444444444]\n",
      "100%|██████████| 300/300 [00:03<00:00, 77.92trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 49.92trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.64trial/s, best loss: -1.0]\n",
      " 56%|█████▋    | 169/300 [02:00<01:33,  1.40trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.14trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.40trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.48trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:57<00:00,  5.24trial/s, best loss: -0.8091603053435115]\n",
      "100%|██████████| 300/300 [00:41<00:00,  7.26trial/s, best loss: -0.8473282442748091]\n",
      " 57%|█████▋    | 171/300 [02:00<01:31,  1.41trial/s, best loss: -0.7480916030534351]\n",
      " 22%|██▏       | 65/300 [02:00<07:15,  1.85s/trial, best loss: -0.732824427480916]\n",
      "100%|██████████| 300/300 [01:09<00:00,  4.29trial/s, best loss: -0.816793893129771]\n",
      "100%|██████████| 300/300 [00:01<00:00, 244.28trial/s, best loss: -0.6870229007633588]\n",
      "100%|██████████| 300/300 [00:17<00:00, 16.71trial/s, best loss: -0.7557251908396947]\n",
      "100%|██████████| 300/300 [00:04<00:00, 74.03trial/s, best loss: -0.6363636363636364]\n",
      "100%|██████████| 300/300 [00:07<00:00, 40.20trial/s, best loss: -0.7272727272727273]\n",
      "100%|██████████| 300/300 [00:55<00:00,  5.43trial/s, best loss: -0.6818181818181818]\n",
      " 55%|█████▍    | 164/300 [02:00<01:39,  1.36trial/s, best loss: -0.5909090909090909]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.20trial/s, best loss: -0.6818181818181818]\n",
      "100%|██████████| 300/300 [00:00<00:00, 334.85trial/s, best loss: -0.5454545454545454]\n",
      "100%|██████████| 300/300 [00:16<00:00, 18.67trial/s, best loss: -0.6363636363636364]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 78.28trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:05<00:00, 50.77trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.64trial/s, best loss: -0.9166666666666666]\n",
      " 60%|█████▉    | 179/300 [02:00<01:21,  1.49trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.55trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:00<00:00, 329.25trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.12trial/s, best loss: -0.9166666666666666]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 85.90trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.58trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.10trial/s, best loss: -0.8333333333333334]\n",
      " 59%|█████▉    | 177/300 [02:00<01:23,  1.47trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.93trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:00<00:00, 327.56trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.51trial/s, best loss: -0.8333333333333334]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:19<00:00, 23.49it/s]\n",
      "100%|██████████| 6425/6425 [04:32<00:00, 23.56it/s]\n",
      "100%|██████████| 4662/4662 [01:40<00:00, 46.39it/s]\n",
      " 67%|██████▋   | 2/3 [1:42:15<49:55, 2995.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:09<00:00, 32.14trial/s, best loss: -0.81]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.57trial/s, best loss: -0.78]\n",
      " 70%|██████▉   | 209/300 [02:01<00:52,  1.73trial/s, best loss: -0.82]\n",
      " 26%|██▌       | 78/300 [02:00<05:42,  1.54s/trial, best loss: -0.8]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.26trial/s, best loss: -0.84]\n",
      "100%|██████████| 300/300 [00:01<00:00, 275.12trial/s, best loss: -0.56]\n",
      "100%|██████████| 300/300 [00:17<00:00, 17.25trial/s, best loss: -0.83]\n",
      "100%|██████████| 300/300 [00:05<00:00, 52.61trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:09<00:00, 33.16trial/s, best loss: -0.8928571428571429]\n",
      "100%|██████████| 300/300 [00:56<00:00,  5.33trial/s, best loss: -0.8571428571428571]\n",
      " 40%|███▉      | 119/300 [02:00<03:02,  1.01s/trial, best loss: -0.8928571428571429]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.85trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:01<00:00, 297.77trial/s, best loss: -0.75]\n",
      "100%|██████████| 300/300 [00:09<00:00, 30.24trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:03<00:00, 84.63trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:06<00:00, 49.27trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:18<00:00, 16.67trial/s, best loss: -0.8571428571428571]\n",
      " 53%|█████▎    | 159/300 [02:00<01:46,  1.32trial/s, best loss: -0.7857142857142857]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.91trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:00<00:00, 325.72trial/s, best loss: -0.7142857142857143]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.38trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:04<00:00, 74.34trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.22trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [01:04<00:00,  4.63trial/s, best loss: -0.8275862068965517]\n",
      " 49%|████▊     | 146/300 [02:00<02:06,  1.22trial/s, best loss: -0.7931034482758621]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.23trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [00:00<00:00, 317.65trial/s, best loss: -0.6896551724137931]\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.93trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.09trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:05<00:00, 58.70trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.39trial/s, best loss: -1.0]\n",
      " 52%|█████▏    | 157/300 [02:00<01:49,  1.31trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.16trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 338.87trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.50trial/s, best loss: -1.0]\n",
      "Skipped category: Games due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.47trial/s, best loss: -0.7647058823529411]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.47trial/s, best loss: -0.7647058823529411]\n",
      "100%|██████████| 300/300 [00:32<00:00,  9.28trial/s, best loss: -0.7647058823529411]\n",
      " 52%|█████▏    | 156/300 [02:00<01:50,  1.30trial/s, best loss: -0.7058823529411765]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.18trial/s, best loss: -0.8235294117647058]\n",
      "100%|██████████| 300/300 [00:00<00:00, 333.74trial/s, best loss: -0.47058823529411764]\n",
      "100%|██████████| 300/300 [00:08<00:00, 36.70trial/s, best loss: -0.7647058823529411]\n",
      "100%|██████████| 300/300 [00:03<00:00, 77.44trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:07<00:00, 42.68trial/s, best loss: -0.7931034482758621]\n",
      "100%|██████████| 300/300 [00:54<00:00,  5.50trial/s, best loss: -0.896551724137931]\n",
      " 46%|████▌     | 137/300 [02:00<02:23,  1.14trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.62trial/s, best loss: -0.896551724137931]\n",
      "100%|██████████| 300/300 [00:00<00:00, 326.85trial/s, best loss: -0.6551724137931034]\n",
      "100%|██████████| 300/300 [00:09<00:00, 30.69trial/s, best loss: -0.896551724137931]\n",
      "Skipped category: Online Communities due to low numbers\n",
      "100%|██████████| 300/300 [00:05<00:00, 51.76trial/s, best loss: -0.8620689655172413]\n",
      "100%|██████████| 300/300 [00:09<00:00, 32.84trial/s, best loss: -0.8275862068965517]\n",
      "100%|██████████| 300/300 [01:30<00:00,  3.33trial/s, best loss: -0.8448275862068966]\n",
      " 40%|████      | 120/300 [02:00<03:00,  1.01s/trial, best loss: -0.896551724137931]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.77trial/s, best loss: -0.896551724137931]\n",
      "100%|██████████| 300/300 [00:00<00:00, 305.40trial/s, best loss: -0.7931034482758621]\n",
      "100%|██████████| 300/300 [00:14<00:00, 20.36trial/s, best loss: -0.8793103448275862]\n",
      "Skipped category: Science due to low numbers\n",
      "100%|██████████| 300/300 [00:10<00:00, 28.32trial/s, best loss: -0.905982905982906]\n",
      "100%|██████████| 300/300 [00:13<00:00, 21.49trial/s, best loss: -0.8803418803418803]\n",
      " 50%|█████     | 150/300 [02:00<02:00,  1.25trial/s, best loss: -0.8803418803418803]\n",
      " 26%|██▋       | 79/300 [02:00<05:36,  1.52s/trial, best loss: -0.7948717948717948]\n",
      "100%|██████████| 300/300 [01:11<00:00,  4.17trial/s, best loss: -0.9145299145299145]\n",
      "100%|██████████| 300/300 [00:01<00:00, 259.00trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.10trial/s, best loss: -0.8717948717948718]\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.59trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:04<00:00, 61.46trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:19<00:00, 15.08trial/s, best loss: -0.7777777777777778]\n",
      " 58%|█████▊    | 174/300 [02:00<01:27,  1.44trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.07trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 344.11trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:07<00:00, 41.52trial/s, best loss: -0.8888888888888888]\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 79.79trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:05<00:00, 50.77trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.78trial/s, best loss: -0.8571428571428571]\n",
      " 55%|█████▌    | 166/300 [02:00<01:37,  1.38trial/s, best loss: -0.8571428571428571]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.28trial/s, best loss: -0.9285714285714286]\n",
      "100%|██████████| 300/300 [00:00<00:00, 338.63trial/s, best loss: -0.7142857142857143]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.75trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.83trial/s, best loss: -0.8833333333333333]\n",
      "100%|██████████| 300/300 [00:09<00:00, 32.52trial/s, best loss: -0.7666666666666667]\n",
      "100%|██████████| 300/300 [01:23<00:00,  3.60trial/s, best loss: -0.8833333333333333]\n",
      " 35%|███▍      | 104/300 [02:00<03:47,  1.16s/trial, best loss: -0.8833333333333333]\n",
      "100%|██████████| 300/300 [00:59<00:00,  5.02trial/s, best loss: -0.9166666666666666]\n",
      "100%|██████████| 300/300 [00:01<00:00, 297.17trial/s, best loss: -0.7166666666666667]\n",
      "100%|██████████| 300/300 [00:15<00:00, 19.86trial/s, best loss: -0.9]\n",
      "100%|██████████| 300/300 [00:03<00:00, 77.36trial/s, best loss: -0.9473684210526315]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.34trial/s, best loss: -0.8947368421052632]\n",
      "100%|██████████| 300/300 [00:26<00:00, 11.45trial/s, best loss: -0.8947368421052632]\n",
      " 59%|█████▊    | 176/300 [02:00<01:24,  1.47trial/s, best loss: -0.8421052631578947]\n",
      "100%|██████████| 300/300 [00:27<00:00, 11.06trial/s, best loss: -0.9473684210526315]\n",
      "100%|██████████| 300/300 [00:00<00:00, 321.79trial/s, best loss: -0.631578947368421]\n",
      "100%|██████████| 300/300 [00:10<00:00, 27.76trial/s, best loss: -0.8947368421052632]\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.45trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.30trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:25<00:00, 11.87trial/s, best loss: -0.8888888888888888]\n",
      " 60%|█████▉    | 179/300 [02:00<01:21,  1.48trial/s, best loss: -0.6666666666666666]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.76trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.88trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.11trial/s, best loss: -0.8888888888888888]\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.20trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.88trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:21<00:00, 13.77trial/s, best loss: -1.0]\n",
      " 56%|█████▋    | 169/300 [02:00<01:33,  1.41trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:28<00:00, 10.55trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:00<00:00, 335.18trial/s, best loss: -0.9230769230769231]\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.00trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 80.54trial/s, best loss: -0.9230769230769231]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.83trial/s, best loss: -0.9230769230769231]\n",
      "100%|██████████| 300/300 [00:27<00:00, 10.72trial/s, best loss: -0.9230769230769231]\n",
      " 57%|█████▋    | 172/300 [02:00<01:30,  1.42trial/s, best loss: -0.8461538461538461]\n",
      "100%|██████████| 300/300 [00:23<00:00, 12.53trial/s, best loss: -0.9230769230769231]\n",
      "100%|██████████| 300/300 [00:00<00:00, 339.70trial/s, best loss: -0.9230769230769231]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.38trial/s, best loss: -0.9230769230769231]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 76.61trial/s, best loss: -0.8125]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.73trial/s, best loss: -0.8125]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.57trial/s, best loss: -0.8125]\n",
      " 52%|█████▏    | 157/300 [02:01<01:50,  1.30trial/s, best loss: -0.6875]\n",
      "100%|██████████| 300/300 [00:29<00:00, 10.10trial/s, best loss: -0.875]\n",
      "100%|██████████| 300/300 [00:00<00:00, 338.67trial/s, best loss: -0.6875]\n",
      "100%|██████████| 300/300 [00:06<00:00, 46.07trial/s, best loss: -0.9375]\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "100%|██████████| 300/300 [00:03<00:00, 75.65trial/s, best loss: -0.9130434782608695]\n",
      "100%|██████████| 300/300 [00:06<00:00, 49.85trial/s, best loss: -0.9130434782608695]\n",
      "100%|██████████| 300/300 [00:50<00:00,  5.94trial/s, best loss: -0.9130434782608695]\n",
      " 47%|████▋     | 141/300 [02:00<02:15,  1.17trial/s, best loss: -0.8695652173913043]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.24trial/s, best loss: -0.9130434782608695]\n",
      "100%|██████████| 300/300 [00:00<00:00, 330.56trial/s, best loss: -0.9130434782608695]\n",
      "100%|██████████| 300/300 [00:06<00:00, 45.25trial/s, best loss: -0.9130434782608695]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 933/933 [00:17<00:00, 53.34it/s]\n",
      "100%|██████████| 6425/6425 [03:02<00:00, 35.20it/s]\n",
      "100%|██████████| 2308/2308 [01:06<00:00, 34.83it/s]\n",
      "100%|██████████| 3/3 [2:55:31<00:00, 3510.36s/it]\n"
     ]
    }
   ],
   "source": [
    "results3, models3 = run_tests_multi(tests2, 0.3, 50, model_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 78/300 [02:00<05:43,  1.55s/trial, best loss: -0.8282950423216445]\n",
      " 51%|█████     | 153/300 [02:02<01:57,  1.25trial/s, best loss: -0.7920193470374849]\n",
      "100%|██████████| 300/300 [01:33<00:00,  3.21trial/s, best loss: -0.7871825876662636]\n",
      "  7%|▋         | 22/300 [02:03<26:04,  5.63s/trial, best loss: -0.777509068923821]\n",
      " 64%|██████▍   | 193/300 [02:01<01:07,  1.59trial/s, best loss: -0.8246674727932285]\n",
      "100%|██████████| 300/300 [00:03<00:00, 85.08trial/s, best loss: -0.7412333736396615]\n",
      "100%|██████████| 300/300 [01:30<00:00,  3.31trial/s, best loss: -0.7859733978234583]\n",
      " 20%|██        | 60/300 [02:00<08:03,  2.01s/trial, best loss: -0.8363363363363363]\n",
      " 87%|████████▋ | 261/300 [02:00<00:17,  2.17trial/s, best loss: -0.8063063063063063]\n",
      " 69%|██████▉   | 208/300 [02:00<00:53,  1.73trial/s, best loss: -0.7822822822822822]\n",
      "  7%|▋         | 21/300 [02:01<26:48,  5.77s/trial, best loss: -0.7852852852852853]\n",
      " 59%|█████▊    | 176/300 [02:00<01:24,  1.46trial/s, best loss: -0.8333333333333334]\n",
      "100%|██████████| 300/300 [00:03<00:00, 96.17trial/s, best loss: -0.7522522522522522]\n",
      "100%|██████████| 300/300 [01:12<00:00,  4.11trial/s, best loss: -0.7852852852852853]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.80trial/s, best loss: -0.8735177865612648]\n",
      "100%|██████████| 300/300 [00:34<00:00,  8.78trial/s, best loss: -0.8616600790513834]\n",
      "100%|██████████| 300/300 [01:46<00:00,  2.83trial/s, best loss: -0.8379446640316206]\n",
      " 18%|█▊        | 55/300 [02:03<09:11,  2.25s/trial, best loss: -0.83399209486166]\n",
      "100%|██████████| 300/300 [01:17<00:00,  3.89trial/s, best loss: -0.841897233201581]\n",
      "100%|██████████| 300/300 [00:01<00:00, 199.14trial/s, best loss: -0.7944664031620553]\n",
      "100%|██████████| 300/300 [00:42<00:00,  7.14trial/s, best loss: -0.8379446640316206]\n",
      "100%|██████████| 300/300 [00:37<00:00,  8.11trial/s, best loss: -0.8776978417266187]\n",
      "100%|██████████| 300/300 [00:40<00:00,  7.44trial/s, best loss: -0.8525179856115108]\n",
      "100%|██████████| 300/300 [01:49<00:00,  2.74trial/s, best loss: -0.8489208633093526]\n",
      " 14%|█▍        | 42/300 [02:03<12:35,  2.93s/trial, best loss: -0.8237410071942446]\n",
      "100%|██████████| 300/300 [01:41<00:00,  2.97trial/s, best loss: -0.89568345323741]\n",
      "100%|██████████| 300/300 [00:01<00:00, 172.75trial/s, best loss: -0.7266187050359713]\n",
      "100%|██████████| 300/300 [00:36<00:00,  8.26trial/s, best loss: -0.8525179856115108]\n",
      " 10%|█         | 30/300 [3:09:59<28:29:54, 379.98s/trial, best loss: -0.7960526315789473]  \n",
      "100%|██████████| 300/300 [00:49<00:00,  6.10trial/s, best loss: -0.7993421052631579]\n",
      "100%|██████████| 300/300 [01:37<00:00,  3.09trial/s, best loss: -0.743421052631579]\n",
      " 14%|█▍        | 42/300 [02:03<12:38,  2.94s/trial, best loss: -0.7532894736842105]\n",
      " 75%|███████▍  | 224/300 [02:00<00:40,  1.87trial/s, best loss: -0.805921052631579]\n",
      "100%|██████████| 300/300 [00:01<00:00, 186.60trial/s, best loss: -0.6677631578947368]\n",
      "100%|██████████| 300/300 [01:06<00:00,  4.55trial/s, best loss: -0.7467105263157895]\n",
      "100%|██████████| 300/300 [00:55<00:00,  5.41trial/s, best loss: -0.8825396825396825]\n",
      "100%|██████████| 300/300 [00:49<00:00,  6.05trial/s, best loss: -0.873015873015873]\n",
      "100%|██████████| 300/300 [01:45<00:00,  2.85trial/s, best loss: -0.8603174603174604]\n",
      " 16%|█▋        | 49/300 [02:00<10:17,  2.46s/trial, best loss: -0.8095238095238095]\n",
      " 62%|██████▏   | 187/300 [01:59<01:12,  1.56trial/s, best loss: -0.8761904761904762]\n",
      "100%|██████████| 300/300 [00:01<00:00, 181.71trial/s, best loss: -0.7428571428571429]\n",
      "100%|██████████| 300/300 [00:56<00:00,  5.34trial/s, best loss: -0.8539682539682539]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 300/300 [00:04<00:00, 70.13trial/s, best loss: -0.7878787878787878]\n",
      "100%|██████████| 300/300 [00:07<00:00, 41.41trial/s, best loss: -0.9090909090909091]\n",
      "100%|██████████| 300/300 [00:40<00:00,  7.37trial/s, best loss: -0.7878787878787878]\n",
      " 48%|████▊     | 144/300 [02:00<02:10,  1.20trial/s, best loss: -0.7575757575757576]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.79trial/s, best loss: -0.8484848484848485]\n",
      "100%|██████████| 300/300 [00:00<00:00, 313.73trial/s, best loss: -0.7878787878787878]\n",
      "100%|██████████| 300/300 [00:08<00:00, 35.76trial/s, best loss: -0.7878787878787878]\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 300/300 [00:04<00:00, 73.87trial/s, best loss: -0.7894736842105263]\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.49trial/s, best loss: -0.8421052631578947]\n",
      "100%|██████████| 300/300 [00:20<00:00, 14.98trial/s, best loss: -0.8421052631578947]\n",
      " 51%|█████▏    | 154/300 [02:00<01:54,  1.28trial/s, best loss: -0.7368421052631579]\n",
      "100%|██████████| 300/300 [00:30<00:00,  9.89trial/s, best loss: -0.8947368421052632]\n",
      "100%|██████████| 300/300 [00:00<00:00, 328.47trial/s, best loss: -0.6842105263157895]\n",
      "100%|██████████| 300/300 [00:08<00:00, 37.30trial/s, best loss: -1.0]\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.22trial/s, best loss: -0.8235294117647058]\n",
      "100%|██████████| 300/300 [00:06<00:00, 48.94trial/s, best loss: -0.7647058823529411]\n",
      "100%|██████████| 300/300 [00:13<00:00, 22.00trial/s, best loss: -0.7647058823529411]\n",
      " 56%|█████▌    | 168/300 [02:00<01:34,  1.40trial/s, best loss: -0.8235294117647058]\n",
      "100%|██████████| 300/300 [00:32<00:00,  9.36trial/s, best loss: -0.8823529411764706]\n",
      "100%|██████████| 300/300 [00:00<00:00, 331.15trial/s, best loss: -0.7058823529411765]\n",
      "100%|██████████| 300/300 [00:05<00:00, 56.82trial/s, best loss: -0.7647058823529411]\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 300/300 [00:06<00:00, 47.76trial/s, best loss: -0.8055555555555556]\n",
      "100%|██████████| 300/300 [00:12<00:00, 24.16trial/s, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:35<00:00,  8.40trial/s, best loss: -0.8055555555555556]\n",
      " 34%|███▍      | 103/300 [02:00<03:50,  1.17s/trial, best loss: -0.7777777777777778]\n",
      "100%|██████████| 300/300 [00:40<00:00,  7.37trial/s, best loss: -0.8055555555555556]\n",
      "100%|██████████| 300/300 [00:01<00:00, 287.35trial/s, best loss: -0.6944444444444444]\n",
      "100%|██████████| 300/300 [00:10<00:00, 28.27trial/s, best loss: -0.8055555555555556]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:55<00:00, 23.11it/s]\n",
      "100%|██████████| 2308/2308 [01:25<00:00, 26.94it/s]\n",
      "100%|██████████| 4662/4662 [01:39<00:00, 47.00it/s]\n",
      " 33%|███▎      | 1/3 [4:22:02<8:44:05, 15722.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:08<00:00, 36.28trial/s, best loss: -0.8764044943820225]\n",
      "100%|██████████| 300/300 [00:22<00:00, 13.59trial/s, best loss: -0.8089887640449438]\n",
      " 98%|█████████▊| 294/300 [02:00<00:02,  2.44trial/s, best loss: -0.8876404494382022]\n",
      " 26%|██▌       | 78/300 [02:01<05:45,  1.55s/trial, best loss: -0.7865168539325843]\n",
      "100%|██████████| 300/300 [00:51<00:00,  5.84trial/s, best loss: -0.8876404494382022]\n",
      "100%|██████████| 300/300 [00:01<00:00, 269.81trial/s, best loss: -0.7865168539325843]\n",
      "100%|██████████| 300/300 [00:11<00:00, 25.33trial/s, best loss: -0.898876404494382]\n"
     ]
    }
   ],
   "source": [
    "results4, models4 = run_tests_multi(tests2, 0, 100, model_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(65.06, 61.9), ('twitterfull', (50.13, 46.55)), ('WEIBO', (49.94, 33.9))]),\n",
       " ('twitterfull',\n",
       "  [(55.41, 52.63), ('PHEME', (61.77, 56.37)), ('WEIBO', (50.84, 46.51))]),\n",
       " ('WEIBO',\n",
       "  [(56.59, 52.75),\n",
       "   ('PHEME', (58.33, 47.34)),\n",
       "   ('twitterfull', (48.05, 43.88))])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_models(tests, confidence_threshold, size_threshold, model_list):\n",
    "    trained_models = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        trained_models.append((train[2], train_models(train[1], confidence_threshold, size_threshold, train[0], model_list)))\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.676056338028169]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.46478873239436624]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.5915492957746479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5604395604395604]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.48351648351648346]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/trial, best loss: 0.5164835164835164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/trial, best loss: 0.5164835164835164]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.6263736263736264]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/trial, best loss: 0.5274725274725275]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/trial, best loss: 0.5824175824175823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/trial, best loss: 0.4619565217391305]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.5869565217391304]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.5434782608695652]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/trial, best loss: 0.482051282051282]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.19s/trial, best loss=?]\n",
      "Error training Adaboost in category Sensitive Subjects, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.4717948717948718]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.4821428571428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (242) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (242) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.09999999999999998]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5333333333333333]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.38888888888888884]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.38888888888888884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:41<05:22, 161.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.32499999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.44999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.32307692307692304]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.36923076923076925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.339622641509434]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.80s/trial, best loss=?]\n",
      "Error training Adaboost in category Law & Government, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.25225225225225223]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/trial, best loss: 0.25225225225225223]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/trial, best loss: 0.3063063063063063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.3063063063063063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/trial, best loss: 0.2702702702702703]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (151) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (151) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15384615384615385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.3257575757575758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/trial, best loss: 0.18939393939393945]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.29729729729729726]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.29729729729729726]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.32432432432432434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.18918918918918914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.2702702702702703]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5555555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:07<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.28125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.21875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.17948717948717952]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.10256410256410253]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.40s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.1282051282051282]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.45945945945945943]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.22972972972972971]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.09459459459459463]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.31081081081081086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.1216216216216216]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.3492063492063492]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.2063492063492064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.3492063492063492]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.42105263157894735]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5789473684210527]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.368421052631579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.368421052631579]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:56<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Shopping, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 10\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:57<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Shopping, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:59<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Shopping, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:12<00:00, 144.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_1 = train_many_models(tests, 0.2, 50, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.7575757575757576]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5757575757575757]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5454545454545454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4516129032258065]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.6129032258064516]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.4193548387096774]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/trial, best loss: 0.4516129032258065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4193548387096774]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.6111111111111112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6415094339622642]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.49056603773584906]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3584905660377359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.679245283018868]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.07692307692307687]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.07692307692307687]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3076923076923077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.5344827586206897]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5258620689655172]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.5258620689655172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/trial, best loss: 0.5258620689655172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.5172413793103448]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4444444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3846153846153846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:07<04:14, 127.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.7272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (162) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (162) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.42500000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.21250000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.23750000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.2222222222222222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:58<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2777777777777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.038461538461538436]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.11538461538461542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "\n",
      " 67%|██████▋   | 2/3 [04:55<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 13\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:13<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:19<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:23<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:26<00:00, 108.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_2 = train_many_models(tests, 0.5, 20, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.6901408450704225]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.295774647887324]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.6338028169014085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5774647887323944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.5824175824175823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.4725274725274725]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.5384615384615384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5494505494505495]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.6263736263736264]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.6153846153846154]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.6153846153846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.45108695652173914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5597826086956521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.4836956521739131]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.3897435897435897]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4871794871794872]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/trial, best loss: 0.5384615384615384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5487179487179488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.5487179487179488]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5178571428571428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:04<02:08, 64.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.27692307692307694]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/trial, best loss: 0.2153846153846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.37735849056603776]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.30188679245283023]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.339622641509434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5045045045045045]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.23423423423423428]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.18018018018018023]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1742424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25757575757575757]\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.59s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3513513513513513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2432432432432432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/trial, best loss: 0.32432432432432434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3513513513513513]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:18<01:45, 105.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.1875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.1875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.28125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1923076923076923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.20512820512820518]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.1282051282051282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/trial, best loss: 0.17948717948717952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.16216216216216217]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.09459459459459463]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.16216216216216217]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.31081081081081086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.45945945945945943]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3492063492063492]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3492063492063492]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.2698412698412699]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3157894736842105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.4736842105263158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.368421052631579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:17<00:00, 85.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_3 = train_many_models(tests, 0.2, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5315315315315315]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4054054054054054]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/trial, best loss: 0.4414414414414415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/trial, best loss: 0.6126126126126126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.45945945945945943]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.484472049689441]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.36645962732919257]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5652173913043479]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/trial, best loss: 0.5962732919254659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.515527950310559]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.5629629629629629]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.4740740740740741]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5799256505576208]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.43494423791821557]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.5315985130111525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/trial, best loss: 0.6022304832713754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.5390334572490707]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.4545454545454546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.4439461883408071]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/trial, best loss: 0.4887892376681614]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5112107623318385]\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.87s/trial, best loss: 0.5156950672645739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.452914798206278]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41414141414141414]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41414141414141414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.48484848484848486]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.27586206896551724]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.4482758620689655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.1724137931034483]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.47619047619047616]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.38095238095238093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5238095238095238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:58<05:56, 178.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.19117647058823528]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.27941176470588236]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.17431192660550454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.29357798165137616]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.21100917431192656]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33944954128440363]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/trial, best loss: 0.24770642201834858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.30379746835443033]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25316455696202533]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5063291139240507]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.21518987341772156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.24390243902439024]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.24390243902439024]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.323170731707317]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.43292682926829273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.25609756097560976]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.18791946308724827]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2818791946308725]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.22818791946308725]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.52s/trial, best loss: 0.3422818791946308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.18120805369127513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.32835820895522383]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.20895522388059706]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25373134328358204]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.25373134328358204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4626865671641791]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.3157894736842105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.10526315789473684]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.6428571428571428]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0714285714285714]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:05<02:28, 148.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.18604651162790697]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.86s/trial, best loss: 0.13953488372093026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4423076923076923]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.28846153846153844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.3846153846153846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5192307692307692]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4821428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4821428571428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2571428571428571]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.16190476190476188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.3648648648648649]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.1351351351351351]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.20270270270270274]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.3918918918918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.2727272727272727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.21212121212121215]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:28<00:00, 149.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_4 = train_many_models(tests, 0, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.18634656 -0.03676989  0.15031008 -0.03959699 -0.12490043 -0.07037755\n -0.09134111 -0.04458665  0.1352139  -0.16476609 -0.05009278  0.09190992\n -0.34166586  0.08114699  0.23261669 -0.17008431  0.26703    -0.16768888\n -0.06202133 -0.05942278  0.1092316  -0.02862591  0.05251266 -0.11338406\n -0.05869795  0.33533546 -0.03953567 -0.19303656  0.01340386  0.14430277\n  0.12718946 -0.02238544  0.04988867  0.00456388  0.02524789 -0.15779145\n -0.02987773  0.10196378  0.28181955  0.05118968 -0.02515618 -0.03099566\n -0.0779213   0.11291613  0.01456078 -0.17366055  0.015126   -0.2848044\n  0.24427599  0.19280988 -0.24432033 -0.08670945  0.14834113 -0.127662\n  0.03236877 -0.05287711  0.19145322  0.07521589 -0.19245347 -0.09138723\n -0.07555477  0.27363858 -0.05572034  0.04520389  0.05240389  0.18196422\n -0.18374667  0.18832822  0.18250655 -0.19465455 -0.10638002  0.05715333\n  0.2827231   0.084935    0.02958411 -0.09023823  0.21262322  0.03100055\n  0.16618191  0.19083691  0.18848822 -0.18259932  0.106947   -0.01263633\n -0.15905377 -0.13997145 -0.05745578 -0.02598044 -0.16546914 -0.22051655\n  0.13094386  0.17497684 -0.08850133  0.052844    0.005095    0.15047556\n  0.05498667  0.06692345 -0.10702322 -0.14551237 -0.11534366  0.26609001\n -0.20847064 -0.26204512 -0.26585776 -0.2789644   0.07561325  0.1621031\n  0.06365511  0.13850023  0.17936866 -0.03577911 -0.04874377  0.16383789\n -0.0411925  -0.02017578 -0.15831366 -0.13642257 -0.05869178  0.08106789\n  0.02017177  0.03341779  0.06465533  0.026192   -0.14571334 -0.10601302\n -0.08588845 -0.10384832 -0.32165346  0.43277434  0.22263125 -0.04443278\n  0.13772123 -0.02116974 -0.07342443  0.08155388 -0.01546111  0.03273155\n -0.2512722  -0.02160933  0.05281444 -0.16476355  0.01053255  0.18035859\n -0.3449012   0.023987    0.32511413  0.13935401 -0.12777989  0.081007\n  0.15717798  0.07340612 -2.21698451 -0.11545645  0.05947145  0.17918311\n -0.10580367  0.17822446  0.02427446 -0.013803    0.13548744  0.10256466\n -0.24156009  0.13866609 -0.01050414 -0.04511344  0.11788198  0.04844212\n  0.09757856  0.08501974 -0.24932776  0.13573311  0.11360656  0.02161834\n -0.08702457 -0.11466544 -0.033427    0.01223289 -0.04737334 -0.10691623\n -0.09661411  0.28688347 -0.05942756  0.01578281  0.06951     0.07973965\n  0.08174323 -0.18866701 -0.16314334  0.02758878  0.19159548 -0.03379688\n -0.1073091   0.06545316 -0.08683923 -0.040576    0.00380845 -0.19891965\n  0.08870278  0.08446962].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willc\\Documents\\wills ensemble\\categorized_voters.ipynb Cell 25\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([text \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m pheme[\u001b[39m'\u001b[39m\u001b[39me_text\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, pheme[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m clf\u001b[39m.\u001b[39;49mpredict(twitter[\u001b[39m'\u001b[39;49m\u001b[39me_text\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:369\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# 'hard' voting\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n\u001b[0;32m    370\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\n\u001b[0;32m    371\u001b[0m         \u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39mbincount(x, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_not_none)),\n\u001b[0;32m    372\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    373\u001b[0m         arr\u001b[39m=\u001b[39mpredictions,\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    376\u001b[0m maj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39minverse_transform(maj)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:68\u001b[0m, in \u001b[0;36m_BaseVoting._predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:68\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39;49mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    816\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    817\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \n\u001b[0;32m    418\u001b[0m \u001b[39m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[0;32m    432\u001b[0m     predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[0;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[1;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    612\u001b[0m         X,\n\u001b[0;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    615\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    617\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[0;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.18634656 -0.03676989  0.15031008 -0.03959699 -0.12490043 -0.07037755\n -0.09134111 -0.04458665  0.1352139  -0.16476609 -0.05009278  0.09190992\n -0.34166586  0.08114699  0.23261669 -0.17008431  0.26703    -0.16768888\n -0.06202133 -0.05942278  0.1092316  -0.02862591  0.05251266 -0.11338406\n -0.05869795  0.33533546 -0.03953567 -0.19303656  0.01340386  0.14430277\n  0.12718946 -0.02238544  0.04988867  0.00456388  0.02524789 -0.15779145\n -0.02987773  0.10196378  0.28181955  0.05118968 -0.02515618 -0.03099566\n -0.0779213   0.11291613  0.01456078 -0.17366055  0.015126   -0.2848044\n  0.24427599  0.19280988 -0.24432033 -0.08670945  0.14834113 -0.127662\n  0.03236877 -0.05287711  0.19145322  0.07521589 -0.19245347 -0.09138723\n -0.07555477  0.27363858 -0.05572034  0.04520389  0.05240389  0.18196422\n -0.18374667  0.18832822  0.18250655 -0.19465455 -0.10638002  0.05715333\n  0.2827231   0.084935    0.02958411 -0.09023823  0.21262322  0.03100055\n  0.16618191  0.19083691  0.18848822 -0.18259932  0.106947   -0.01263633\n -0.15905377 -0.13997145 -0.05745578 -0.02598044 -0.16546914 -0.22051655\n  0.13094386  0.17497684 -0.08850133  0.052844    0.005095    0.15047556\n  0.05498667  0.06692345 -0.10702322 -0.14551237 -0.11534366  0.26609001\n -0.20847064 -0.26204512 -0.26585776 -0.2789644   0.07561325  0.1621031\n  0.06365511  0.13850023  0.17936866 -0.03577911 -0.04874377  0.16383789\n -0.0411925  -0.02017578 -0.15831366 -0.13642257 -0.05869178  0.08106789\n  0.02017177  0.03341779  0.06465533  0.026192   -0.14571334 -0.10601302\n -0.08588845 -0.10384832 -0.32165346  0.43277434  0.22263125 -0.04443278\n  0.13772123 -0.02116974 -0.07342443  0.08155388 -0.01546111  0.03273155\n -0.2512722  -0.02160933  0.05281444 -0.16476355  0.01053255  0.18035859\n -0.3449012   0.023987    0.32511413  0.13935401 -0.12777989  0.081007\n  0.15717798  0.07340612 -2.21698451 -0.11545645  0.05947145  0.17918311\n -0.10580367  0.17822446  0.02427446 -0.013803    0.13548744  0.10256466\n -0.24156009  0.13866609 -0.01050414 -0.04511344  0.11788198  0.04844212\n  0.09757856  0.08501974 -0.24932776  0.13573311  0.11360656  0.02161834\n -0.08702457 -0.11466544 -0.033427    0.01223289 -0.04737334 -0.10691623\n -0.09661411  0.28688347 -0.05942756  0.01578281  0.06951     0.07973965\n  0.08174323 -0.18866701 -0.16314334  0.02758878  0.19159548 -0.03379688\n -0.1073091   0.06545316 -0.08683923 -0.040576    0.00380845 -0.19891965\n  0.08870278  0.08446962].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "ensemble = []\n",
    "for model in models_1[0][1]['People & Society'].keys():\n",
    "    set = models_1[0][1]['People & Society']\n",
    "    ensemble.append((model, set[model]))\n",
    "clf = VotingClassifier(ensemble, voting=\"hard\")\n",
    "X_train = np.array([text for text in pheme['e_text']])\n",
    "clf.fit(X_train, pheme['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array(twitter['e_text'][0]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo = get_dataset(\"weibo\")\n",
    "weibo = weibo.drop([1933, 3564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4662/4662 [00:27<00:00, 171.96it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_hard, predictions_soft = predict_points_mutiple_models(models_1[0][1], \"weibo_categories.json\", weibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "X_train = np.array([text for text in ph['e_text']])\n",
    "svm.fit(X_train, twitter['target'])\n",
    "X_test = np.array([text for text in weibo['e_text']])\n",
    "pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.26, 33.71)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.26, 33.75)\n"
     ]
    }
   ],
   "source": [
    "print(check_score(weibo['target'], predictions_hard))\n",
    "print(check_score(weibo['target'], predictions_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGxCAYAAAAplG/RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABI+UlEQVR4nO3deVhU9f4H8PcMMOwziALDKCBeTcE99Bpe1yRByyXtei00vJHeTDQ111uYS0mpuWailpKFabfSFNMkN1wIBSM3RFEQUkELYQQDhpnz+4MfUxM4MswZtt6v5znP48z5fs98Dg/Ch8/ne86RCIIggIiIiMiCpPUdABERETV9TDiIiIjI4phwEBERkcUx4SAiIiKLY8JBREREFseEg4iIiCyOCQcRERFZHBMOIiIisjjr+g6gIdPpdLh16xacnZ0hkUjqOxwiIjKRIAi4f/8+VCoVpFLL/Y1dUlKCsrIys48jk8lgZ2cnQkQNDxMOI27dugUvL6/6DoOIiMyUk5ODVq1aWeTYJSUl8PVxQu4drdnHUiqVyMzMbJJJBxMOI5ydnQEAN862htyJ3Sdqmp59rHN9h0BkMeXQ4AS+1f88t4SysjLk3tHiRkpryJ1r/7tCfV8Hn4AslJWV1TjhSEhIwPLly5GSkoLbt29j165dGDlypH5/UVER5s2bh927d+PXX3+Fr68vpk2bhldeeUU/pqSkBK+//jp27NiB0tJSBAcH48MPP4SHh4d+THZ2NiZPnowjR47AyckJYWFhiIqKgrV1zdMIJhxGVLZR5E5Ss76JiBoya4lNfYdAZDn//7SwumiLOzlL4ORc+8/RwfS5xcXF6Nq1K1566SWMGjWqyv6ZM2fi8OHD+Oyzz9C6dWscPHgQr776KlQqFYYPHw4AmDFjBvbt24f//e9/UCgUiIiIwKhRo3Dy5EkAgFarxdNPPw2lUolTp07h9u3bePHFF2FjY4OlS5fWOFYmHERERCLQCjpozXgcqlbQmTxnyJAhGDJkyEP3nzp1CmFhYRgwYAAAYNKkSdi4cSNOnz6N4cOHo7CwEB9//DG2b9+OJ598EgCwdetW+Pn54YcffsATTzyBgwcP4tKlS/j+++/h4eGBbt26YcmSJZg7dy4WLlwImUxWo1j5ZzsREZEIdBDM3gBArVYbbKWlpbWOqXfv3tizZw9u3rwJQRBw5MgRXLlyBYMHDwYApKSkQKPRICgoSD+nQ4cO8Pb2RmJiIgAgMTERnTt3NmixBAcHQ61W4+LFizWOhQkHERFRA+Ll5QWFQqHfoqKian2sdevWwd/fH61atYJMJkNISAjWr1+Pfv36AQByc3Mhk8ng4uJiMM/DwwO5ubn6MX9MNir3V+6rKbZUiIiIRKCDDqY3RQznAxVX1Mjlcv37tra2tT7munXr8MMPP2DPnj3w8fFBQkICpkyZApVKZVDVqAtMOIiIiESgFQRohdov4qicK5fLDRKO2vrtt9/w3//+F7t27cLTTz8NAOjSpQtSU1OxYsUKBAUFQalUoqysDAUFBQZVjry8PCiVSgAVl+qePn3a4Nh5eXn6fTXFlgoREVETpNFooNFoqtzwzMrKCjpdRTUlICAANjY2OHTokH5/eno6srOzERgYCAAIDAzE+fPncefOHf2Y+Ph4yOVy+Pv71zgeVjiIiIhE8MeFn7Wdb6qioiJkZGToX2dmZiI1NRWurq7w9vZG//79MXv2bNjb28PHxwfHjh3Dtm3bsHLlSgCAQqFAeHg4Zs6cCVdXV8jlckydOhWBgYF44oknAACDBw+Gv78/xo8fj2XLliE3NxdvvvkmpkyZYlK7hwkHERGRCHQQoK3jhCM5ORkDBw7Uv545cyYAICwsDDExMdixYwfmz5+P0NBQ5Ofnw8fHB++8847Bjb9WrVoFqVSK0aNHG9z4q5KVlRXi4uIwefJkBAYGwtHREWFhYVi8eLFJsUoEwYyGUxOnVquhUChw70ob3viLmqxgVbf6DoHIYsoFDY7iGxQWFoqyLqI6lb8rMi97wtmM3xX37+vg2+G2RWOtT6xwEBERiaA+WiqNCRMOIiIiEYh1lUpTxT4BERERWRwrHERERCLQ/f9mzvymjAkHERGRCLRmXqViztzGgAkHERGRCLQCzHxarHixNERcw0FEREQWxwoHERGRCLiGwzgmHERERCLQQQItJGbNb8rYUiEiIiKLY4WDiIhIBDqhYjNnflPGhIOIiEgEWjNbKubMbQzYUiEiIiKLY4WDiIhIBKxwGMeEg4iISAQ6QQKdYMZVKmbMbQzYUiEiIiKLY4WDiIhIBGypGMeEg4iISARaSKE1o3GgFTGWhogJBxERkQgEM9dwCFzDQURERGQeVjiIiIhEwDUcxjHhICIiEoFWkEIrmLGGo4nf2pwtFSIiIrI4VjiIiIhEoIMEOjP+jtehaZc4mHAQERGJgGs4jGNLhYiIiCyOFQ4iIiIRmL9olC0VIiIieoSKNRxmPLyNLRUiIiIi87DCQUREJAKdmc9S4VUqRERE9Ehcw2EcEw4iIiIR6CDlfTiM4BoOIiIisjhWOIiIiESgFSTQmvGIeXPmNgZMOIiIiESgNXPRqJYtFSIiIiLzsMJBREQkAp0ghc6Mq1R0vEqFiIiIHoUtFePYUiEiIiKLY4WDiIhIBDqYd6WJTrxQGiQmHERERCIw/8ZfTbvp0LTPjoiIiBoEVjiIiIhEYP6zVJp2DYAJBxERkQh0kEAHc9Zw8E6jRERE9AiscBjXtM+OiIiIGgRWOIiIiERg/o2/mnYNoGmfHRERUR3RCRKzN1MlJCRg2LBhUKlUkEgk2L17d5UxaWlpGD58OBQKBRwdHdGzZ09kZ2fr95eUlGDKlClo3rw5nJycMHr0aOTl5RkcIzs7G08//TQcHBzg7u6O2bNno7y83KRYmXAQERE1UsXFxejatSvWr19f7f5r166hT58+6NChA44ePYpz584hMjISdnZ2+jEzZszA3r178b///Q/Hjh3DrVu3MGrUKP1+rVaLp59+GmVlZTh16hQ++eQTxMTEYMGCBSbFKhGEJv60GDOo1WooFArcu9IGcmfmZtQ0Bau61XcIRBZTLmhwFN+gsLAQcrncIp9R+bvi3TP9YedU+5UKJUXlmNfzWK1jlUgk2LVrF0aOHKl/b+zYsbCxscGnn35a7ZzCwkK4ublh+/bteO655wAAly9fhp+fHxITE/HEE09g//79eOaZZ3Dr1i14eHgAAKKjozF37lzcvXsXMpmsRvHxtygREZEIKp8Wa84GVCQwf9xKS0trF49Oh3379uGxxx5DcHAw3N3d0atXL4O2S0pKCjQaDYKCgvTvdejQAd7e3khMTAQAJCYmonPnzvpkAwCCg4OhVqtx8eLFGsfDhIOIiKgB8fLygkKh0G9RUVG1Os6dO3dQVFSEd999FyEhITh48CCeffZZjBo1CseOHQMA5ObmQiaTwcXFxWCuh4cHcnNz9WP+mGxU7q/cV1O8SoWIiEgEWkigNePmXZVzc3JyDFoqtra2tTqeTlfxOLgRI0ZgxowZAIBu3brh1KlTiI6ORv/+/Wsda22wwkFERCQCsVoqcrncYKttwtGiRQtYW1vD39/f4H0/Pz/9VSpKpRJlZWUoKCgwGJOXlwelUqkf8+erVipfV46pCSYcRERETZBMJkPPnj2Rnp5u8P6VK1fg4+MDAAgICICNjQ0OHTqk35+eno7s7GwEBgYCAAIDA3H+/HncuXNHPyY+Ph5yubxKMmMMWypEREQi0AJmtlRMV1RUhIyMDP3rzMxMpKamwtXVFd7e3pg9ezb+9a9/oV+/fhg4cCAOHDiAvXv34ujRowAAhUKB8PBwzJw5E66urpDL5Zg6dSoCAwPxxBNPAAAGDx4Mf39/jB8/HsuWLUNubi7efPNNTJkyxaTqCxMOIiIiEfyxLVLb+aZKTk7GwIED9a9nzpwJAAgLC0NMTAyeffZZREdHIyoqCtOmTUP79u3x1VdfoU+fPvo5q1atglQqxejRo1FaWorg4GB8+OGH+v1WVlaIi4vD5MmTERgYCEdHR4SFhWHx4sUmxcr7cBjB+3DQXwHvw0FNWV3eh2N+YgjsnGxqfZySIg2iAg9YNNb6xN+iREREZHFsqRAREYlAgAQ6M9ZwCGbMbQyYcBAREYlAK0ihNWMNhzlzG4OmfXZERETUILDCQUREJILaPmL+j/ObMiYcREREItBCCq0ZjQNz5jYGTfvsiIiIqEFghYOIiEgEbKkYx4SDiIhIBDpIoTOjcWDO3MagaZ8dERERNQiscBAREYlAK0igNaMtYs7cxoAJBxERkQi4hsM4JhxEREQiEMx8WqzAO40SERERmYcVDiIiIhFoIYHWjAewmTO3MWDCQUREJAKdYN46DJ0gYjANEFsqREREZHGscJDozv/giP996I6r5x2Qn2eDtz7ORO8hhfr9vxVL8fE7nkj8TgH1PWsovcowIvwunnnxV/2Ybz9rjiO7miHjvD0eFFnhq7TzcFJo9ft/OuWEOc+1rfbz136bjvbdfrPcCRL9ybjXczH+9TyD93IybPFyvw4AgGnv5aB73yI099DgtwdSpCU74uN3PJGTYQcAcG5WjnkfZMPX7zc4N9Oi8FdrJH4nx9YoTzwosqrz86Ha0Zm5aNScuY0BEw4SXckDKdp0/A3Bz+djcbhvlf0bF6qQetIZc9Zlw8OrDGePOWPd/FZo7qFBYLC64hi/SdFjgBo9BqixJUpV5Rj+PYrxeeoFg/c+WeaJ1BNOeKwrkw2qe1mX7TDvX230r7Xa30vrV8854PDXzXD3pgzOzcox7vU8LP38OsJ6+UGnk0DQAYnfyRHznhKFv1pD5VuKiKU34ezyM96d4lMfp0O1oIMEOjPWYZgztzFocAnHgAED0K1bN6xevbq+Q6Fa6vnkffR88v5D919KdsRT/8xH195FAICh437Fvk+bIz3VQZ9wjJp4F0BFJaM6NjIBru7l+tflmoof2CNe+gWSpv1/lhoorRa4d9em2n37Y5vr/533swyfvKdE9KEr8PAqw+0btigqtEbcthb6MXduyrD3k+b45+S7Fo+bqK40uvqNIAgoLy9/9EBqsPx7FOOHgwr8ctsGggCknnTCzeu2COj/8CTlURIPKnD/njUG/ytfxEiJaq6lbxm2n72ImMQ0zP3gBtxallU7ztZei8H/ysftGzLcvVV9guLqocE/hhTiXKKjJUMmkVXeadScrSlrUAnHhAkTcOzYMaxZswYSiQQSiQQxMTGQSCTYv38/AgICYGtrixMnTmDChAkYOXKkwfzp06djwIAB+tc6nQ5RUVHw9fWFvb09unbtii+//LJuT4qqePXtm/B+rAShAR3xtE9XvBnaBlOW/ozOTxTX+pjffd4cAQPuw02lETFSopq5fNYBK6Z74Y3QNlg3ryWU3mV4f1cG7B1/X3f0TNgv2H31PPZcu4CeT97H/LFtUK4x/BE878Mb+ObaOXz+4yU8KLLCqlledX0qZIbKNRzmbE1Zg2qprFmzBleuXEGnTp2wePFiAMDFixcBAPPmzcOKFSvQpk0bNGvWrEbHi4qKwmeffYbo6Gi0a9cOCQkJGDduHNzc3NC/f/8q40tLS1FaWqp/rVarRTgr+rNvtrTA5RQHLIq5DvdWZTj/gxPW/7diDcfj/YpMPt7dWzZIOeqM/27MEj9YohpIPiLX/zszzR6Xf3TEp6cvod/wAnz3eUU75fDXzXA2wRmu7ho8N/ku3th4AzNGtIWm9PdfMhvfUiF2pQdatinFS/Nv4z9v3cIH/21V5+dDZAkNKuFQKBSQyWRwcHCAUqkEAFy+fBkAsHjxYjz11FM1PlZpaSmWLl2K77//HoGBgQCANm3a4MSJE9i4cWO1CUdUVBQWLVokwpnQw5T+JkHMu55Y8HEWegVVJHRt/Etw/aI9vox2r1XCcXCnK5yblSNwcOGjBxPVgWK1FX6+bgtV69/bKg/uW+HBfSvcyrTF5bMO+CrtIv4xpBBHd//+B9S9uza4d9cGORl2uF9ghZW7r2H7ag/k36m+9UINiw5mPkuFi0Ybhh49epg0PiMjAw8ePKiSpJSVlaF79+7Vzpk/fz5mzpypf61Wq+HlxZKmmMrLJSjXSCGVGt7hRmolQNCZfjxBqEg4gp67B2v+TKYGws5BC5VPGQ59Vf2PWIkEgESAjezhd3qqXPxsbAw1LIKZV6kITDgaBkdHw8VTUqkUgmD4H1Gj+b1/X1RU8Zfyvn370LJlS4Nxtra21X6Gra3tQ/dRzf1WLMWtzN+/jrk5Mly7YA9nl3K4t9KgS2ARNi9RQWZ3Ex6tynAu0Qnff+mKSW/d1M/Jv2ONe3dscCtTBgDIvGwHB0cd3FqWQd7s97546gkn5GbbIuSF3+/hQVTXJi64hR8OynHnZxmaKzUYPysXWh1wdFczKL1L0X94AVKOOaMw3xpunhqMibiDst+kOH3IGQDQ80k1mrmVIz3VHiXFVvBpX4KXI2/hwmkH5P0sq+ezo5ri02KNa3AJh0wmg1arfeQ4Nzc3XLhgeB+G1NRU2NhU/Jnr7+8PW1tbZGdnV9s+Icu58pODwU25Ni6sSPieGpOPWauzMX9DFrYs9cR7Ed64X2AN95ZlmDD3tsGNv/Zta4HPVir1r2c92w4A8PqqbIMrUQ583hz+PYrg3e73tTdEda2FpwbzP7yhv2nXxTOOmP5MOxTmW8PKRkCnXsV4duIvcFJoUfCLNc7/4IgZI9qi8NeKn1dlJVIMCf0V/1lYAhuZgLu3bHByvwI7P/Co5zMjEk+DSzhat26NpKQkZGVlwcnJCTpd9XX2J598EsuXL8e2bdsQGBiIzz77DBcuXNC3S5ydnTFr1izMmDEDOp0Offr0QWFhIU6ePAm5XI6wsLC6PK2/lK69i/DdrdSH7nd1L8es1TlGjzF+Vi7Gz8p95GfN//CGqeERiS5q8sNvzpWfZ4PI8W0euh+ouN/MjOHtxA6L6hjvNGpcgzu7WbNmwcrKCv7+/nBzc0N2dna144KDgxEZGYk5c+agZ8+euH//Pl588UWDMUuWLEFkZCSioqLg5+eHkJAQ7Nu3D76+Ve9+SUREZI7Kloo5W1MmEf68EIL01Go1FAoF7l1pA7lzg8vNiEQRrOpW3yEQWUy5oMFRfIPCwkLI5fJHT6iFyt8VIw6+BBvH2q+50RSX4ZvBWywaa31qcC0VIiKixojPUjGOCQcREZEIeJWKcewTEBERkcWxwkFERCQCVjiMY8JBREQkAiYcxrGlQkRERBbHCgcREZEIWOEwjgkHERGRCASYd2lrU78pFhMOIiIiEbDCYRzXcBAREZHFscJBREQkAlY4jGPCQUREJAImHMaxpUJEREQWxwoHERGRCFjhMI4JBxERkQgEQQLBjKTBnLmNAVsqREREZHFMOIiIiESgg8TszVQJCQkYNmwYVCoVJBIJdu/e/dCxr7zyCiQSCVavXm3wfn5+PkJDQyGXy+Hi4oLw8HAUFRUZjDl37hz69u0LOzs7eHl5YdmyZSbHyoSDiIhIBJVrOMzZTFVcXIyuXbti/fr1Rsft2rULP/zwA1QqVZV9oaGhuHjxIuLj4xEXF4eEhARMmjRJv1+tVmPw4MHw8fFBSkoKli9fjoULF2LTpk0mxco1HERERI3UkCFDMGTIEKNjbt68ialTp+K7777D008/bbAvLS0NBw4cwJkzZ9CjRw8AwLp16zB06FCsWLECKpUKsbGxKCsrw5YtWyCTydCxY0ekpqZi5cqVBonJo7DCQUREJILKRaPmbEBFReGPW2lpaa1j0ul0GD9+PGbPno2OHTtW2Z+YmAgXFxd9sgEAQUFBkEqlSEpK0o/p168fZDKZfkxwcDDS09Nx7969GsfChIOIiEgEYrVUvLy8oFAo9FtUVFStY3rvvfdgbW2NadOmVbs/NzcX7u7uBu9ZW1vD1dUVubm5+jEeHh4GYypfV46pCbZUiIiIRCDWZbE5OTmQy+X6921tbWt1vJSUFKxZswZnz56FRFL/l9yywkFERNSAyOVyg622Ccfx48dx584deHt7w9raGtbW1rhx4wZef/11tG7dGgCgVCpx584dg3nl5eXIz8+HUqnUj8nLyzMYU/m6ckxNMOEgIiISgWBmO0XsG3+NHz8e586dQ2pqqn5TqVSYPXs2vvvuOwBAYGAgCgoKkJKSop93+PBh6HQ69OrVSz8mISEBGo1GPyY+Ph7t27dHs2bNahwPWypEREQiEAAIgnnzTVVUVISMjAz968zMTKSmpsLV1RXe3t5o3ry5wXgbGxsolUq0b98eAODn54eQkBBMnDgR0dHR0Gg0iIiIwNixY/WX0L7wwgtYtGgRwsPDMXfuXFy4cAFr1qzBqlWrTIqVCQcREVEjlZycjIEDB+pfz5w5EwAQFhaGmJiYGh0jNjYWERERGDRoEKRSKUaPHo21a9fq9ysUChw8eBBTpkxBQEAAWrRogQULFph0SSzAhIOIiEgUOkggqcXdQv8431QDBgyAYEJZJSsrq8p7rq6u2L59u9F5Xbp0wfHjx00NzwATDiIiIhHw4W3GcdEoERERWRwrHERERCLQCRJIzKhS1OZZKo0JEw4iIiIRCIKZV6mYMbcxYEuFiIiILI4VDiIiIhFw0ahxTDiIiIhEwITDOCYcREREIuCiUeO4hoOIiIgsjhUOIiIiEfAqFeOYcBAREYmgIuEwZw2HiME0QGypEBERkcWxwkFERCQCXqViHBMOIiIiEQj/v5kzvyljS4WIiIgsjhUOIiIiEbClYhwTDiIiIjGwp2IUEw4iIiIxmFnhQBOvcHANBxEREVkcKxxEREQi4J1GjWPCQUREJAIuGjWOLRUiIiKyOFY4iIiIxCBIzFv42cQrHEw4iIiIRMA1HMaxpUJEREQWxwoHERGRGHjjL6NqlHDs2bOnxgccPnx4rYMhIiJqrHiVinE1SjhGjhxZo4NJJBJotVpz4iEiIqImqEYJh06ns3QcREREjV8Tb4uYw6w1HCUlJbCzsxMrFiIiokaLLRXjTL5KRavVYsmSJWjZsiWcnJxw/fp1AEBkZCQ+/vhj0QMkIiJqFAQRtibM5ITjnXfeQUxMDJYtWwaZTKZ/v1OnTvjoo49EDY6IiIiaBpMTjm3btmHTpk0IDQ2FlZWV/v2uXbvi8uXLogZHRETUeEhE2Jouk9dw3Lx5E23btq3yvk6ng0ajESUoIiKiRof34TDK5AqHv78/jh8/XuX9L7/8Et27dxclKCIiImpaTK5wLFiwAGFhYbh58yZ0Oh2+/vprpKenY9u2bYiLi7NEjERERA0fKxxGmVzhGDFiBPbu3Yvvv/8ejo6OWLBgAdLS0rB371489dRTloiRiIio4at8Wqw5WxNWq/tw9O3bF/Hx8WLHQkRERE1UrW/8lZycjLS0NAAV6zoCAgJEC4qIiKix4ePpjTM54fj555/x/PPP4+TJk3BxcQEAFBQUoHfv3tixYwdatWoldoxEREQNH9dwGGXyGo6XX34ZGo0GaWlpyM/PR35+PtLS0qDT6fDyyy9bIkYiIiJq5EyucBw7dgynTp1C+/bt9e+1b98e69atQ9++fUUNjoiIqNEwd+EnF40a8vLyqvYGX1qtFiqVSpSgiIiIGhuJULGZM78pM7mlsnz5ckydOhXJycn695KTk/Haa69hxYoVogZHRETUaPDhbUbVqMLRrFkzSCS/l3qKi4vRq1cvWFtXTC8vL4e1tTVeeukljBw50iKBEhERUeNVo4Rj9erVFg6DiIiokeMaDqNqlHCEhYVZOg4iIqLGjZfFGmXyGo4/KikpgVqtNtiIiIiobiQkJGDYsGFQqVSQSCTYvXu3fp9Go8HcuXPRuXNnODo6QqVS4cUXX8StW7cMjpGfn4/Q0FDI5XK4uLggPDwcRUVFBmPOnTuHvn37ws7ODl5eXli2bJnJsZqccBQXFyMiIgLu7u5wdHREs2bNDDYiIqK/pHpYNFpcXIyuXbti/fr1VfY9ePAAZ8+eRWRkJM6ePat/2Orw4cMNxoWGhuLixYuIj49HXFwcEhISMGnSJP1+tVqNwYMHw8fHBykpKVi+fDkWLlyITZs2mRSryZfFzpkzB0eOHMGGDRswfvx4rF+/Hjdv3sTGjRvx7rvvmno4IiKipqEeWipDhgzBkCFDqt2nUCiqPPfsgw8+wN///ndkZ2fD29sbaWlpOHDgAM6cOYMePXoAANatW4ehQ4dixYoVUKlUiI2NRVlZGbZs2QKZTIaOHTsiNTUVK1euNEhMHsXkCsfevXvx4YcfYvTo0bC2tkbfvn3x5ptvYunSpYiNjTX1cERERPQHf16qUFpaKtqxCwsLIZFI9I8mSUxMhIuLiz7ZAICgoCBIpVIkJSXpx/Tr1w8ymUw/Jjg4GOnp6bh3716NP9vkhCM/Px9t2rQBAMjlcuTn5wMA+vTpg4SEBFMPR0RE1DSI9Hh6Ly8vKBQK/RYVFSVKeCUlJZg7dy6ef/55yOVyAEBubi7c3d0NxllbW8PV1RW5ubn6MR4eHgZjKl9XjqkJk1sqbdq0QWZmJry9vdGhQwd88cUX+Pvf/469e/fqMyYiIqK/GrHuNJqTk6NPCADA1tbWzMgqFpCOGTMGgiBgw4YNZh+vNkxOOP7973/jp59+Qv/+/TFv3jwMGzYMH3zwATQaDVauXGmJGImIiP4y5HK5QcJhrspk48aNGzh8+LDBsZVKJe7cuWMwvry8HPn5+VAqlfoxeXl5BmMqX1eOqQmTE44ZM2bo/x0UFITLly8jJSUFbdu2RZcuXUw9HBERUdPQAO/DUZlsXL16FUeOHEHz5s0N9gcGBqKgoAApKSkICAgAABw+fBg6nQ69evXSj3njjTeg0WhgY2MDAIiPj0f79u1NujrV5ITjz3x8fODj42PuYYiIiMhERUVFyMjI0L/OzMxEamoqXF1d4enpieeeew5nz55FXFwctFqtfs2Fq6srZDIZ/Pz8EBISgokTJyI6OhoajQYREREYO3as/oGsL7zwAhYtWoTw8HDMnTsXFy5cwJo1a7Bq1SqTYq1RwrF27doaH3DatGkmBUBERNQUSGDmGo5azElOTsbAgQP1r2fOnAmg4g7hCxcuxJ49ewAA3bp1M5h35MgRDBgwAAAQGxuLiIgIDBo0CFKpFKNHjzb4va9QKHDw4EFMmTIFAQEBaNGiBRYsWGDSJbFADROOmmYxEomECQcREVEdGTBgAATh4VmOsX2VXF1dsX37dqNjunTpguPHj5sc3x/VKOHIzMw060MauwtlJXAqM+su8EQNlpWIi9OIGhpBKAPq6qkbfHibUWav4SAiIiI0yEWjDQn/bCciIiKLY4WDiIhIDKxwGMWEg4iISARi3Wm0qWJLhYiIiCyuVgnH8ePHMW7cOAQGBuLmzZsAgE8//RQnTpwQNTgiIqJGQxBha8JMTji++uorBAcHw97eHj/++KP+sbmFhYVYunSp6AESERE1Ckw4jDI54Xj77bcRHR2NzZs36++pDgD/+Mc/cPbsWVGDIyIioqbB5EWj6enp6NevX5X3FQoFCgoKxIiJiIio0eGiUeNMrnAolUqDB8VUOnHiBNq0aSNKUERERI1O5Z1GzdmaMJMTjokTJ+K1115DUlISJBIJbt26hdjYWMyaNQuTJ0+2RIxEREQNH9dwGGVyS2XevHnQ6XQYNGgQHjx4gH79+sHW1hazZs3C1KlTLREjERERNXImJxwSiQRvvPEGZs+ejYyMDBQVFcHf3x9OTk6WiI+IiKhR4BoO42p9p1GZTAZ/f38xYyEiImq8eGtzo0xOOAYOHAiJ5OELWw4fPmxWQERERNT0mJxwdOvWzeC1RqNBamoqLly4gLCwMLHiIiIialzMbKmwwvEnq1atqvb9hQsXoqioyOyAiIiIGiW2VIwS7eFt48aNw5YtW8Q6HBERETUhoj2ePjExEXZ2dmIdjoiIqHFhhcMokxOOUaNGGbwWBAG3b99GcnIyIiMjRQuMiIioMeFlscaZnHAoFAqD11KpFO3bt8fixYsxePBg0QIjIiKipsOkhEOr1eLf//43OnfujGbNmlkqJiIiImpiTFo0amVlhcGDB/OpsERERH/GZ6kYZfJVKp06dcL169ctEQsREVGjVbmGw5ytKTM54Xj77bcxa9YsxMXF4fbt21Cr1QYbERER0Z/VeA3H4sWL8frrr2Po0KEAgOHDhxvc4lwQBEgkEmi1WvGjJCIiagyaeJXCHDVOOBYtWoRXXnkFR44csWQ8REREjRPvw2FUjRMOQaj4SvTv399iwRAREVHTZNJlscaeEktERPRXxht/GWdSwvHYY489MunIz883KyAiIqJGiS0Vo0xKOBYtWlTlTqNEREREj2JSwjF27Fi4u7tbKhYiIqJGiy0V42qccHD9BhERkRFsqRhV4xt/VV6lQkRERGSqGlc4dDqdJeMgIiJq3FjhMMrkx9MTERFRVVzDYRwTDiIiIjGwwmGUyQ9vIyIiIjIVKxxERERiYIXDKCYcREREIuAaDuPYUiEiIiKLY4WDiIhIDGypGMWEg4iISARsqRjHlgoRERFZHCscREREYmBLxShWOIiIiMQgiLCZKCEhAcOGDYNKpYJEIsHu3bsNQxIELFiwAJ6enrC3t0dQUBCuXr1qMCY/Px+hoaGQy+VwcXFBeHg4ioqKDMacO3cOffv2hZ2dHby8vLBs2TKTY2XCQURE1EgVFxeja9euWL9+fbX7ly1bhrVr1yI6OhpJSUlwdHREcHAwSkpK9GNCQ0Nx8eJFxMfHIy4uDgkJCZg0aZJ+v1qtxuDBg+Hj44OUlBQsX74cCxcuxKZNm0yKlS0VIiIiEUj+fzNnvqmGDBmCIUOGVLtPEASsXr0ab775JkaMGAEA2LZtGzw8PLB7926MHTsWaWlpOHDgAM6cOYMePXoAANatW4ehQ4dixYoVUKlUiI2NRVlZGbZs2QKZTIaOHTsiNTUVK1euNEhMHoUVDiIiIjGI1FJRq9UGW2lpaa3CyczMRG5uLoKCgvTvKRQK9OrVC4mJiQCAxMREuLi46JMNAAgKCoJUKkVSUpJ+TL9+/SCTyfRjgoODkZ6ejnv37tU4HiYcREREIqi8LNacDQC8vLygUCj0W1RUVK3iyc3NBQB4eHgYvO/h4aHfl5ubC3d3d4P91tbWcHV1NRhT3TH++Bk1wZYKERFRA5KTkwO5XK5/bWtrW4/RiIcVDiIiIjGI1FKRy+UGW20TDqVSCQDIy8szeD8vL0+/T6lU4s6dOwb7y8vLkZ+fbzCmumP88TNqggkHERGRWOrwkthH8fX1hVKpxKFDh/TvqdVqJCUlITAwEAAQGBiIgoICpKSk6MccPnwYOp0OvXr10o9JSEiARqPRj4mPj0f79u3RrFmzGsfDhIOIiKiRKioqQmpqKlJTUwFULBRNTU1FdnY2JBIJpk+fjrfffht79uzB+fPn8eKLL0KlUmHkyJEAAD8/P4SEhGDixIk4ffo0Tp48iYiICIwdOxYqlQoA8MILL0AmkyE8PBwXL17Ezp07sWbNGsycOdOkWLmGg4iISAT18SyV5ORkDBw4UP+6MgkICwtDTEwM5syZg+LiYkyaNAkFBQXo06cPDhw4ADs7O/2c2NhYREREYNCgQZBKpRg9ejTWrl2r369QKHDw4EFMmTIFAQEBaNGiBRYsWGDSJbEV5ycITfxmqrWnVquhUChw/IIKTs4sBlHTNK/L4PoOgchiyoUyHFJ/hsLCQoOFmGKq/F3RaeJSWMnsHj3hIbRlJbiw+b8WjbU+8bcoERERWRxbKkRERCLg4+mNY8JBREQkBj4t1ii2VIiIiMjiWOEgIiISAVsqxjHhICIiEgNbKkYx4SAiIhIDEw6juIaDiIiILI4VDiIiIhFwDYdxTDiIiIjEwJaKUWypEBERkcWxwkFERCQCiSBAYsbjycyZ2xgw4SAiIhIDWypGsaVCREREFscKBxERkQh4lYpxTDiIiIjEwJaKUWypEBERkcWxwkFERCQCtlSMY8JBREQkBrZUjGLCQUREJAJWOIzjGg4iIiKyOFY4iIiIxMCWilFMOIiIiETS1Nsi5mBLhYiIiCyOFQ4iIiIxCELFZs78JowJBxERkQh4lYpxbKkQERGRxbHCQUREJAZepWIUEw4iIiIRSHQVmznzmzK2VIiIiMji6rXCIQgC/vOf/+DLL7/EvXv38OOPP6Jbt24PHZ+VlQVfX99HjqP6dT3JGUc3qXDzvCPUd2QI25iOTsH39Ptnt36i2nlPz7+BAf+5jfwcW3y/riUyTslx/64Mco8yPD7yFwyKuAlrWUXNMT/HFlF9u1c5RsTXF+DzeJFlToyoGqERNxAakW3wXs51e/xnaA8AQLMWZQifnYluve/BwVGLnzPtsXOjN04ebAEA6Pz3Ary37Xy1x37tuW64esHZsidA4mFLxah6TTgOHDiAmJgYHD16FG3atEGLFi3qMxwSSdkDK6j8itHzn3ew7ZX2VfZHnk4xeJ1+1AX/m9sGnYfkAwDuXLODoANGL81Ei9YlyE13wJfzfVH2mxTD3jD8wT4p9hI82v2mf+3YrNwCZ0RkXNYVB7zxUmf9a225RP/v199Lh6NzORa/2hHqe9YY8MxdzFuVhtee647raU5I+1GO0D69DI43ftoNdA0swNULTnV2DmQ+XqViXL0mHNeuXYOnpyd69+5dn2GQyDoMLECHgQUP3S931xi8vhjfDH8LVKO5d2nF/AGF6DCgUL+/uXcp7l63Q+JnHlUSDgeX8irHI6prWq0E936RVbvPr5sa6xe1xZXzFZWKHdHeGDnhJtp1LML1NCeUa6QGc62sdXhi0K/Y+5kKgKTaY1IDxftwGFVvazgmTJiAqVOnIjs7GxKJBK1bt8aBAwfQp08fuLi4oHnz5njmmWdw7dq1hx7j3r17CA0NhZubG+zt7dGuXTts3bpVvz8nJwdjxoyBi4sLXF1dMWLECGRlZdXB2VFN3b9rg7QjLvj7v+4YHVdy3woOLlWrFzET22NhQADWP+ePi/HNLBUmkVEtfX7DpwlJ+Dj+DGYvvww3zxL9vrRUOfoN/QVOCg0kEgH9ht6BTKbDudOKao/1xJP5cHbR4ODXHnUVPlGdqLeEY82aNVi8eDFatWqF27dv48yZMyguLsbMmTORnJyMQ4cOQSqV4tlnn4VOV/3S3cjISFy6dAn79+9HWloaNmzYoG/LaDQaBAcHw9nZGcePH8fJkyfh5OSEkJAQlJWVVXu80tJSqNVqg40sK/mrFrB11KFTcP5Dx/ySZYuTnyjxxAu/JyW2jlo882YWxq+/ivAtl+Hb4z4+mfQYkw6qc+k/OWPl/McQ+XInrF/UFh6tSrD8s3Owd6xIkKOm+8HKWocvkn7AN+dOYuqiDCyZ6o/b2fbVHm/w6FycPdEMv+bZ1uVpkAgqWyrmbE1ZvbVUFAoFnJ2dYWVlBaVSCQAYPXq0wZgtW7bAzc0Nly5dQqdOnaocIzs7G927d0ePHhWLs1q3bq3ft3PnTuh0Onz00UeQSCrKklu3boWLiwuOHj2KwYMHVzleVFQUFi1aJNYpUg2c+cIdj4/8BTZ21f9PK8y1wUdhfugyNB+9nv894XB0LUf/l3P1r726FqPwjgzHNnmi41P3qjsUkUUkH3fV/zvriiPSf3JGzOHT6BvyCw5+pcT417Lg5KzF/AmdoL5ng8CgXzF/VRrmjOuKrCuOBsdq7lGKx/vcw7sz/Or6NEgMXDRqVIO6LPbq1at4/vnn0aZNG8jlcn0CkZ2dXe34yZMnY8eOHejWrRvmzJmDU6dO6ff99NNPyMjIgLOzM5ycnODk5ARXV1eUlJQ8tE0zf/58FBYW6recnBzRz5F+d/20M+5et39oO6UwzwbRz/vDJ+A+Rkddf+TxvLsV4ZcsO7HDJDJJ8X1r3Myyh8rnNyi9fsPwcbex6o12+OmHZshMd8L29T64esEZz7xwq8rcwaPycL/ABj8cdq3myESNW4O68dewYcPg4+ODzZs3Q6VSQafToVOnTg9tgQwZMgQ3btzAt99+i/j4eAwaNAhTpkzBihUrUFRUhICAAMTGxlaZ5+bmVu3xbG1tYWvLMmZdOb3THa06F0Hl/6DKvsLcimSjVadi/Gv5NUhrkBrfuuTABaRU7+wctPD0KsHhPTLY2Ve0gwWd4eJPnQ6QVPmeFhA0Kg+HvnGHtrxB/S1INcSrVIxrMAnHr7/+ivT0dGzevBl9+/YFAJw4ceKR89zc3BAWFoawsDD07dsXs2fPxooVK/D4449j586dcHd3h1wut3T49AelxVKDSkN+ji1uXnSAg0s5mrWsSB5L7lvh3LeuGPbGjSrzC3NtED3WHy4ty/DMGzdQ9KuNfl9lQpH8ZQtY2Qho2bEYAHD+O1ec+cId/3z30ZUQIjGFz7mOpCOuuHPLDs3dyzAu4gZ0OuBonNv/VzvsMHXRVXy0rA3UBdYIDPoV3XsXYOErHQ2O0/WJAnh6leC7/ynr6UzIbLxKxagGk3A0a9YMzZs3x6ZNm+Dp6Yns7GzMmzfP6JwFCxYgICAAHTt2RGlpKeLi4uDnV9H7DA0NxfLlyzFixAj94tQbN27g66+/xpw5c9CqVau6OK2/pJ/POSH6eX/9671vtwYABIy+i7HvV7SzUvc2BwSg2/Bfq8y/ctwFv2TZ45cse7z9RIDBvuVZP+j//f26lrh30xZW1gLc2pRg3AdX0WXowxefEllCC49SzH0/HXIXDQrzbXAxRY4Z/+oG9b2KS13f+k8n/Pv1TLy14SLsHbS4lW2PlfMeQ3KCYdsk+Lk8XDorx8+ZDvVxGkQW12ASDqlUih07dmDatGno1KkT2rdvj7Vr12LAgAEPnSOTyTB//nxkZWXB3t4effv2xY4dOwAADg4OSEhIwNy5czFq1Cjcv38fLVu2xKBBg1jxsLC/BaoNEoPqPPHCHYOrTv6o5z/vouc/7xqd3+O5X9DjuV9qHSORWN573fgCz1s37PHONH+jYwBg2awOYoVE9YQtFeMkgtDEazhmUKvVUCgUOH5BBSdn9lSpaZrXpeoVW0RNRblQhkPqz1BYWGixPzYrf1cEhiyGtU3tF66Xa0qQeGCBRWOtT/wtSkRERBbXYFoqREREjRlbKsYx4SAiIhKDTqjYzJnfhDHhICIiEgPvNGoU13AQERGRxTHhICIiEoEEZj68zcTP02q1iIyMhK+vL+zt7fG3v/0NS5YswR8vPhUEAQsWLICnpyfs7e0RFBSEq1evGhwnPz8foaGhkMvlcHFxQXh4OIqKisz/gvwJEw4iIiIxVN5p1JzNBO+99x42bNiADz74AGlpaXjvvfewbNkyrFu3Tj9m2bJlWLt2LaKjo5GUlARHR0cEBwejpKREPyY0NBQXL15EfHw84uLikJCQgEmTJon2ZanENRxERESN0KlTpzBixAg8/fTTACqemP7555/j9OnTACqqG6tXr8abb76JESNGAAC2bdsGDw8P7N69G2PHjkVaWhoOHDiAM2fO6J+8vm7dOgwdOhQrVqyASqUSLV5WOIiIiERgVjvlD5fUqtVqg620tLTaz+vduzcOHTqEK1euAKh4SvqJEycwZMgQAEBmZiZyc3MRFBSkn6NQKNCrVy8kJiYCABITE+Hi4qJPNgAgKCgIUqkUSUlJon59WOEgIiISg0hXqXh5eRm8/dZbb2HhwoVVhs+bNw9qtRodOnSAlZUVtFot3nnnHYSGhgIAcnNzAQAeHh4G8zw8PPT7cnNz4e7ubrDf2toarq6u+jFiYcJBRETUgOTk5Bjc2tzW1rbacV988QViY2Oxfft2dOzYEampqZg+fTpUKhXCwsLqKtwaY8JBREQkAokgQGLG48kq58rl8ho9S2X27NmYN28exo4dCwDo3Lkzbty4gaioKISFhUGpVAIA8vLy4OnpqZ+Xl5eHbt26AQCUSiXu3DF8kGZ5eTny8/P188XCNRxERERi0ImwmeDBgweQSg1/jVtZWUGnqziQr68vlEolDh06pN+vVquRlJSEwMBAAEBgYCAKCgqQkpKiH3P48GHodDr06tXLtIAegRUOIiKiRmjYsGF455134O3tjY4dO+LHH3/EypUr8dJLLwEAJBIJpk+fjrfffhvt2rWDr68vIiMjoVKpMHLkSACAn58fQkJCMHHiRERHR0Oj0SAiIgJjx44V9QoVgAkHERGRKMRqqdTUunXrEBkZiVdffRV37tyBSqXCf/7zHyxYsEA/Zs6cOSguLsakSZNQUFCAPn364MCBA7Czs9OPiY2NRUREBAYNGgSpVIrRo0dj7dq1tT6Ph5EIghlfnSZOrVZDoVDg+AUVnJzZfaKmaV6XwfUdApHFlAtlOKT+DIWFhTVaF1Eblb8r+vVZAGtru0dPeIjy8hIknFhs0VjrEyscREREYqjF3UKrzG/C+Gc7ERERWRwrHERERCL4491Cazu/KWPCQUREJAa2VIxiS4WIiIgsjhUOIiIiEUh0FZs585syJhxERERiYEvFKLZUiIiIyOJY4SAiIhKDSI+nb6qYcBAREYmgrm9t3tiwpUJEREQWxwoHERGRGLho1CgmHERERGIQAJhzaWvTzjeYcBAREYmBaziM4xoOIiIisjhWOIiIiMQgwMw1HKJF0iAx4SAiIhIDF40axZYKERERWRwrHERERGLQAZCYOb8JY8JBREQkAl6lYhxbKkRERGRxrHAQERGJgYtGjWLCQUREJAYmHEaxpUJEREQWxwoHERGRGFjhMIoJBxERkRh4WaxRTDiIiIhEwMtijeMaDiIiIrI4VjiIiIjEwDUcRjHhICIiEoNOACRmJA26pp1wsKVCREREFscKBxERkRjYUjGKCQcREZEozEw40LQTDrZUiIiIyOJY4SAiIhIDWypGMeEgIiISg06AWW0RXqVCREREZB5WOIiIiMQg6Co2c+Y3YUw4iIiIxMA1HEYx4SAiIhID13AYxTUcREREZHGscBAREYmBLRWjmHAQERGJQYCZCYdokTRIbKkQERGRxbHCQUREJAa2VIxiwkFERCQGnQ6AGffS0DXt+3CwpUJERNRI3bx5E+PGjUPz5s1hb2+Pzp07Izk5Wb9fEAQsWLAAnp6esLe3R1BQEK5evWpwjPz8fISGhkIul8PFxQXh4eEoKioSPVYmHERERGKobKmYs5ng3r17+Mc//gEbGxvs378fly5dwvvvv49mzZrpxyxbtgxr165FdHQ0kpKS4OjoiODgYJSUlOjHhIaG4uLFi4iPj0dcXBwSEhIwadIk0b4sldhSISIiEkMdr+F477334OXlha1bt+rf8/X1/cPhBKxevRpvvvkmRowYAQDYtm0bPDw8sHv3bowdOxZpaWk4cOAAzpw5gx49egAA1q1bh6FDh2LFihVQqVS1P58/YYWDiIioAVGr1QZbaWlpteP27NmDHj164J///Cfc3d3RvXt3bN68Wb8/MzMTubm5CAoK0r+nUCjQq1cvJCYmAgASExPh4uKiTzYAICgoCFKpFElJSaKeFxMOIiIiMegE8zcAXl5eUCgU+i0qKqraj7t+/To2bNiAdu3a4bvvvsPkyZMxbdo0fPLJJwCA3NxcAICHh4fBPA8PD/2+3NxcuLu7G+y3traGq6urfoxY2FIhIiISgSDoIJjxxNfKuTk5OZDL5fr3bW1tqx2v0+nQo0cPLF26FADQvXt3XLhwAdHR0QgLC6t1HJbCCgcREZEYBDOrG/+/hkMulxtsD0s4PD094e/vb/Cen58fsrOzAQBKpRIAkJeXZzAmLy9Pv0+pVOLOnTsG+8vLy5Gfn68fIxYmHERERI3QP/7xD6Snpxu8d+XKFfj4+ACoWECqVCpx6NAh/X61Wo2kpCQEBgYCAAIDA1FQUICUlBT9mMOHD0On06FXr16ixsuWChERkRgEMx9Pb+JVKjNmzEDv3r2xdOlSjBkzBqdPn8amTZuwadMmAIBEIsH06dPx9ttvo127dvD19UVkZCRUKhVGjhwJoKIiEhISgokTJyI6OhoajQYREREYO3asqFeoAEw4iIiIxKHTARIz7hZq4vqPnj17YteuXZg/fz4WL14MX19frF69GqGhofoxc+bMQXFxMSZNmoSCggL06dMHBw4cgJ2dnX5MbGwsIiIiMGjQIEilUowePRpr166t/Xk8hEQQmvjN282gVquhUChw/IIKTs7sPlHTNK/L4PoOgchiyoUyHFJ/hsLCQoOFmGKq/F0xyDkU1hJZrY9TLpTh0P1Yi8Zan1jhICIiEkMdt1QaGyYcREREIhB0OghmtFTMuaS2MWCfgIiIiCyOFQ4iIiIxsKViFBMOIiIiMegEQMKE42HYUiEiIiKLY4WDiIhIDIIAwJz7cDTtCgcTDiIiIhEIOgGCGS2Vpn5bLCYcREREYhB0MK/CwctiiYiIiMzCCgcREZEI2FIxjgkHERGRGNhSMYoJhxGV2WZxUdP+JqC/tnKhrL5DILKYyu/vuqgelENj1n2/yqERL5gGiAmHEffv3wcAhDyRW8+REFnSZ/UdAJHF3b9/HwqFwiLHlslkUCqVOJH7rdnHUiqVkMlq/8TZhoyPpzdCp9Ph1q1bcHZ2hkQiqe9w/hLUajW8vLyQk5PTJB/PTMTv8bolCALu378PlUoFqdRy10mUlJSgrMz8aqFMJoOdnZ0IETU8rHAYIZVK0apVq/oO4y9JLpfzhzE1afwerzuWqmz8kZ2dXZNNFMTCy2KJiIjI4phwEBERkcUx4aAGxdbWFm+99RZsbW3rOxQii+D3OP1VcdEoERERWRwrHERERGRxTDiIiIjI4phwEBERkcUx4SAiMpEgCJg0aRJcXV0hkUiQmppqdHxWVlaNxhE1ZUw4yKIGDBiA6dOn13cYRKI6cOAAYmJiEBcXh9u3b6NTp071HRJRg8c7jVK9EgQBWq0W1tb8VqTG49q1a/D09ETv3r3rOxSiRoMVDrKYCRMm4NixY1izZg0kEgkkEgliYmIgkUiwf/9+BAQEwNbWFidOnMCECRMwcuRIg/nTp0/HgAED9K91Oh2ioqLg6+sLe3t7dO3aFV9++WXdnhT95U2YMAFTp05FdnY2JBIJWrdujQMHDqBPnz5wcXFB8+bN8cwzz+DatWsPPca9e/cQGhoKNzc32Nvbo127dti6dat+f05ODsaMGQMXFxe4urpixIgRyMrKqoOzI7IcJhxkMWvWrEFgYCAmTpyI27dv4/bt2/Dy8gIAzJs3D++++y7S0tLQpUuXGh0vKioK27ZtQ3R0NC5evIgZM2Zg3LhxOHbsmCVPg8jAmjVrsHjxYrRq1Qq3b9/GmTNnUFxcjJkzZyI5ORmHDh2CVCrFs88+C51OV+0xIiMjcenSJezfvx9paWnYsGEDWrRoAQDQaDQIDg6Gs7Mzjh8/jpMnT8LJyQkhISGiPByMqL6wjk0Wo1AoIJPJ4ODgAKVSCQC4fPkyAGDx4sV46qmnanys0tJSLF26FN9//z0CAwMBAG3atMGJEyewceNG9O/fX/wTIKqGQqGAs7MzrKys9N/Xo0ePNhizZcsWuLm54dKlS9Wu78jOzkb37t3Ro0cPAEDr1q31+3bu3AmdToePPvpI/5TqrVu3wsXFBUePHsXgwYMtdGZElsWEg+pF5Q/amsrIyMCDBw+qJCllZWXo3r27mKERmezq1atYsGABkpKS8Msvv+grG9nZ2dUmHJMnT8bo0aNx9uxZDB48GCNHjtSvB/npp5+QkZEBZ2dngzklJSVG2zREDR0TDqoXjo6OBq+lUin+fJd9jUaj/3dRUREAYN++fWjZsqXBOD6TgurbsGHD4OPjg82bN0OlUkGn06FTp04PbYEMGTIEN27cwLfffov4+HgMGjQIU6ZMwYoVK1BUVISAgADExsZWmefm5mbpUyGyGCYcZFEymQxarfaR49zc3HDhwgWD91JTU2FjYwMA8Pf3h62tLbKzs9k+oQbl119/RXp6OjZv3oy+ffsCAE6cOPHIeW5ubggLC0NYWBj69u2L2bNnY8WKFXj88cexc+dOuLu7Qy6XWzp8ojrDRaNkUa1bt0ZSUhKysrIMSs1/9uSTTyI5ORnbtm3D1atX8dZbbxkkIM7Ozpg1axZmzJiBTz75BNeuXcPZs2exbt06fPLJJ3V1OkRVNGvWDM2bN8emTZuQkZGBw4cPY+bMmUbnLFiwAN988w0yMjJw8eJFxMXFwc/PDwAQGhqKFi1aYMSIETh+/DgyMzNx9OhRTJs2DT///HNdnBKRRTDhIIuaNWsWrKys4O/vDzc3N2RnZ1c7Ljg4GJGRkZgzZw569uyJ+/fv48UXXzQYs2TJEkRGRiIqKgp+fn4ICQnBvn374OvrWxenQlQtqVSKHTt2ICUlBZ06dcKMGTOwfPlyo3NkMhnmz5+PLl26oF+/frCyssKOHTsAAA4ODkhISIC3tzdGjRoFPz8/hIeHo6SkhBUPatT4eHoiIiKyOFY4iIiIyOKYcBAREZHFMeEgIiIii2PCQURERBbHhIOIiIgsjgkHERERWRwTDiIiIrI4JhxEDdyECRMwcuRI/esBAwZg+vTpdR7H0aNHIZFIUFBQ8NAxEokEu3fvrvExFy5ciG7dupkVV1ZWFiQSCVJTU806DhFZFhMOolqYMGECJBIJJBIJZDIZ2rZti8WLF6O8vNzin/31119jyZIlNRpbkySBiKgu8OFtRLUUEhKCrVu3orS0FN9++y2mTJkCGxsbzJ8/v8rYsrIyyGQyUT7X1dVVlOMQEdUlVjiIasnW1hZKpRI+Pj6YPHkygoKCsGfPHgC/t0HeeecdqFQqtG/fHgCQk5ODMWPGwMXFBa6urhgxYgSysrL0x9RqtZg5cyZcXFzQvHlzzJkzB39++sCfWyqlpaWYO3cuvLy8YGtri7Zt2+Ljjz9GVlYWBg4cCKDiAWMSiQQTJkwAAOh0OkRFRcHX1xf29vbo2rUrvvzyS4PP+fbbb/HYY4/B3t4eAwcONIizpubOnYvHHnsMDg4OaNOmDSIjI6HRaKqM27hxI7y8vODg4IAxY8agsLDQYP9HH30EPz8/2NnZoUOHDvjwww9NjoWI6hcTDiKR2Nvbo6ysTP/60KFDSE9PR3x8POLi4qDRaBAcHAxnZ2ccP34cJ0+ehJOTE0JCQvTz3n//fcTExGDLli04ceIE8vPzsWvXLqOf++KLL+Lzzz/H2rVrkZaWho0bN8LJyQleXl746quvAADp6em4ffs21qxZAwCIiorCtm3bEB0djYsXL2LGjBkYN24cjh07BqAiMRo1ahSGDRuG1NRUvPzyy5g3b57JXxNnZ2fExMTg0qVLWLNmDTZv3oxVq1YZjMnIyMAXX3yBvXv34sCBA/jxxx/x6quv6vfHxsZiwYIFeOedd5CWloalS5ciMjKSTwkmamwEIjJZWFiYMGLECEEQBEGn0wnx8fGCra2tMGvWLP1+Dw8PobS0VD/n008/Fdq3by/odDr9e6WlpYK9vb3w3XffCYIgCJ6ensKyZcv0+zUajdCqVSv9ZwmCIPTv31947bXXBEEQhPT0dAGAEB8fX22cR44cEQAI9+7d079XUlIiODg4CKdOnTIYGx4eLjz//POCIAjC/PnzBX9/f4P9c+fOrXKsPwMg7Nq166H7ly9fLgQEBOhfv/XWW4KVlZXw888/69/bv3+/IJVKhdu3bwuCIAh/+9vfhO3btxscZ8mSJUJgYKAgCIKQmZkpABB+/PHHh34uEdU/ruEgqqW4uDg4OTlBo9FAp9PhhRdewMKFC/X7O3fubLBu46effkJGRgacnZ0NjlNSUoJr166hsLAQt2/fRq9evfT7rK2t0aNHjyptlUqpqamwsrJC//79axx3RkYGHjx4gKeeesrg/bKyMnTv3h0AkJaWZhAHAAQGBtb4Myrt3LkTa9euxbVr11BUVITy8vIqj1j39vZGy5YtDT5Hp9MhPT0dzs7OuHbtGsLDwzFx4kT9mPLycigUCpPjIaL6w4SDqJYGDhyIDRs2QCaTQaVSwdra8L+To6OjweuioiIEBAQgNja2yrHc3NxqFYO9vb3Jc4qKigAA+/btM/hFD1SsSxFLYmIiQkNDsWjRIgQHB0OhUGDHjh14//33TY518+bNVRIgKysr0WIlIstjwkFUS46Ojmjbtm2Nxz/++OPYuXMn3N3dq/yVX8nT0xNJSUno168fgIq/5FNSUvD4449XO75z587Q6XQ4duwYgoKCquyvrLBotVr9e/7+/rC1tUV2dvZDKyN+fn76BbCVfvjhh0ef5B+cOnUKPj4+eOONN/Tv3bhxo8q47Oxs3Lp1CyqVSv85UqkU7du3h4eHB1QqFa5fv47Q0FCTPp+IGhYuGiWqI6GhoWjRogVGjBiB48ePIzMzE0ePHsW0adPw888/AwBee+01vPvuu9i9ezcuX76MV1991eg9NFq3bo2wsDC89NJL2L17t/6YX3zxBQDAx8cHEokEcXFxuHv3LoqKiuDs7IxZs2ZhxowZ+OSTT3Dt2jWcPXsW69at0y/EfOWVV3D16lXMnj0b6enp2L59O2JiYkw633bt2iE7Oxs7duzAtWvXsHbt2moXwNrZ2SEsLAw//fQTjh8/jmnTpmHMmDFQKpUAgEWLFiEqKgpr167FlStXcP78eWzduhUrV640KR4iql9MOIjqiIODAxISEuDt7Y1Ro0bBz88P4eHhKCkp0Vc8Xn/9dYwfPx5hYWEIDAyEs7Mznn32WaPH3bBhA5577jm8+uqr6NChAyZOnIji4mIAQMuWLbFo0SLMmzcPHh4eiIiIAAAsWbIEkZGRiIqKgp+fH0JCQrBv3z74+voCqFhX8dVXX2H37t3o2rUroqOjsXTpUpPOd/jw4ZgxYwYiIiLQrVs3nDp1CpGRkVXGtW3bFqNGjcLQoUMxePBgdOnSxeCy15dffhkfffQRtm7dis6dO6N///6IiYnRx0pEjYNEeNhqNCIiIiKRsMJBREREFseEg4iIiCyOCQcRERFZHBMOIiIisjgmHERERGRxTDiIiIjI4phwEBERkcUx4SAiIiKLY8JBREREFseEg4iIiCyOCQcRERFZHBMOIiIisrj/A6Jhn24EEZeCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51.57, 47.94)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51.57, 47.92)\n"
     ]
    }
   ],
   "source": [
    "print(check_score(weibo[\"target\"], predictions_soft))\n",
    "print(check_score(weibo[\"target\"], predictions_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/trial, best loss: 0.506426735218509]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.37s/trial, best loss: 0.33676092544987146]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.46s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.26s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.71s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.81s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.55s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.22s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.61s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.55s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.29s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.21s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.19s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.16s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.17s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.20s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.44s/trial, best loss: 0.3316195372750642]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.46s/trial, best loss: 0.3316195372750642]\n",
      "{'learner': SVC(C=1.27806368437018, coef0=0.48726712591817056, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006615201746896151), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/trial, best loss: 0.49382716049382713]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.67s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.38s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.40s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.40s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.39s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.49s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.27s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.71s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.47s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.70s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.42s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.45s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.52s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.50s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.60s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.74s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.78s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.26s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.34s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.23s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.46s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 25/25 [00:05<00:00,  5.37s/trial, best loss: 0.4246913580246914]\n",
      "{'learner': SVC(C=0.9657655830484548, coef0=0.6786722363807116,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=1.4737120975701307e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.3443396226415094]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.96s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.88s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.94s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "{'learner': SVC(C=1.174510237626359, coef0=0.02669401762935497,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.009299695485933401), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.78s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.53s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.70s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.60s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.78s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.71s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.44s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.59s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.63s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.53s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.27s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 16/16 [00:05<00:00,  5.49s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.29s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.62s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 19/19 [00:04<00:00,  4.79s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.59s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.84s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.32s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.78s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.63s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.44s/trial, best loss: 0.40821256038647347]\n",
      "{'learner': SVC(C=0.9227940526363324, coef0=0.7927791220638721, degree=1, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0047687362414503606), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.42690058479532167]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.10s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.85s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.3801169590643275]\n",
      "{'learner': SVC(C=1.1079814075167367, coef0=0.8245707521169836,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=2.799872522153208e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.34693877551020413]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.86s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.84s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.80s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.83s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "{'learner': SVC(C=0.9257408490290698, coef0=0.41311745281537826,\n",
      "    decision_function_shape='ovo', kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=0.006917915910103056), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.90s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.0980392156862745]\n",
      "{'learner': SVC(C=0.8398322802689391, coef0=0.9227589466765949,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=3.358917433194155e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.00s/trial, best loss: 0.37914691943127965]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.85s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.99s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.92s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.91s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.92s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "{'learner': SVC(C=0.7540885291669677, coef0=0.7528619691414311,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, tol=1.0681087675420041e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.83s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.88s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.86s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.88s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.005586592178770999]\n",
      "{'learner': SVC(C=0.6079746578511527, coef0=0.11574484436091592,\n",
      "    decision_function_shape='ovo', degree=5, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.0003660128763222489), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "{'learner': SVC(C=0.770276256541704, coef0=0.8734355361758418, degree=1, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42,\n",
      "    tol=0.0034900441487901706), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.057376398293643, coef0=0.4632876803061109,\n",
      "    decision_function_shape='ovo', degree=5, kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=1.3789159332712913e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.4]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.4]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.4]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.37142857142857144]\n",
      "{'learner': SVC(C=1.0831080076863404, coef0=0.316185484275032, kernel='poly',\n",
      "    probability=True, random_state=42, tol=9.764195804613026e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0180836682609906, coef0=0.20588792776765352, degree=4, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42,\n",
      "    tol=0.0011333977367915522), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.48]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.42000000000000004]\n",
      "{'learner': SVC(C=1.3174914317906543, coef0=0.7010254690005955, degree=1, probability=True,\n",
      "    random_state=42, tol=0.0006737435001820457), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8863991547664496, coef0=0.4762849565334496, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006657527193216036), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 5375.09it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5347.30it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4563.92it/s]\n",
      " 33%|███▎      | 1/3 [12:29<24:58, 749.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.15625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.15625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.15625]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.15625]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.1945646294220587, coef0=0.7884022933921573, degree=1, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0005025238209911815), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.33999999999999997]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.26]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.26]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.26]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.26]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.26]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.24]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.96s/trial, best loss: 0.24]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.03s/trial, best loss: 0.24]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.24]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.95s/trial, best loss: 0.24]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.24]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.24]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.24]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.24]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "{'learner': SVC(C=0.6492912940993498, coef0=0.5441071721230211,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=6.834361122169257e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.23809523809523814]\n",
      "{'learner': SVC(C=0.8382306246268949, coef0=0.1803690144099015, degree=4, probability=True,\n",
      "    random_state=42, tol=0.0006357388371780233), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4943820224719101]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.4943820224719101]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2134831460674157]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.1910112359550562]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.78s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "{'learner': SVC(C=0.9357870759949558, coef0=0.8812821811553421, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.000697527292063522), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0550309647234999, coef0=0.12586013483651415,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.4616474472242081e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0029349581026352, coef0=0.8341480110132776,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    tol=6.702387659796514e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.38]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.14]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.14]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.14]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.14]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.14]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "{'learner': SVC(C=1.0620389180277778, coef0=0.029225219203634967, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=6.105606229249174e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "{'learner': SVC(C=0.5739737166730667, coef0=0.2585621879762716, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0006013771814293189), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.75s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.2962962962962963]\n",
      "{'learner': SVC(C=1.2705136171970062, coef0=0.5400803587482712, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.465830903553389e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.9453032431574453, coef0=0.6007505212540446,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=2.1979249406020847e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.92s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.08s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.92s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=0.8022419371773636, coef0=0.3728577272853363,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0007225168975079846), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=0.8345218023385902, coef0=0.8612891003431599,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, tol=7.146656516836443e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.8933232117455074, coef0=0.5719852675043511,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=0.00015489737340369154), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8452513408234731, coef0=0.9510009361774524, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.007109605847214362), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.0244418566405622, coef0=0.7524552152977808,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.008671256105803455), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Shopping\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=0.9027490213784626, coef0=0.9009048690863479,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.002082398998649251), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 5571.19it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6213.67it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5065.41it/s]\n",
      " 67%|██████▋   | 2/3 [24:06<11:58, 718.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.75s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "{'learner': SVC(C=1.0739993031808703, coef0=0.416689057344241,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0007512366343107693), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "{'learner': SVC(C=1.0106129084990836, coef0=0.9259986948470166, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=2.6061167280872727e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "{'learner': SVC(C=1.1349840539747738, coef0=0.22540388279634171,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=8.469028406795745e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.82s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "{'learner': SVC(C=1.3450905167851424, coef0=0.706298652560372, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0005204310494716461), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=1.3600985998300588, coef0=0.9577397780001515,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0003397762686307047), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.24]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.24]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.040000000000000036]\n",
      "{'learner': SVC(C=1.0549129681233322, coef0=0.23988649512904547, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0010371211656674854), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.07s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.9380684153137936, coef0=0.40053045674426, degree=5, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0007584402160608023), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.96s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.94s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.86s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.84s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.87s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.98s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "{'learner': SVC(C=1.2609631231136633, coef0=0.33740777295663926, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0010461527328453723), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.5625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.4375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.4375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.375]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "{'learner': SVC(C=1.0315806400436711, coef0=0.3308717648341267,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.007034405498861934), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.97s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.20s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.1102772816703703, coef0=0.45848872977822486, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=2.1697960991976383e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.89s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.94s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.120562506943213, coef0=0.2177396686039209, degree=5, probability=True,\n",
      "    random_state=42, tol=0.00026489988551958623), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.1825275975727285, coef0=0.9761729518584825, degree=5, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42,\n",
      "    tol=0.009792736878295684), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.150038096349518, coef0=0.6282824018315654, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0047396390412245875), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.800544497151287, coef0=0.13263043902140748, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.009867581817724826), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.076808603204328, coef0=0.965096967170564, degree=2, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00027473265677620127), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 5466.15it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6541.73it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 6223.86it/s]\n",
      "100%|██████████| 3/3 [35:05<00:00, 701.76s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/trial, best loss: 0.5136363636363637]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.90s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.79s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.87s/trial, best loss: 0.4772727272727273]\n",
      "{'learner': SVC(C=0.9902408249812638, coef0=0.12156199270367096,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00045155910532401663), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "{'learner': SVC(C=0.7136085040433904, coef0=0.48747808619366395,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', probability=True,\n",
      "    random_state=42, tol=0.00011788274422353139), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.55]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.55]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.55]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.525]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.525]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.525]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "{'learner': SVC(C=1.3766200869982947, coef0=0.5372880079150215, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0009084885622898456), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.3798882681564246]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.67s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.78s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.2737430167597765]\n",
      "{'learner': SVC(C=0.966099473809587, coef0=0.2398600586262697, degree=1, kernel='sigmoid',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=2.41754101616871e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.4482758620689655]\n",
      "{'learner': SVC(C=0.7596674069226144, coef0=0.7374776518119935,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, tol=0.0009731534599314168), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.181596039796485, coef0=0.9000207945440192, degree=4, probability=True,\n",
      "    random_state=42, tol=0.001272526113055135), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.3163904172390262, coef0=0.5599152283031321,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.002164113892036766), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4838709677419355]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.467741935483871]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.98s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.00s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.99s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.85s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.88s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.33870967741935487]\n",
      "{'learner': SVC(C=1.2213920692095193, coef0=0.5746683577070564,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.6855032004828986e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8184558750129268, coef0=0.538820867119558, degree=5, probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.4176057809663056e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.9818181818181818]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2909090909090909]\n",
      "{'learner': SVC(C=0.8610172308299733, coef0=0.22278476975059336,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0013140751222849442), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0925644179222571, coef0=0.4653535477535402, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0005872685422652758), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "{'learner': SVC(C=0.7276426586657265, coef0=0.9809266667602178,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00010439865792361638), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "{'learner': SVC(C=1.0811806468537133, coef0=0.7411559984150862,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.00011456860847060542), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 6042.76it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5872.48it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4765.43it/s]\n",
      " 33%|███▎      | 1/3 [09:21<18:42, 561.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "{'learner': SVC(C=1.0973347350416882, coef0=0.8146959543122512, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00020866131622642725), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.95s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.97s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.05s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.85s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.08s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "{'learner': SVC(C=0.8309466980369555, coef0=0.7462564439354765,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.002540178954143434), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=0.9918299805919085, coef0=0.028751298823087357,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0001641799004124282), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "{'learner': SVC(C=0.6845698620823486, coef0=0.5829835206007147,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0007016193070621238), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.025075498683294, coef0=0.3604506564046419,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, tol=4.375838053860454e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.90s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.99s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.85s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.97s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.1923076923076923]\n",
      "{'learner': SVC(C=1.0913418353305946, coef0=0.5584001473576362,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.009749224234551556), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.96s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0003502521229837, coef0=0.8018539595879638, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, tol=1.655617446329184e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.95s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.86s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "{'learner': SVC(C=0.7360887983885595, coef0=0.30755783313415963, degree=1, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0034674311163742384), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=0.8694698610777177, coef0=0.18959463421163147,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.268070022219199e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Sensitive Subjects/Other due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.91s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.12s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.94s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.1946223693358395, coef0=0.6411910581138591,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00043559422548918785), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.16s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8463355617960903, coef0=0.8375194175259746, degree=1, probability=True,\n",
      "    random_state=42, tol=0.00012253195457966962), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.5]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "{'learner': SVC(C=1.143654831462878, coef0=0.6128369207843704,\n",
      "    decision_function_shape='ovo', degree=2, kernel='sigmoid', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0022901877843015373), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=0.6568428862910083, coef0=0.42494678991564283,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00024138419907427888), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2699371173196583, coef0=0.020408215422609288,\n",
      "    decision_function_shape='ovo', kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=0.002266874195033649), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Shopping\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.09s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.80s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.0467746599276628, coef0=0.1608792540108338,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.0004193260884928869), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 6089.65it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6755.00it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5710.00it/s]\n",
      " 67%|██████▋   | 2/3 [20:28<10:23, 623.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.95s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.88s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.01s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.10s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.01s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.93s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=0.7026417007342285, coef0=0.7345482881735375, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.00875741934024043), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.00s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.92s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.1717656596961255, coef0=0.5731214871814254, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0006639095964708486), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.07s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8644753527772016, coef0=0.25395865614792945,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00817403429570748), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.92s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.83s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.95s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.77s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.86s/trial, best loss: 0.050000000000000044]\n",
      "{'learner': SVC(C=1.0778675653060408, coef0=0.296421671266788, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.905793243720779e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.821195441662391, coef0=0.9583351928177092,\n",
      "    decision_function_shape='ovo', degree=1, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0003837521871284174), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.01s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.96s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.1333333333333333]\n",
      "{'learner': SVC(C=1.2659932834237202, coef0=0.444864129767393, probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.4148634983954097e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0414631976494435, coef0=0.6508710734520677,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006283629427111075), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.7945079944947862, coef0=0.2949425551562904,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.004813427310731593), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0339729934507316, coef0=0.6514424963305195,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0005460029755411147), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Sensitive Subjects/Other due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8690534124790918, coef0=0.4762509472326891, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0023841900823015913), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 1.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.94s/trial, best loss: 1.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 1.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 1.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  2.00s/trial, best loss: 1.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 1.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.13s/trial, best loss: 1.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 1.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 1.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 1.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.87s/trial, best loss: 1.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 1.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 1.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 1.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.90s/trial, best loss: 1.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 1.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 1.0]\n",
      "{'learner': SVC(C=0.7837025169471417, coef0=0.07992371875603121, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=5.421404725167397e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2380696262460873, coef0=0.9468190026744151,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', probability=True,\n",
      "    random_state=42, tol=0.00019134297199107587), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [29:39<10:23, 623.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "error training Sports svm, skipping\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4885.76it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6141.91it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5726.74it/s]\n",
      "100%|██████████| 3/3 [29:40<00:00, 593.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.63s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.52s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.79s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.16s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.41s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.28s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.82s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.61s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.42s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.28s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.62s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.67s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.54s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.45s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.47s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.21s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.17s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.78s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.54s/trial, best loss: 0.3256410256410256]\n",
      "{'learner': SVC(C=1.4850977719052936, coef0=0.7213847427709724,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0003521601209020623), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.61s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.59s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.58s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.72s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.64s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.93s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.86s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.70s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.42s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.71s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.78s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.51s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.87s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.89s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.57s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.54s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.49s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.31s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.47s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.53s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.32s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.60s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.50s/trial, best loss: 0.4156479217603912]\n",
      "{'learner': SVC(C=1.1200050163118433, coef0=0.994496830106449, degree=5, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0010135904438530305), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.96s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.07s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.10s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  2.00s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.00s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.19s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.01s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.17s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.73s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.00s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.12s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.09s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.99s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.19s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.39s/trial, best loss: 0.27314814814814814]\n",
      "{'learner': SVC(C=1.1708437379896266, coef0=0.485690543308848, gamma='auto',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00011814792103229369), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/trial, best loss: 0.4326923076923077]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.89s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.01s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.74s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.63s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.79s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.88s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.51s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.56s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.64s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.59s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.64s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.36s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.98s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.73s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.56s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 18/18 [00:05<00:00,  5.70s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.60s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.51s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.40s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.62s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.70s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.49s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.83s/trial, best loss: 0.38221153846153844]\n",
      "{'learner': SVC(C=1.1626704608976373, coef0=0.9482855293141186,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.006293009855243045), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4819277108433735]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.87s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.93s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 18/18 [00:01<00:00,  2.00s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.03s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.05s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.11s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.02s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.90s/trial, best loss: 0.40963855421686746]\n",
      "{'learner': SVC(C=1.1447870773999322, coef0=0.9663254573708002,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0010246783232766106), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.2864321608040201]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.2864321608040201]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.11s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.17s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.97s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.93s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.06s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.10s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.11s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.96s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.92s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.03s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.18s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.06s/trial, best loss: 0.27638190954773867]\n",
      "{'learner': SVC(C=1.2469151352914385, coef0=0.811105799135416, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0029710726635458827), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.77s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "{'learner': SVC(C=1.044399647885405, coef0=0.8816520053654071,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    tol=5.868767919848203e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.11s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.10s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.80s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.02s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.89s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.96s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.28971962616822433]\n",
      "{'learner': SVC(C=0.9989572336743652, coef0=0.5557713973821182,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=1.2870730925494057e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "{'learner': SVC(C=1.2157804241037837, coef0=0.567975708674522, degree=5, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42,\n",
      "    tol=0.0003333890435284616), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.8529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.8529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "{'learner': SVC(C=0.9605745182657707, coef0=0.5116331451080922, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00173690406830319), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.574468085106383]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.5319148936170213]\n",
      "{'learner': SVC(C=1.500782150948154, coef0=0.45076475389230797, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0026451540449486787), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 5813.43it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5744.23it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5186.27it/s]\n",
      " 33%|███▎      | 1/3 [09:39<19:19, 579.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.6060606060606061]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6060606060606061]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.12121212121212122]\n",
      "{'learner': SVC(C=1.053170110418928, coef0=0.5772521344971144, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0015240630301997062), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4423076923076923]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.34615384615384615]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.34615384615384615]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.28846153846153844]\n",
      "{'learner': SVC(C=1.5143011307215515, coef0=0.9028860174159863,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.003082161441447713), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "{'learner': SVC(C=1.076290480716731, coef0=0.8842217989495117,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=6.965222376786167e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2808988764044944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "{'learner': SVC(C=1.2162138325340206, coef0=0.31943164255526724,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.00624942702293549), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "{'learner': SVC(C=1.0124889109973583, coef0=0.2460990112526118,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0012734169930438024), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.22448979591836737]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "{'learner': SVC(C=0.8465270774716437, coef0=0.15490731392475865,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00010705665030995827), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=1.1661134391877166, coef0=0.7018332444398482, degree=5, probability=True,\n",
      "    random_state=42, tol=0.00012759062964340633), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.24137931034482762]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.24137931034482762]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "{'learner': SVC(C=1.0425441228670578, coef0=0.20241183270764618,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.0288910412901804e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "{'learner': SVC(C=1.0004399631515826, coef0=0.7164300669839695, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0020279902697426166), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Sensitive Subjects/Accidents & Disasters due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 7118.84it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6722.07it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5813.04it/s]\n",
      " 67%|██████▋   | 2/3 [15:57<07:40, 460.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "{'learner': SVC(C=1.0150034429945505, coef0=0.4277436151638021, degree=4, probability=True,\n",
      "    random_state=42, tol=5.697602835540444e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "{'learner': SVC(C=0.6883588002316052, coef0=0.530058644489191,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=3.202134316824303e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "{'learner': SVC(C=1.3086733391297063, coef0=0.1611692395882237,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00011394522825153981), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=1.2769912811259527, coef0=0.5310038091788527, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0003779463696752834), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.62s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "{'learner': SVC(C=0.973308512783995, coef0=0.06846108792505667,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.008319688927469907), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.7184767166405854, coef0=0.5650723805451646,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00015847292027060725), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=1.0229598964397024, coef0=0.4884428253572495,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.2766100390547977e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.0625]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.63s/trial, best loss: 0.0625]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.0625]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.0625]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.0625]\n",
      "{'learner': SVC(C=1.1029499511798162, coef0=0.21644250264917964, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=4.810775526142717e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.2938025999061962, coef0=0.7770288266113425, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0005497771214803883), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Sensitive Subjects/Accidents & Disasters due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4555.55it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6818.52it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 7002.14it/s]\n",
      "100%|██████████| 3/3 [22:13<00:00, 444.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/trial, best loss: 0.4619771863117871]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.58s/trial, best loss: 0.3136882129277566]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.95s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.56s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.68s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.82s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.34s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.42s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.73s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.45s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.36s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.51s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.86s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.32s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.47s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.96s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.33s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.64s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.68s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.34s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 23/23 [00:05<00:00,  5.57s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.61s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.44s/trial, best loss: 0.26615969581749055]\n",
      "{'learner': SVC(C=1.0354579939043367, coef0=0.6343214579891316, degree=1, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.005462888691007148), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.02s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.50s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.23s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.15s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.71s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.99s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.98s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 9/9 [00:10<00:00, 10.30s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.06s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.91s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.97s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.27s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.09s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.33s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.87s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 18/18 [00:03<00:00,  3.97s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.86s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.10s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.50s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 22/22 [00:03<00:00,  3.67s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.75s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 24/24 [00:03<00:00,  3.77s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.26s/trial, best loss: 0.43202416918429]\n",
      "{'learner': SVC(C=0.8188298309947025, coef0=0.9174219843469561, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.668548470353182e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.10s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.04s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.10s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.14s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.45s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.58s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.61s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.69s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.76s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.37s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.56s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.47s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.52s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.52s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.39s/trial, best loss: 0.36923076923076925]\n",
      "{'learner': SVC(C=0.6413929204561002, coef0=0.14483087242897996, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0021260473311007105), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/trial, best loss: 0.5223300970873787]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.18s/trial, best loss: 0.5223300970873787]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.93s/trial, best loss: 0.4563106796116505]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.92s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.67s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.17s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.22s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.69s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.20s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.42s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.70s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.65s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.63s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.16s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.88s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.88s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.72s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.44s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.83s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.74s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.23s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.70s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.20s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 24/24 [00:03<00:00,  3.64s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.12s/trial, best loss: 0.43495145631067966]\n",
      "{'learner': SVC(C=0.8642653945638715, coef0=0.5839810885286911,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.003363392176623931), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.43190661478599224]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.39688715953307396]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.3891050583657587]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 13/13 [00:01<00:00,  2.00s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.96s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.91s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.99s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.89s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.86s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.98s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.03s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.39s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.93s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.31s/trial, best loss: 0.3463035019455253]\n",
      "{'learner': SVC(C=1.3432699639883203, coef0=0.1521625047465014,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0008482677684109368), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.01s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.02s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.00s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.98s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.12s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.01s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.16s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.09s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.09s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.95s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.01s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.98s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.12s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.02s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.08s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.94s/trial, best loss: 0.36768802228412256]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.92s/trial, best loss: 0.36768802228412256]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.03s/trial, best loss: 0.36768802228412256]\n",
      "{'learner': SVC(C=0.6755970533119107, coef0=0.594016954483138, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.005345841940323481), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.2329749103942652]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.31s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.09s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.92s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.89s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.89s/trial, best loss: 0.2114695340501792]\n",
      "{'learner': SVC(C=1.2523483472146713, coef0=0.9298410184908785, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00016579205394151881), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.16s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.98s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.31s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.96s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.10s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.42s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.23s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.32s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.02s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.17s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.19s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.15s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.97s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.03s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.23s/trial, best loss: 0.3519736842105263]\n",
      "{'learner': SVC(C=1.024399663052638, coef0=0.9942689934608099,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005087492312337215), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.91s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.99s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.93s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.92s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.95s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.96s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.85s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.85s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.13s/trial, best loss: 0.13183279742765275]\n",
      "{'learner': SVC(C=1.235825619240749, coef0=0.9238401177323995,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    tol=0.0014237686718697505), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.4571428571428572]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.4571428571428572]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=0.7834479179614491, coef0=0.9977348431453368, degree=4, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.005666066907806563), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.06s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.84s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "{'learner': SVC(C=1.0201874371566448, coef0=0.11023114461785166, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00014900666244169306), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.7325581395348837]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.4767441860465116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4767441860465116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "{'learner': SVC(C=0.7404738303826865, coef0=0.6267263365455618,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=5.047620044484848e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.84s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.00s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.92s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.82s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "{'learner': SVC(C=1.498549077659054, coef0=0.18066536792136256,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.39840649940919e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.9444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.9444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.7222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.6111111111111112]\n",
      "{'learner': SVC(C=0.9423971911934294, coef0=0.5537580311095094,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=7.160568694467945e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.7777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.7777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.27s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.4722222222222222]\n",
      "{'learner': SVC(C=0.8946049155899276, coef0=0.5854157388769318,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0014967607096380174), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 4747.06it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5246.96it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4695.59it/s]\n",
      " 33%|███▎      | 1/3 [13:41<27:23, 821.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.1785714285714286]\n",
      "{'learner': SVC(C=0.9689573367316257, coef0=0.4308797345901485,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=2.3634845999761477e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3294117647058824]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.2588235294117647]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.81s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "{'learner': SVC(C=0.708658334469585, coef0=0.4802867330432232,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    shrinking=False, tol=2.3984789710312818e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.13s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.1842439006344645, coef0=0.9222532817907875,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.003994644487376946), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.22556390977443608]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.22556390977443608]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.87s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "{'learner': SVC(C=0.8256828805648174, coef0=0.8111818877100204,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00011321533743303551), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.77s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.84s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.02s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.09090909090909094]\n",
      "{'learner': SVC(C=1.2647949300574346, coef0=0.9134434356454106,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.004065886583365643), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.24561403508771928]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.79s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.14035087719298245]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.14035087719298245]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.14035087719298245]\n",
      "{'learner': SVC(C=1.00882083848888, coef0=0.7233970841400361, decision_function_shape='ovo',\n",
      "    degree=4, kernel='poly', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.003071829161006276), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.39s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.98s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.18s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.11s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.93s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.21333333333333337]\n",
      "{'learner': SVC(C=0.8412115704503753, coef0=0.35886401942974866,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0008515015488483201), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.92s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.94s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.78s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.09s/trial, best loss: 0.16326530612244894]\n",
      "{'learner': SVC(C=1.1595357821726857, coef0=0.6677138581574943, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0019438975552523775), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.62s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.21818181818181814]\n",
      "{'learner': SVC(C=1.3053593755817927, coef0=0.9907790248511561,\n",
      "    decision_function_shape='ovo', degree=5, probability=True, random_state=42,\n",
      "    tol=0.006738077748238987), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.32432432432432434]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.32432432432432434]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.2702702702702703]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2702702702702703]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.96s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.18918918918918914]\n",
      "{'learner': SVC(C=0.8585777920702677, coef0=0.699468624580953,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=3.9518201312698455e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.1875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.1875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.1875]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.1875]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.1875]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.1875]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.7797889050649219, coef0=0.5163508240164248, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00017318010063429505), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2316406332920518, coef0=0.43105338630321455, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0022489487222173304), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "{'learner': SVC(C=0.4830395270814024, coef0=0.9273971994519238,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.6794411463268183e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.1273292544503029, coef0=0.9677116074578805,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.002380793477486848), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 5691.64it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6645.95it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5427.88it/s]\n",
      " 67%|██████▋   | 2/3 [23:59<11:41, 701.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "{'learner': SVC(C=1.1854487404071743, coef0=0.4616991803791799, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.006744868923094926), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.62s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.18604651162790697]\n",
      "{'learner': SVC(C=0.8238837122820875, coef0=0.29430990881146823, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00015236716068676753), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.97s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.99s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.09090909090909094]\n",
      "{'learner': SVC(C=1.0288633092207546, coef0=0.6241710851772245,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=1.7548258743746086e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.19277108433734935]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.19277108433734935]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.69s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.68s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.10843373493975905]\n",
      "{'learner': SVC(C=1.0389121698412023, coef0=0.3918118822663198,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=6.76107455772695e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.6714638142626838, coef0=0.36920014751766206, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005610573081463986), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "{'learner': SVC(C=1.2880514976184676, coef0=0.8955765202855243,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.005725730917700241), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.14814814814814814]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.14814814814814814]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.03703703703703709]\n",
      "{'learner': SVC(C=1.3364383335792416, coef0=0.7789939037627189, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005010131440851913), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.91s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.1071428571428571]\n",
      "{'learner': SVC(C=1.0766816669103876, coef0=0.12850224576898261, degree=2, probability=True,\n",
      "    random_state=42, tol=0.00041467392482562803), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.94s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "{'learner': SVC(C=1.3527952358595319, coef0=0.5489386173857607,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0023905782633924493), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=1.3669075550514596, coef0=0.12701541259495197, degree=2, probability=True,\n",
      "    random_state=42, tol=0.0009512504785812856), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.2681833218104106, coef0=0.9590096510934277,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00047027757948644045), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.87s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=1.099635698549255, coef0=0.17566072294139579, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00047434981375646124), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8940054835764077, coef0=0.07461559453754929, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, tol=1.8183007404132265e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.15s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=0.6771598742435734, coef0=0.5687710609329284, degree=4, probability=True,\n",
      "    random_state=42, tol=0.00018750571204383915), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4370.79it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6322.05it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5702.27it/s]\n",
      "100%|██████████| 3/3 [33:56<00:00, 678.73s/it]\n"
     ]
    }
   ],
   "source": [
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n",
    "results1 = run_tests(tests, 0.2, 50)\n",
    "results2 = run_tests(tests, 0.5, 20)\n",
    "results3 = run_tests(tests, 0.2, 200)\n",
    "results4 = run_tests(tests, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.7017543859649122]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.6491228070175439]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.4736842105263158]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.7543859649122807]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5915492957746479]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5352112676056338]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.6338028169014085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.6621621621621622]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.5675675675675675]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.472972972972973]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5405405405405406]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.48611111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.5069444444444444]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.33s/trial, best loss: 0.5694444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5138888888888888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4375]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3924050632911392]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.4493670886075949]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.4810126582278481]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5759493670886076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.4810126582278481]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.3555555555555555]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.4222222222222223]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.5555555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.6]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5111111111111111]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.33333333333333337]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.4]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.75]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.375]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5833333333333333]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.5833333333333333]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.33333333333333337]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4444444444444444]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.3076923076923077]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3076923076923077]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23076923076923073]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:09<00:00, 131.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(pheme.drop(\"target\", axis=1), pheme[\"target\"], train_size=0.8, stratify=pheme[\"target\"]) \n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "models = train_models(\"pheme\", 0.2, 50, train_set, model_list)\n",
    "a = predict_points_mutiple_models(models, \"pheme_categories.json\", X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.5166666666666666]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Adaboost in category People & Society, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.55]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5945945945945945]\n"
     ]
    }
   ],
   "source": [
    "multi_result1 = get_tests_multi(tests, 0.2, 50, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.64]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.64]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.64]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.64]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.36]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.36]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.64]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.36]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.36]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.38s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.56]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.56]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.56]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.56]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.52]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.52]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.52]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.52]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.52]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.52]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.52]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.52]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.45833333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.21s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.15s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.78s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.10s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.20833333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.6046511627906976]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.12s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 12/12 [00:05<00:00,  5.01s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.41860465116279066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6744186046511628]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.94s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  2.00s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.48913043478260865]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:15<00:00, 15.50s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.00s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.19s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.95s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.18s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.38s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.34782608695652173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.5217391304347826]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.5217391304347826]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.10s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (307) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (307) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.75]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:11<00:00, 113.14it/s]\n",
      "100%|██████████| 1491/1491 [00:09<00:00, 156.81it/s]\n",
      "100%|██████████| 817/817 [00:04<00:00, 173.10it/s]\n",
      " 33%|███▎      | 1/3 [26:10<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.41s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.37s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.07s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.99s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.28s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.18s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.07s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.35s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.07s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.41s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.03s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.01s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.05s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.18s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.16s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.47s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.64s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.13636363636363635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.43s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.28125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.28125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.28125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.234375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.234375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.234375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.234375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.234375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.234375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.234375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.484375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.28125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.28125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.28125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.265625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.265625]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.265625]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.265625]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.265625]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.265625]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.265625]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.265625]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.39s/trial, best loss: 0.265625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.265625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.234375]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.12s/trial, best loss: 0.234375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.234375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.234375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.234375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.234375]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.234375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.234375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.234375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.234375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.234375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.234375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.08s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 12, n_neighbors = 14\n",
      "\n",
      " 33%|███▎      | 1/3 [40:13<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.41s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.49s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.51s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.20s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.26s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.98s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 11\n",
      "\n",
      " 33%|███▎      | 1/3 [46:42<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 12, n_neighbors = 14\n",
      "\n",
      " 33%|███▎      | 1/3 [48:39<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Shopping, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.04s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.15s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.99s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:01<00:00, 210.82it/s]\n",
      "100%|██████████| 6425/6425 [00:25<00:00, 256.47it/s]\n",
      "100%|██████████| 817/817 [00:04<00:00, 168.20it/s]\n",
      " 67%|██████▋   | 2/3 [52:44<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.01s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.11s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.97s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.12s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.14s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.30s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.32s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.43s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.18s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.25s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.97s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 6/6 [00:01<00:00,  2.00s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 13/13 [00:01<00:00,  2.00s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.06s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.87s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.07s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.01s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.99s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.17s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.49s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.01s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.10526315789473684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.13s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.12s/trial, best loss: 0.1578947368421053]\n",
      "Skipped category: Food & Drink due to class issues\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.08s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.06s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.95s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.15s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.01s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.06s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.00s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.23s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.95s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 10/10 [00:05<00:00,  5.22s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.64s/trial, best loss: 0.03448275862068961]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.08s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.93s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.94s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 14/14 [00:01<00:00,  2.00s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 1.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 1.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.18s/trial, best loss: 1.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:05:03<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 8\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:07:01<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Health, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.31s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 9\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:08:52<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:10:18<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.00s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:10:49<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.95s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:01<00:00, 129.98it/s]\n",
      "100%|██████████| 6425/6425 [01:23<00:00, 76.74it/s]\n",
      "100%|██████████| 1491/1491 [00:13<00:00, 113.39it/s]\n",
      "100%|██████████| 3/3 [1:13:21<00:00, 1467.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((64.9, 47.49), (64.82, 47.44)),\n",
       "   ('twitter15', (52.05, 39.26), (51.78, 38.83)),\n",
       "   ('twitter16', (50.8, 36.75), (51.04, 37.25))]),\n",
       " ('twitter15',\n",
       "  [((62.88, 61.21), (63.55, 61.79)),\n",
       "   ('PHEME', (61.4, 51.65), (61.37, 51.53)),\n",
       "   ('twitter16', (53.0, 46.59), (53.0, 46.38))]),\n",
       " ('twitter16',\n",
       "  [((69.51, 67.58), (69.51, 67.58)),\n",
       "   ('PHEME', (62.05, 60.04), (61.68, 59.74)),\n",
       "   ('twitter15', (51.37, 46.11), (51.31, 46.21))])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result2 = run_tests_multi(tests, 0.5, 20, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.15s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.38596491228070173]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.55s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.05s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.98s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.24s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.6842105263157895]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.18s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.80s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.55s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 15/15 [00:07<00:00,  7.32s/trial, best loss: 0.45614035087719296]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.92s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.13s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.12s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.472972972972973]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.09s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.14s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.06s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.18s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.72s/trial, best loss: 0.6756756756756757]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.12s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.02s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.45s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.78s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 6/6 [00:09<00:00,  9.54s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.19s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 8/8 [00:05<00:00,  5.77s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 9/9 [00:14<00:00, 14.98s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.15s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.75s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.37s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.93s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.3918918918918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.6081081081081081]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.6081081081081081]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.03s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.03s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.6056338028169015]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.6056338028169015]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.26s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.10s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.98s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 11/11 [00:07<00:00,  7.36s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.28s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.45070422535211263]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.11s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4217687074829932]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.34s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.3945578231292517]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.36s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.50s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.63s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.50s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.69s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.47619047619047616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.92s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 3/3 [01:11<00:00, 71.26s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 4/4 [00:08<00:00,  8.79s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 6/6 [00:20<00:00, 20.57s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.76s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.40s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.45s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.13s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.77s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.71s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 15/15 [00:08<00:00,  8.50s/trial, best loss: 0.5714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.5782312925170068]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.5170068027210885]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.5170068027210885]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.44897959183673475]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.44897959183673475]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.44897959183673475]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.4144736842105263]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.20s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.10s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.89s/trial, best loss: 0.48026315789473684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.4671052631578947]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.89s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.87s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.4078947368421053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.44s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.18s/trial, best loss: 0.48684210526315785]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.20s/trial, best loss: 0.48684210526315785]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.37s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.06s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.54s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.07s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.5681818181818181]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.43181818181818177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.19s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.93s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.40s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.54s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.32s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.34090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.00s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.10s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.36363636363636365]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:07<00:00, 164.61it/s]\n",
      "100%|██████████| 1491/1491 [00:08<00:00, 177.57it/s]\n",
      "100%|██████████| 817/817 [00:05<00:00, 154.05it/s]\n",
      " 33%|███▎      | 1/3 [18:31<37:03, 1111.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.5151515151515151]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.21212121212121215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.26s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.15s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.303030303030303]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.303030303030303]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.94s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 11/11 [00:05<00:00,  5.31s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.24242424242424243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.35s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.37735849056603776]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.43s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.77s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.80s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.79s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.89s/trial, best loss: 0.26415094339622647]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.339622641509434]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.94s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.09s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.05s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.36s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.32s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.39s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.66s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.59s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.29s/trial, best loss: 0.2558139534883721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.06s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.98s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.80s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.68s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.17s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.04s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.12s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.34s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.91s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.38s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.27s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.43s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.37s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.04s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.26136363636363635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.07s/trial, best loss: 0.26136363636363635]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.09s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.20s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4204545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.03s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.15s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.00s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.65s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.23863636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.48s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.50s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.48s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.14s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.29s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.00s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.11s/trial, best loss: 0.20454545454545459]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.07s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.14s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.02s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.05s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.87s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.47s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.19s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.92s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.00s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.20s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.61s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.81s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.82s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.69s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.01s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.43s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.70s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.54s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.79s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.44s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.11s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.37s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.66s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.83s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.40s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.19s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.83s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.18s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 12/12 [00:06<00:00,  6.61s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.06s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.14s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.21904761904761905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.56s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.85s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.27s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.31s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.08s/trial, best loss: 0.2571428571428571]\n",
      "100%|██████████| 10/10 [00:06<00:00,  6.24s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.49s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.18s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 13/13 [00:25<00:00, 25.34s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 14/14 [00:15<00:00, 15.21s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.38s/trial, best loss: 0.23809523809523814]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.51s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.38s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.69s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.51s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.03s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.86s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.51s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.23s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.43s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.56s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.42s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.49s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.92s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.53s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.51s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.41s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.59s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.3548387096774194]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.39s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.50s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.52s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.56s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.64s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.37s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.39s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.41s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.32s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.29s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.40s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.89s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.63s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.22s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.45s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.56s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.34s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.44s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.85s/trial, best loss: 0.22580645161290325]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:08<00:00, 35.70it/s]\n",
      "100%|██████████| 6425/6425 [03:53<00:00, 27.55it/s]\n",
      "100%|██████████| 817/817 [00:18<00:00, 43.72it/s]\n",
      " 67%|██████▋   | 2/3 [40:26<20:31, 1231.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/trial, best loss: 0.6538461538461539]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.24s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.32s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.38s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.36s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.46s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.50s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.47s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.42s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.25s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.24s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.35s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.32s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.23s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.30s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.25s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.35s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.29s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.21s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.24s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.21s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.1923076923076923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.6538461538461539]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.44s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.35s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.18s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.21s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.40s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.22s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.34s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.17s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.36s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.49s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.24s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.33s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.43s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.22s/trial, best loss: 0.09999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.68s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.05s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.41s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.28s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.25s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.22s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.31s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.25s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.29s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.17s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.18s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.15s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.16s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.40s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.42s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.42s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.40s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.48s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.25s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.32s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.45s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.22s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.16s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.37s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.54s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.55s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.53s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.52s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.49s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.56s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.27s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.44s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.28s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.33s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.26s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.38s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.39s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.39s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.27s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.33s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.20s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.51s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.35s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.2931034482758621]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.2931034482758621]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.85s/trial, best loss: 0.15517241379310343]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.58s/trial, best loss: 0.15517241379310343]\n",
      "100%|██████████| 5/5 [00:14<00:00, 14.79s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.77s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.65s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.28s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.08s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.12068965517241381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.69s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.36s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.54s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.36s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.22s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.51s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.48s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.31s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.17s/trial, best loss: 0.051724137931034475]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.20s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.25s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.10s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.15s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.27s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.46s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.34s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.22s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.17s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.42s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.48s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.42s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.40s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.13s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.16s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.17s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.14s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.48s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.47s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.42s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.02s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.46s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.57s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.32s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.70s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.58s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.32s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.56s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.14s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.13s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.14s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.21s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.51s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.18s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.34s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.16s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.11s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.13s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.23s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.15s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.14s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.16s/trial, best loss: 0.2666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.17s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.13s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.24s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:05<00:00,  5.55s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.14s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.37s/trial, best loss: 0.2666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.22s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.15s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.51s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.40s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.20s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.06666666666666665]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 33.11it/s]\n",
      "100%|██████████| 6425/6425 [01:25<00:00, 75.43it/s] \n",
      "100%|██████████| 1491/1491 [00:25<00:00, 57.63it/s]\n",
      "100%|██████████| 3/3 [1:00:53<00:00, 1217.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((66.93, 56.46), (66.69, 56.28)),\n",
       "   ('twitter15', (51.51, 41.61), (51.17, 41.16)),\n",
       "   ('twitter16', (52.26, 41.46), (52.51, 41.91))]),\n",
       " ('twitter15',\n",
       "  [((63.88, 61.02), (63.88, 60.86)),\n",
       "   ('PHEME', (61.56, 52.93), (61.67, 52.94)),\n",
       "   ('twitter16', (56.18, 49.09), (56.06, 48.89))]),\n",
       " ('twitter16',\n",
       "  [((71.34, 69.8), (71.34, 69.8)),\n",
       "   ('PHEME', (61.54, 60.14), (61.51, 60.11)),\n",
       "   ('twitter15', (52.78, 48.61), (53.12, 48.78))])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result3 = run_tests_multi(tests, 0.2, 200, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.25s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.22s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.24s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.27s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/trial, best loss: 0.3932584269662921]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.50s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.54s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.40s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.45s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.18s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.27s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.5955056179775281]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.5955056179775281]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.5842696629213483]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.36s/trial, best loss: 0.5842696629213483]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.73s/trial, best loss: 0.5730337078651686]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.67s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.35s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.72s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.5168539325842696]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.65s/trial, best loss: 0.6292134831460674]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.56s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.59s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.81s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 6/6 [00:33<00:00, 33.29s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.51s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.13s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.72s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.29s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 13/13 [00:14<00:00, 14.56s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.14s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 15/15 [00:14<00:00, 14.02s/trial, best loss: 0.5056179775280899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.36s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.33s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.30s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.32s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.45s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.46s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.62s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.65s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.37s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.52s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.48s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.49s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.44s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.24s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.35s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.42s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.69s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.20s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.34s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.43s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.53s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.59s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.17s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.54s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.13s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.73s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.17s/trial, best loss: 0.3700787401574803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/trial, best loss: 0.5511811023622047]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.01s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.07s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.22s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.28s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.46s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.49s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.84s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 11/11 [00:17<00:00, 17.39s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.68s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.93s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 14/14 [00:11<00:00, 11.14s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 15/15 [00:13<00:00, 13.68s/trial, best loss: 0.4803149606299213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/trial, best loss: 0.4173228346456693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.63s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.08s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.38s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.83s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.70s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.54s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.51s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.70s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.37s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.38s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5660377358490566]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.20s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.17s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.17s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.19s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.17s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.16s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.27s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.17s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.31s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.27s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.58s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.50s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.30s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.45s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.65s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.63s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.55s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.74s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.96s/trial, best loss: 0.41509433962264153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.31s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.39s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.39s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.46226415094339623]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.29s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.21s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.18s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.17s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.4339622641509434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.96s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.69s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.53s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.19s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.49s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.63s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.55s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.59s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.41s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.88s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.03s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.92s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.36s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.54s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.35s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.34s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.44s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.34s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.48s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.81s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.62s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.28s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.35s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.41s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.36s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.49s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.20s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.26s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.37s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.16s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.24s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.89s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.36s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.46s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.70s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.61s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.50s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.74s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.48s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.54s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.46s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 2/2 [00:07<00:00,  7.41s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.22s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.58s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.11s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 6/6 [00:16<00:00, 16.68s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.60s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.74s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.19s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 11/11 [00:11<00:00, 11.98s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.57s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.29s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.64s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.30s/trial, best loss: 0.519047619047619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.59s/trial, best loss: 0.5571428571428572]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.73s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.68s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.97s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.57s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.80s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.45s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.15s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.15s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.53s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5294117647058824]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.03s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.16s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.04s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5028571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.33s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:30<00:00, 30.40s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.57s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 3/3 [00:13<00:00, 13.65s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 5/5 [01:34<00:00, 94.45s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.09s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 7/7 [00:10<00:00, 10.20s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.04s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:22<00:00, 22.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:11<00:00, 11.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.46s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.43999999999999995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.70s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.15s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.06s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.06s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.40s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.22784810126582278]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.89s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 5/5 [00:10<00:00, 10.81s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.50s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.31645569620253167]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.240506329113924]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.189873417721519]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.66s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.11764705882352944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:09<00:00, 135.68it/s]\n",
      "100%|██████████| 1491/1491 [00:15<00:00, 96.94it/s]\n",
      "100%|██████████| 817/817 [00:07<00:00, 111.46it/s]\n",
      " 33%|███▎      | 1/3 [32:18<1:04:36, 1938.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.51s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.93s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 15/15 [00:04<00:00,  4.73s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.1607142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.1607142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.34883720930232553]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2441860465116279]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.36046511627906974]\n",
      "100%|██████████| 2/2 [00:14<00:00, 14.92s/trial, best loss: 0.34883720930232553]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.29s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.17s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.47s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.22093023255813948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.30s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.53s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.3709677419354839]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.3709677419354839]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.17741935483870963]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.97s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.09s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.01s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.63s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.27419354838709675]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.20967741935483875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2706766917293233]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.18s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.43s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.38s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.3007518796992481]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.09s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.28s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.34745762711864403]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.3389830508474576]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.3389830508474576]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.2966101694915254]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.22033898305084743]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.22033898305084743]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.30508474576271183]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.30508474576271183]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.03s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.98s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/trial, best loss: 0.34745762711864403]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 10/10 [00:25<00:00, 25.23s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 14/14 [00:10<00:00, 10.75s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2542372881355932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.288135593220339]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.09s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2457627118644068]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.23728813559322037]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.06s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.49s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2545454545454545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.47s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.37s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.53s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.05s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.72s/trial, best loss: 0.2545454545454545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.34545454545454546]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.40s/trial, best loss: 0.18181818181818177]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.56s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.3125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.3125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.3125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.08333333333333337]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.99s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (276) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (276) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:08<00:00, 35.77it/s]\n",
      "100%|██████████| 6425/6425 [03:16<00:00, 32.69it/s]\n",
      "100%|██████████| 817/817 [00:27<00:00, 29.37it/s]\n",
      " 67%|██████▋   | 2/3 [1:00:25<29:50, 1790.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5588235294117647]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.54s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.45s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.37s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.52s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.00s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:06<00:00,  6.85s/trial, best loss: 0.23529411764705888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.4883720930232558]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.44s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.31s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2093023255813954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0444444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:06<00:00,  6.85s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.14117647058823535]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.3176470588235294]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.10s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:10<00:00, 10.45s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:14<00:00, 14.25s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16470588235294115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.10588235294117643]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.10588235294117643]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.31666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.31666666666666665]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.53s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.23333333333333328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.09s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.31999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.28]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.28]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.28]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.52]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.52]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.48]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.48]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.48]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.48]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.48]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.48]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.36]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.36]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.36]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.28]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.28]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.56s/trial, best loss: 0.28]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.28]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.28]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.28]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.28]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.01s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.16000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.48s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 56.63it/s]\n",
      "100%|██████████| 6425/6425 [01:20<00:00, 79.99it/s] \n",
      "100%|██████████| 1491/1491 [00:19<00:00, 75.06it/s]\n",
      "100%|██████████| 3/3 [1:24:28<00:00, 1689.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((67.47, 60.83), (67.63, 61.02)),\n",
       "   ('twitter15', (51.17, 43.71), (51.64, 44.4)),\n",
       "   ('twitter16', (54.71, 47.38), (55.08, 47.75))]),\n",
       " ('twitter15',\n",
       "  [((66.89, 64.47), (66.89, 64.47)),\n",
       "   ('PHEME', (61.56, 52.72), (61.46, 52.56)),\n",
       "   ('twitter16', (55.45, 49.17), (55.69, 49.45))]),\n",
       " ('twitter16',\n",
       "  [((68.9, 67.23), (68.9, 67.23)),\n",
       "   ('PHEME', (60.23, 58.71), (60.3, 58.82)),\n",
       "   ('twitter15', (53.79, 50.01), (53.52, 49.6))])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result4 = run_tests_multi(tests, 0, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:02<00:00, 40.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# Multi baseline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc_mod*100)), float(\"{0:.2f}\".format(f1_mod*100))\n",
    "\n",
    "\n",
    "def run_baseline_tests(tests, model_list):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_baseline_results(train[0], tests, model_list)))\n",
    "    return test_results\n",
    "\n",
    "def get_baseline_results(train, tests, model_list): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_val_text = np.array([text for text in X_val['e_text']])\n",
    "    models = []\n",
    "    for model_name, model in model_list:\n",
    "        #baseline_model = optimize_model(model, X_train_text, y_train)\n",
    "        #sk_model = baseline_model.best_model()[\"learner\"].fit(X_train_text, y_train)\n",
    "        sk_model = model.fit(X_train_text, y_train)\n",
    "        models.append((model_name, sk_model))\n",
    "\n",
    "    vc_hard = VotingClassifier(estimators=models, voting=\"hard\")\n",
    "    vc_hard = vc_hard.fit(X_train_text, y_train)\n",
    "    #vc_soft = VotingClassifier(estimators=models, voting=\"soft\")\n",
    "    #vc_soft.fit(X_train_text, y_train)\n",
    "\n",
    "    results = []\n",
    "    results.append((evaluate_baseline(vc_hard, X_val_text, y_val)))\n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_data_text = np.array([text for text in test_data['e_text']])\n",
    "        test_target = test_set[\"target\"]\n",
    "        results.append((test_name, evaluate_baseline(vc_hard, test_data_text, test_target)))\n",
    "    return results\n",
    "\n",
    "multi_baseline_results = run_baseline_tests(tests2, model_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(83.27, 81.76),\n",
       "   ('PHEME', (88.59, 87.65)),\n",
       "   ('twitterfull', (55.98, 51.6)),\n",
       "   ('WEIBO', (50.15, 35.29))]),\n",
       " ('twitterfull',\n",
       "  [(78.35, 78.21),\n",
       "   ('PHEME', (59.0, 58.06)),\n",
       "   ('twitterfull', (87.69, 87.67)),\n",
       "   ('WEIBO', (51.33, 51.32))]),\n",
       " ('WEIBO',\n",
       "  [(82.21, 82.17),\n",
       "   ('PHEME', (55.75, 49.16)),\n",
       "   ('twitterfull', (52.51, 51.38)),\n",
       "   ('WEIBO', (89.27, 89.27))])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.70s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 2/2 [00:08<00:00,  8.81s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 3/3 [00:05<00:00,  5.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 5/5 [00:06<00:00,  6.16s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 6/6 [00:08<00:00,  8.19s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 7/7 [00:12<00:00, 12.87s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.87s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 9/9 [00:08<00:00,  8.20s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.07s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.78s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.38s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.86s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 14/14 [00:08<00:00,  8.95s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 15/15 [00:06<00:00,  6.18s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 16/16 [00:06<00:00,  6.59s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 17/17 [00:06<00:00,  6.06s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 18/18 [00:06<00:00,  6.33s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 19/19 [00:06<00:00,  6.89s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 20/20 [00:06<00:00,  6.45s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 21/21 [00:06<00:00,  6.42s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 22/22 [00:06<00:00,  6.80s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 23/23 [00:05<00:00,  5.52s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 24/24 [00:06<00:00,  6.02s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 25/25 [00:06<00:00,  6.66s/trial, best loss: 0.15369649805447472]\n",
      "{'learner': SVC(C=1.2007340688965829, coef0=0.41195154588714744, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0021174726338347707), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:05<06:11, 185.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.14s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.03s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.20s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.13s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "{'learner': SVC(C=0.5853585639125682, coef0=0.9129795392049047,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=2.2560165272510383e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:59<01:48, 108.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "{'learner': SVC(C=0.9906379338992914, coef0=0.5764761568576748, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.617804258277811e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:46<00:00, 95.48s/it] \n"
     ]
    }
   ],
   "source": [
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc_mod*100)), float(\"{0:.2f}\".format(f1_mod*100))\n",
    "\n",
    "\n",
    "def run_baseline_tests(tests):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_baseline_results(train[0], tests)))\n",
    "    return test_results\n",
    "\n",
    "def get_baseline_results(train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_val_text = np.array([text for text in X_val['e_text']])\n",
    "    baseline = optimize_model(\"svm\", X_train_text, y_train)\n",
    "    results = []\n",
    "    results.append(evaluate_baseline(baseline, X_val_text, y_val))\n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_data_text = np.array([text for text in test_data['e_text']])\n",
    "        test_target = test_set[\"target\"]\n",
    "        results.append((test_name, evaluate_baseline(baseline, test_data_text, test_target)))\n",
    "    return results\n",
    "\n",
    "baseline_results = run_baseline_tests(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(83.5, 82.24),\n",
       "   ('PHEME', (94.09, 93.64)),\n",
       "   ('twitter15', (50.17, 47.63)),\n",
       "   ('twitter16', (61.69, 59.78))]),\n",
       " ('twitter15',\n",
       "  [(81.61, 81.6),\n",
       "   ('PHEME', (55.7, 51.97)),\n",
       "   ('twitter15', (95.91, 95.91)),\n",
       "   ('twitter16', (62.3, 60.07))]),\n",
       " ('twitter16',\n",
       "  [(74.39, 74.39),\n",
       "   ('PHEME', (61.29, 60.87)),\n",
       "   ('twitter15', (56.2, 55.43)),\n",
       "   ('twitter16', (87.52, 87.52))])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
