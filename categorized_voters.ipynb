{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are trained on different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from hpsklearn import svc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_dataset(dataset_text):\n",
    "    nlp = spacy.load(\"spacy-twitter\")\n",
    "    encoded = np.array([nlp(text).vector for text in dataset_text])\n",
    "    return encoded.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    dataset = pd.read_csv(f'datasets\\\\{name}.csv')\n",
    "    dataset.rename(columns = {\"Unnamed: 0\":\"entry\"}, inplace=True)\n",
    "    dataset['e_text'] = embed_dataset(dataset['text'])\n",
    "    return dataset\n",
    "\n",
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# glove twitter\n",
    "nlp = spacy.load(\"spacy-twitter\")\n",
    "X = np.array([nlp(text).vector for text in pheme['text']])\n",
    "\n",
    "pheme['e_text'] = X.tolist()\n",
    "pheme_train = pheme.drop('target', axis=1)\n",
    "#6/2/2 train/val/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(pheme_train, pheme['target'], test_size = 0.2, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)\n",
    "X_train_text = np.array([text for text in X_train['e_text']])\n",
    "X_test_text = np.array([text for text in X_test['e_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models  \n",
    "\n",
    "SVMs trained on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import svc, decision_tree_classifier\n",
    "\n",
    "def optimize_model(model_name, X_train, y_train):\n",
    "    mod = HyperoptEstimator(classifier=svc(name=model_name, random_state=42, probability=True),\n",
    "                            preprocessing=[],\n",
    "                            max_evals=25,\n",
    "                            trial_timeout=120,\n",
    "                            verbose=False)\n",
    "    mod.fit(X_train, y_train)\n",
    "    print(mod.best_model())\n",
    "    return mod\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    print(\"Accuracy:\", float(\"{0:.2f}\".format(acc_mod*100)), \"%\")\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    print(\"F1:\", float(\"{0:.2f}\".format(f1_mod*100)), \"%\")\n",
    "    cm = confusion_matrix(y_test, pred_y)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "    disp.plot()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.88 %\n",
      "F1: 81.43 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAGwCAYAAAATw+f5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABC3klEQVR4nO3de3gU9b3H8c/mSiDZDYm5EAk3QUgEBIMHVkURkaBoQWitnohBUVsaUEO5yKkgghKLtgoeBEUFqVJQq1iuGlDugQKCBwEjIBCUJKhAQtBcd84fNFtXgmYzk8ua9+t55nnYmd9v5rt9UvPN9/ubGZthGIYAAABqyK++AwAAAL6NZAIAAJhCMgEAAEwhmQAAAKaQTAAAAFNIJgAAgCkkEwAAwJSA+g6gIXO5XDp+/LjCwsJks9nqOxwAgJcMw9CZM2cUFxcnP7/a+/u5uLhYpaWlps8TFBSkJk2aWBBR3SKZ+AnHjx9XfHx8fYcBADDp2LFjatmyZa2cu7i4WG1bhyrvRIXpc8XGxurw4cM+l1CQTPyEsLAwSdLRj9vIHkpHCL9Mt13apb5DAGpNucq0SSvd/z2vDaWlpco7UaGjO9vIHlbz3xWFZ1xqnXREpaWlJBO/JJWtDXuon6kfEKAhC7AF1ncIQO359wsj6qJVHRpmU2hYza/jku+200kmAACwQIXhUoWJt11VGC7rgqlj/LkNAIAFXDJMb95o06aNbDbbeVtaWpqkc2s50tLSFBkZqdDQUA0dOlT5+fke58jJydHAgQPVtGlTRUdHa9y4cSovL/f6u5NMAADgg7Zv367c3Fz3lpmZKUn6zW9+I0lKT0/XsmXL9NZbb2n9+vU6fvy4hgwZ4p5fUVGhgQMHqrS0VFu2bNFrr72mBQsWaPLkyV7HQpsDAAALuOSSmUZF5ezCwkKP/cHBwQoODj5vfFRUlMfnp556Spdccomuu+46FRQU6JVXXtGiRYvUt29fSdL8+fOVkJCgrVu3qlevXvrggw+0b98+rVmzRjExMerWrZumTZumCRMmaMqUKQoKCqp27FQmAACwQIVhmN4kKT4+Xg6Hw71lZGT87LVLS0v1+uuv695775XNZtPOnTtVVlamfv36ucd06tRJrVq1UlZWliQpKytLXbp0UUxMjHtMcnKyCgsLtXfvXq++O5UJAAAakGPHjslut7s/V1WV+LGlS5fq9OnTGj58uCQpLy9PQUFBCg8P9xgXExOjvLw895gfJhKVxyuPeYNkAgAAC9RkEeWP50uS3W73SCaq45VXXtFNN92kuLi4Gl/fDNocAABYwCVDFSa2miYiR48e1Zo1a3Tfffe598XGxqq0tFSnT5/2GJufn6/Y2Fj3mB/f3VH5uXJMdZFMAADgw+bPn6/o6GgNHDjQvS8pKUmBgYFau3ate192drZycnLkdDolSU6nU3v27NGJEyfcYzIzM2W325WYmOhVDLQ5AACwgFVtDq/muFyaP3++UlNTFRDwn1/pDodDI0aM0JgxYxQRESG73a7Ro0fL6XSqV69ekqT+/fsrMTFRw4YN04wZM5SXl6dHH31UaWlp1Vqn8UMkEwAAWOCHd2TUdL631qxZo5ycHN17773nHXv22Wfl5+enoUOHqqSkRMnJyXrhhRfcx/39/bV8+XKNHDlSTqdTzZo1U2pqqqZOnep1HDbDMPHNf+EKCwvlcDh06vN2vJsDv1jJcd3qOwSg1pQbZVqn91RQUOD1osbqqvxd8fn+GIWZ+F1x5oxLlybk12qstYXKBAAAFnD9ezMz31eRTAAAYIHKuzLMzPdVJBMAAFigwpDJt4ZaF0tdYyEAAAAwhcoEAAAWYM0EAAAwxSWbKmQzNd9X0eYAAACmUJkAAMACLuPcZma+ryKZAADAAhUm2xxm5tY32hwAAMAUKhMAAFigMVcmSCYAALCAy7DJZZi4m8PE3PpGmwMAAJhCZQIAAAvQ5gAAAKZUyE8VJgr+FRbGUtdIJgAAsIBhcs2EwZoJAADQWFGZAADAAqyZAAAAplQYfqowTKyZ8OHHadPmAAAAplCZAADAAi7Z5DLxN7pLvluaIJkAAMACjXnNBG0OAABgCpUJAAAsYH4BJm0OAAAatXNrJky86Is2BwAAaKyoTAAAYAGXyXdzcDcHAACNHGsmAACAKS75NdrnTLBmAgAAmEJlAgAAC1QYNlWYeI24mbn1jWQCAAALVJhcgFlBmwMAADRWVCYAALCAy/CTy8TdHC7u5gAAoHGjzQEAAFBDVCYAALCAS+buyHBZF0qdI5kAAMAC5h9a5bvNAt+NHAAANAhUJgAAsID5d3P47t/3JBMAAFjAJZtcMrNmgidgAgDQqDXmyoTvRg4AABoEKhMAAFjA/EOrfPfve5IJAAAs4DJscpl5zoQPvzXUd9MgAADQIFCZAADAAi6TbQ5ffmgVyQQAABYw/9ZQ300mfDdyAAAaua+++kp33XWXIiMjFRISoi5dumjHjh3u44ZhaPLkyWrRooVCQkLUr18/HThwwOMcJ0+eVEpKiux2u8LDwzVixAgVFRV5FQfJBAAAFqiQzfTmjVOnTunqq69WYGCgVq1apX379ukvf/mLmjdv7h4zY8YMzZo1S3PnztW2bdvUrFkzJScnq7i42D0mJSVFe/fuVWZmppYvX64NGzbogQce8CoW2hwAAFigrtscf/7znxUfH6/58+e797Vt29b9b8Mw9Nxzz+nRRx/VoEGDJEkLFy5UTEyMli5dqjvuuEP79+/X6tWrtX37dvXo0UOS9Pzzz+vmm2/WM888o7i4uGrFQmUCAIAGpLCw0GMrKSmpctw///lP9ejRQ7/5zW8UHR2t7t27a968ee7jhw8fVl5envr16+fe53A41LNnT2VlZUmSsrKyFB4e7k4kJKlfv37y8/PTtm3bqh0zyQQAABaokNlWxznx8fFyOBzuLSMjo8rrffHFF5ozZ446dOig999/XyNHjtSDDz6o1157TZKUl5cnSYqJifGYFxMT4z6Wl5en6Ohoj+MBAQGKiIhwj6kO2hwAAFjAqjbHsWPHZLfb3fuDg4OrHu9yqUePHpo+fbokqXv37vr00081d+5cpaam1jiOmqAyAQCABSpf9GVmkyS73e6xXSiZaNGihRITEz32JSQkKCcnR5IUGxsrScrPz/cYk5+f7z4WGxurEydOeBwvLy/XyZMn3WOqg2QCAAAfdPXVVys7O9tj3+eff67WrVtLOrcYMzY2VmvXrnUfLyws1LZt2+R0OiVJTqdTp0+f1s6dO91jPvzwQ7lcLvXs2bPasdDmAADAAoZscnl5e+eP53sjPT1dV111laZPn67bb79d//rXv/TSSy/ppZdekiTZbDY9/PDDeuKJJ9ShQwe1bdtWkyZNUlxcnAYPHizpXCVjwIABuv/++zV37lyVlZVp1KhRuuOOO6p9J4dEMgEAgCV+2Kqo6XxvXHnllXr33Xc1ceJETZ06VW3bttVzzz2nlJQU95jx48fr7NmzeuCBB3T69Gldc801Wr16tZo0aeIe88Ybb2jUqFG64YYb5Ofnp6FDh2rWrFlexWIzDMPwakYjUlhYKIfDoVOft5M9jI4QfpmS47rVdwhArSk3yrRO76mgoMBjUaOVKn9XjNsyUMGhgTU+T0lRmZ6+akWtxlpbqEwAAGCBxvwKcpIJAAAsUGHyraFm5tY3340cAAA0CFQmAACwAG0OAABgikt+cpko+JuZW998N3IAANAgUJkAAMACFYZNFSZaFWbm1jeSCQAALMCaCQAAYIph8q2hhom59c13IwcAAA0ClQkAACxQIZsqTLzoy8zc+kYyAQCABVyGuXUPLh9+UxZtDgAAYAqVCdS6u/8rUflfBp23/9bUrzUq4yutfD1SH73bXAf3hOi7In/9Y/8ehToq3OPyjgVp0bMx2r05VKe+DlRkTJn6DjmlOx/KV2CQD6fy+EULaVah1PF5uuqmAoVHluvQ3hDNmXSxPv+kqSTprj/mqc+g04qKK1NZqU0H94Ro/lOxyt7VrJ4jR025TC7ANDO3vpFMoNbNWpUtV8V/Sn9HPmuiiXe0V+9bCyRJxd/7qUefQvXoU6hXM+LOm3/sYLBcLumhP3+puLYlOvJZEz03Ll7F3/npgceO19n3ALyR/pdjatOxWDNGt9LJ/ED1HXpKTy05pPv7dNK3eYH66otgzf7Txco9GqTgJoZue+BrZfz9C91zVYIKTvKfZl/kkk0uE+sezMytbw3uJ7ZPnz7q1q2bnnvuufoOBRYJj6zw+Lzkfx1q0aZEXZ1FkqQh938tSfpkS2iV86+8/oyuvP6M+3OL1qX68tAJLV94EckEGqSgJi5dc3OBptzTVp9uO/dz/fpfYtXrxkLdcvc3em1GC330bnOPOS9NidNN/31SbRO/1+5NYfURNlBjDS6Z+DmGYaiiokIBAT4XOiSVldr04T+aa8jvTshmIgk/e8ZfYeEVPz8QqAf+/ob8A6TSEs8f8pJimy77r7PnjQ8IdOnmu75VUYGfvtgXUldhwmKN+QmYDapBM3z4cK1fv14zZ86UzWaTzWbTggULZLPZtGrVKiUlJSk4OFibNm3S8OHDNXjwYI/5Dz/8sPr06eP+7HK5lJGRobZt2yokJESXX3653n777br9UvCwZbVDRYX+6n/7yRqf46vDQXrv1SjdPOwbCyMDrPP9WX/t29FU//1wviJiyuTnZ6jvkFNKSPpOETHl7nE9+xVq6YE9WnZ4j267/2tNvOMSFdLi8FmVaybMbL6qQf3Uzpw5U59//rk6d+6sqVOnSpL27t0rSXrkkUf0zDPPqF27dmrevPlPncYtIyNDr7/+uubOnasOHTpow4YNuuuuuxQVFaXrrrvuvPElJSUqKSlxfy4sLLTgW+GH3v97hK68vlCRseU/P7gK3+QG6k8pl+jaW07r5pSaJyRAbZsxupXG/PWY/r5rnyrKpYN7QrRuabg6dP3ePWb35mb6w42Xyh5RrptSTupPLx7VgwPbq+DbwHqMHPBeg0omHA6HgoKC1LRpU8XGxkqSPvvsM0nS1KlTdeONN1b7XCUlJZo+fbrWrFkjp9MpSWrXrp02bdqkF198scpkIiMjQ48//rgF3wRVyf8yULs2hmnSy4drNP/bvACN/80lSuxxVg89fczi6ABr5R4N1rih7RUcUqFmYS6dPBGo/5l7RLlH/3NnU8n3/jp+xF/HjwTrs4+b6dVN+zXgzpNa8r8x9Rg5asolk+/mYAFm7evRo4dX4w8ePKjvvvvuvASktLRU3bt3r3LOxIkTNWbMGPfnwsJCxcfHex8sqvTB4kiFX1Sunv28r/h8kxuo8b+5RB26fK8/PpsjP9+tBqKRKfneXyXf+yvUUa6k687o5SfOv2Opks1PCgzmdmdfZZi8m8Mgmah9zZp53nvt5+cnw/D8P11ZWZn730VF5+4UWLFihS6++GKPccHBwVVeIzg4+ILHYI7LJX2wJEL9fnNS/j/6qTt5IkCnTgTq+OFzf7Ed/qyJmjZzKeriUtmbV+ib3ECN+3V7RV9cqvsnH1fBt/85QUR0zdolQG1Luq5QNpt07FCwLm5bqvsmHdexg030wZIIBYdU6L8fOqGsD+w6mR8oe0S5fnXPN7ootkwbl4XXd+ioId4a2oAEBQWpouLnV+lHRUXp008/9di3e/duBQae6zUmJiYqODhYOTk5VbY0ULd2bQjTia+ClHzH+escViy8SK//Ndb9eextHSRJf3w2R/1/e1IfbwjT8cPBOn44WClJl3nMff/47lqNG6ipZnaX7pmYq4talOnMaX9tXunQ/KdaqKLcJj9/m1q2L9Gk3xyRPaJCZ0756/NPmuqPt7XX0c+b1HfogNcaXDLRpk0bbdu2TUeOHFFoaKhcLleV4/r27aunn35aCxculNPp1Ouvv65PP/3U3cIICwvT2LFjlZ6eLpfLpWuuuUYFBQXavHmz7Ha7UlNT6/JrNXpJfc5c8Bf/sLF5GjY274Jz+//2pPr/lsWW8C0bloVrwwWqDGUlfpp2X5s6jQe1rzE/AbPBRT527Fj5+/srMTFRUVFRysnJqXJccnKyJk2apPHjx+vKK6/UmTNndPfdd3uMmTZtmiZNmqSMjAwlJCRowIABWrFihdq2bVsXXwUA0IhUtjnMbL7KZvx44QHcCgsL5XA4dOrzdrKHNbi8C7BEcly3+g4BqDXlRpnW6T0VFBTIbrfXyjUqf1cM+uBeBTY7/z1E1VV2tlTv9X+1VmOtLQ2uzQEAgC/i3RwAAMCUxnw3B7V7AABgCpUJAAAs0JgrEyQTAABYoDEnE7Q5AACAKVQmAACwQGOuTJBMAABgAUPmbu/05Yc+kUwAAGCBxlyZYM0EAAAwhcoEAAAWaMyVCZIJAAAs0JiTCdocAADAFCoTAABYoDFXJkgmAACwgGHYZJhICMzMrW+0OQAAgClUJgAAsIBLNlMPrTIzt76RTAAAYIHGvGaCNgcAADCFygQAABZozAswSSYAALBAY25zkEwAAGCBxlyZYM0EAAAwhWQCAAALGP9uc9R087YyMWXKFNlsNo+tU6dO7uPFxcVKS0tTZGSkQkNDNXToUOXn53ucIycnRwMHDlTTpk0VHR2tcePGqby83OvvTpsDAAALGJIMw9x8b1122WVas2aN+3NAwH9+raenp2vFihV666235HA4NGrUKA0ZMkSbN2+WJFVUVGjgwIGKjY3Vli1blJubq7vvvluBgYGaPn26V3GQTAAA4KMCAgIUGxt73v6CggK98sorWrRokfr27StJmj9/vhISErR161b16tVLH3zwgfbt26c1a9YoJiZG3bp107Rp0zRhwgRNmTJFQUFB1Y6DNgcAABaofAKmmU2SCgsLPbaSkpILXvPAgQOKi4tTu3btlJKSopycHEnSzp07VVZWpn79+rnHdurUSa1atVJWVpYkKSsrS126dFFMTIx7THJysgoLC7V3716vvjvJBAAAFqi8m8PMJknx8fFyOBzuLSMjo8rr9ezZUwsWLNDq1as1Z84cHT58WL1799aZM2eUl5enoKAghYeHe8yJiYlRXl6eJCkvL88jkag8XnnMG7Q5AABoQI4dOya73e7+HBwcXOW4m266yf3vrl27qmfPnmrdurXefPNNhYSE1HqcP0RlAgAAC5i5k+OHD7yy2+0e24WSiR8LDw/XpZdeqoMHDyo2NlalpaU6ffq0x5j8/Hz3GovY2Njz7u6o/FzVOoyfQjIBAIAFDMP8ZkZRUZEOHTqkFi1aKCkpSYGBgVq7dq37eHZ2tnJycuR0OiVJTqdTe/bs0YkTJ9xjMjMzZbfblZiY6NW1aXMAAOCDxo4dq1tvvVWtW7fW8ePH9dhjj8nf31933nmnHA6HRowYoTFjxigiIkJ2u12jR4+W0+lUr169JEn9+/dXYmKihg0bphkzZigvL0+PPvqo0tLSql0NqUQyAQCABer6cdpffvml7rzzTn377beKiorSNddco61btyoqKkqS9Oyzz8rPz09Dhw5VSUmJkpOT9cILL7jn+/v7a/ny5Ro5cqScTqeaNWum1NRUTZ061evYSSYAALBAXScTixcv/snjTZo00ezZszV79uwLjmndurVWrlzp1XWrQjIBAIAFXIZNtkb61lAWYAIAAFOoTAAAYAGzd2SYvZujPpFMAABggXPJhJk1ExYGU8docwAAAFOoTAAAYIG6vpujISGZAADAAsa/NzPzfRVtDgAAYAqVCQAALECbAwAAmNOI+xwkEwAAWMFkZUI+XJlgzQQAADCFygQAABbgCZgAAMCUxrwAkzYHAAAwhcoEAABWMGzmFlH6cGWCZAIAAAs05jUTtDkAAIApVCYAALACD60CAABmNOa7OaqVTPzzn/+s9gl/9atf1TgYAADge6qVTAwePLhaJ7PZbKqoqDATDwAAvsuHWxVmVCuZcLlctR0HAAA+rTG3OUzdzVFcXGxVHAAA+DbDgs1HeZ1MVFRUaNq0abr44osVGhqqL774QpI0adIkvfLKK5YHCAAAGjavk4knn3xSCxYs0IwZMxQUFOTe37lzZ7388suWBgcAgO+wWbD5Jq+TiYULF+qll15SSkqK/P393fsvv/xyffbZZ5YGBwCAz6DNUX1fffWV2rdvf95+l8ulsrIyS4ICAAC+w+tkIjExURs3bjxv/9tvv63u3btbEhQAAD6nEVcmvH4C5uTJk5WamqqvvvpKLpdL77zzjrKzs7Vw4UItX768NmIEAKDha8RvDfW6MjFo0CAtW7ZMa9asUbNmzTR58mTt379fy5Yt04033lgbMQIAgAasRu/m6N27tzIzM62OBQAAn9WYX0Fe4xd97dixQ/v375d0bh1FUlKSZUEBAOBzeGto9X355Ze68847tXnzZoWHh0uSTp8+rauuukqLFy9Wy5YtrY4RAAA0YF6vmbjvvvtUVlam/fv36+TJkzp58qT2798vl8ul++67rzZiBACg4atcgGlm81FeVybWr1+vLVu2qGPHju59HTt21PPPP6/evXtbGhwAAL7CZpzbzMz3VV4nE/Hx8VU+nKqiokJxcXGWBAUAgM9pxGsmvG5zPP300xo9erR27Njh3rdjxw499NBDeuaZZywNDgAANHzVqkw0b95cNtt/ejlnz55Vz549FRBwbnp5ebkCAgJ07733avDgwbUSKAAADVojfmhVtZKJ5557rpbDAADAxzXiNke1konU1NTajgMAAPioGj+0SpKKi4tVWlrqsc9ut5sKCAAAn9SIKxNeL8A8e/asRo0apejoaDVr1kzNmzf32AAAaJQa8VtDvU4mxo8frw8//FBz5sxRcHCwXn75ZT3++OOKi4vTwoULayNGAADQgHnd5li2bJkWLlyoPn366J577lHv3r3Vvn17tW7dWm+88YZSUlJqI04AABq2Rnw3h9eViZMnT6pdu3aSzq2POHnypCTpmmuu0YYNG6yNDgAAH1H5BEwzm6/yOplo166dDh8+LEnq1KmT3nzzTUnnKhaVL/4CAACNh9fJxD333KNPPvlEkvTII49o9uzZatKkidLT0zVu3DjLAwQAwCc04gWYXq+ZSE9Pd/+7X79++uyzz7Rz5061b99eXbt2tTQ4AADQ8Hldmfix1q1ba8iQISQSAIBGzSaTayZMXv+pp56SzWbTww8/7N5XXFystLQ0RUZGKjQ0VEOHDlV+fr7HvJycHA0cOFBNmzZVdHS0xo0bp/Lycq+uXa3KxKxZs6p9wgcffNCrAAAAgDnbt2/Xiy++eN4f9unp6VqxYoXeeustORwOjRo1SkOGDNHmzZslnXvj98CBAxUbG6stW7YoNzdXd999twIDAzV9+vRqX99mGMbPdmnatm1bvZPZbPriiy+qffGGrrCwUA6HQzdE3qMAv6D6DgeoFUd+17G+QwBqTUVJsQ4+/T8qKCiotSc0V/6uaP3Uk/Jr0qTG53EVF+voI3/SsWPHPGINDg5WcHDwBecVFRXpiiuu0AsvvKAnnnhC3bp103PPPaeCggJFRUVp0aJF+vWvfy1J+uyzz5SQkKCsrCz16tVLq1at0i233KLjx48rJiZGkjR37lxNmDBBX3/9tYKCqve7r1ptjsOHD1dr+yUlEgAAeMWiBZjx8fFyOBzuLSMj4ycvm5aWpoEDB6pfv34e+3fu3KmysjKP/Z06dVKrVq2UlZUlScrKylKXLl3ciYQkJScnq7CwUHv37q32Vzf1bg4AAGCtqioTF7J48WJ9/PHH2r59+3nH8vLyFBQUdN5jG2JiYpSXl+ce88NEovJ45bHqIpkAAMAKFr3oy263V6slc+zYMT300EPKzMxUExPtFSuYvpsDAADU/RMwd+7cqRMnTuiKK65QQECAAgICtH79es2aNUsBAQGKiYlRaWmpTp8+7TEvPz9fsbGxkqTY2Njz7u6o/Fw5pjpIJgAA8EE33HCD9uzZo927d7u3Hj16KCUlxf3vwMBArV271j0nOztbOTk5cjqdkiSn06k9e/boxIkT7jGZmZmy2+1KTEysdiy0OQAAsIJFbY7qCgsLU+fOnT32NWvWTJGRke79I0aM0JgxYxQRESG73a7Ro0fL6XSqV69ekqT+/fsrMTFRw4YN04wZM5SXl6dHH31UaWlpP7lW48dqVJnYuHGj7rrrLjmdTn311VeSpL/97W/atGlTTU4HAIDva4CP03722Wd1yy23aOjQobr22msVGxurd955x33c399fy5cvl7+/v5xOp+666y7dfffdmjp1qlfX8boy8Y9//EPDhg1TSkqKdu3apZKSEklSQUGBpk+frpUrV3p7SgAAYIF169Z5fG7SpIlmz56t2bNnX3BO69atTf/u9roy8cQTT2ju3LmaN2+eAgMD3fuvvvpqffzxx6aCAQDAVzXmV5B7XZnIzs7Wtddee95+h8Nx3opRAAAaDcN2bjMz30d5XZmIjY3VwYMHz9u/adMmtWvXzpKgAADwOQ1wzURd8TqZuP/++/XQQw9p27ZtstlsOn78uN544w2NHTtWI0eOrI0YAQBAA+Z1m+ORRx6Ry+XSDTfcoO+++07XXnutgoODNXbsWI0ePbo2YgQAoMEzu+6hUa2ZsNls+tOf/qRx48bp4MGDKioqUmJiokJDQ2sjPgAAfEMdP2eiIanxQ6uCgoK8ejoWAAD4ZfI6mbj++utls114xemHH35oKiAAAHyS2ds7G1Nlolu3bh6fy8rKtHv3bn366adKTU21Ki4AAHwLbY7qe/bZZ6vcP2XKFBUVFZkOCAAA+BbL3hp611136dVXX7XqdAAA+JZG/JwJy94ampWVpSZNmlh1OgAAfAq3hnphyJAhHp8Nw1Bubq527NihSZMmWRYYAADwDV4nEw6Hw+Ozn5+fOnbsqKlTp6p///6WBQYAAHyDV8lERUWF7rnnHnXp0kXNmzevrZgAAPA9jfhuDq8WYPr7+6t///68HRQAgB9pzK8g9/pujs6dO+uLL76ojVgAAIAP8jqZeOKJJzR27FgtX75cubm5Kiws9NgAAGi0GuFtoZIXayamTp2qP/7xj7r55pslSb/61a88HqttGIZsNpsqKiqsjxIAgIauEa+ZqHYy8fjjj+v3v/+9Pvroo9qMBwAA+JhqJxOGcS5luu6662otGAAAfBUPraqmn3pbKAAAjRptjuq59NJLfzahOHnypKmAAACAb/EqmXj88cfPewImAACgzVFtd9xxh6Kjo2srFgAAfFcjbnNU+zkTrJcAAABV8fpuDgAAUIVGXJmodjLhcrlqMw4AAHwaayYAAIA5jbgy4fW7OQAAAH6IygQAAFZoxJUJkgkAACzQmNdM0OYAAACmUJkAAMAKtDkAAIAZtDkAAABqiMoEAABWoM0BAABMacTJBG0OAABgCpUJAAAsYPv3Zma+ryKZAADACo24zUEyAQCABbg1FAAAoIaoTAAAYAXaHAAAwDQfTgjMoM0BAABMoTIBAIAFGvMCTJIJAACs0IjXTNDmAAAAppBMAABggco2h5nNG3PmzFHXrl1lt9tlt9vldDq1atUq9/Hi4mKlpaUpMjJSoaGhGjp0qPLz8z3OkZOTo4EDB6pp06aKjo7WuHHjVF5e7vV3J5kAAMAKhgWbF1q2bKmnnnpKO3fu1I4dO9S3b18NGjRIe/fulSSlp6dr2bJleuutt7R+/XodP35cQ4YMcc+vqKjQwIEDVVpaqi1btui1117TggULNHnyZK+/OmsmAABoQAoLCz0+BwcHKzg4+Lxxt956q8fnJ598UnPmzNHWrVvVsmVLvfLKK1q0aJH69u0rSZo/f74SEhK0detW9erVSx988IH27dunNWvWKCYmRt26ddO0adM0YcIETZkyRUFBQdWOmcoEAAAWsKrNER8fL4fD4d4yMjJ+9toVFRVavHixzp49K6fTqZ07d6qsrEz9+vVzj+nUqZNatWqlrKwsSVJWVpa6dOmimJgY95jk5GQVFha6qxvVRWUCAAArWHQ3x7Fjx2S32927q6pKVNqzZ4+cTqeKi4sVGhqqd999V4mJidq9e7eCgoIUHh7uMT4mJkZ5eXmSpLy8PI9EovJ45TFvkEwAAGAFi5KJygWV1dGxY0ft3r1bBQUFevvtt5Wamqr169ebCKJmSCYAAPBRQUFBat++vSQpKSlJ27dv18yZM/Xb3/5WpaWlOn36tEd1Ij8/X7GxsZKk2NhY/etf//I4X+XdHpVjqos1EwAAWKCubw2tisvlUklJiZKSkhQYGKi1a9e6j2VnZysnJ0dOp1OS5HQ6tWfPHp04ccI9JjMzU3a7XYmJiV5dl8oEAABWqOMnYE6cOFE33XSTWrVqpTNnzmjRokVat26d3n//fTkcDo0YMUJjxoxRRESE7Ha7Ro8eLafTqV69ekmS+vfvr8TERA0bNkwzZsxQXl6eHn30UaWlpf3kOo2qkEwAAOCDTpw4obvvvlu5ublyOBzq2rWr3n//fd14442SpGeffVZ+fn4aOnSoSkpKlJycrBdeeME939/fX8uXL9fIkSPldDrVrFkzpaamaurUqV7HQjIBAIAFbIYhm1Hz0oS3c1955ZWfPN6kSRPNnj1bs2fPvuCY1q1ba+XKlV5dtyokEwAAWIEXfQEAANQMlQkAACxg9o4MK+7mqC8kEwAAWIE2BwAAQM1QmQAAwAK0OQAAgDmNuM1BMgEAgAUac2WCNRMAAMAUKhMAAFiBNgcAADDLl1sVZtDmAAAAplCZAADACoZxbjMz30eRTAAAYAHu5gAAAKghKhMAAFiBuzkAAIAZNte5zcx8X0WbAwAAmEJlArWuc9IpDR2eo/YJZxQZXappD3VR1kdRkiT/AJfuHvWFruz9rWJbfq+zZwK0e1uE5j93iU5+HSxJ6tLjlP786q4qz/3QnT10YK+9zr4LUJXfXvap7ui8Vxfbz0iSDp6M0JztSdqY01qStGDwe/qvi497zFnyaaIeX3+dJMkRXKwZN65Rx4u+VXiTYn37XYg+PNxWz23tqbNlQXX7ZVBztDnqh2EY+t3vfqe3335bp06d0q5du9StW7cLjj9y5Ijatm37s+PQsDQJcelwdqg+eDdOk57b43EsuIlL7RPO6O8vttEXn4cq1F6u3084oMdm/Z8euvNKSdL+3Q6lXH+1x7xho77Q5T1P6cDesDr7HsCF5J8N1bNbe+noaYckaXCnbP3vzas19M3f6ODJCEnSm3sT9L//+i/3nO/L/vOfX0M2fXi4jWZt+y+dKg5RK0eBHr12oxxNijU+88a6/TKoscZ8N0e9JhOrV6/WggULtG7dOrVr104XXXRRfYaDWrJjU6R2bIqs8th3RQH60++6e+x7Yfqlmvn3HYqKLdbXeU1UXu6nU98Gu4/7B7jU6/pvtGxRS0m22gwdqJZ1R9p4fJ65rafu6LxXXWPy3clEcXmAvvmuaZXzC0uCtWRvZ/fn42fCtPjTy3RPt921FTJqA8+ZqB+HDh1SixYtdNVVV9VnGGhgmoWWy+WSis5U/ePZq883CnOU6YP3WtRxZMDP87O5lHzJIYUElumTvBj3/lsuPaBbLz2gb74L0bojbTRnR5KKywOrPEdU07Pq1+6wdhyPq6uwAVPqbQHm8OHDNXr0aOXk5Mhms6lNmzZavXq1rrnmGoWHhysyMlK33HKLDh06dMFznDp1SikpKYqKilJISIg6dOig+fPnu48fO3ZMt99+u8LDwxUREaFBgwbpyJEjFzxfSUmJCgsLPTbUrcCgCt2TfkjrV8Xo+7NVJxP9b8vVx1si9W1+kzqODriwDhHfascD87T79y/psT4b9OCqATp06lxVYsXnHTQh8wYNX/orzfv4Ct3a8XP9ud/a887x9I2Z2vnAPK2/Z6GKSgM16aM+dfwtYEZlm8PM5qvqLZmYOXOmpk6dqpYtWyo3N1fbt2/X2bNnNWbMGO3YsUNr166Vn5+fbrvtNrlcVd8vM2nSJO3bt0+rVq3S/v37NWfOHHerpKysTMnJyQoLC9PGjRu1efNmhYaGasCAASotLa3yfBkZGXI4HO4tPj6+1r4/zucf4NLEZ/bKZjP0v090rHJMZEyxrrjqW33wLlUJNCxHTodryJLbdcfbQ7Xk08s0/YYPdUnzk5Kkt/YlavOxVjpwMlLLP79UE9f01Y2XHFa8vcDjHH/efLV+/eavlbZigFo5CjXh6i318VVQU4YFm4+qtzaHw+FQWFiY/P39FRsbK0kaOnSox5hXX31VUVFR2rdvnzp37nzeOXJyctS9e3f16NFDktSmTRv3sSVLlsjlcunll1+WzXaurz5//nyFh4dr3bp16t+//3nnmzhxosaMGeP+XFhYSEJRR/wDXJr49KeKblGsifd1v3BVYlCuzhQEaus61tegYSlz+Sun4NwCzH1fR6lz9AkNu3yPpqy77ryx/5d/rv3RylGgY4UO9/5vvmuqb75rqsOnm6ugpIleH7JUc3Yk6ZvvmtXNlwBqqEE9Z+LAgQO688471a5dO9ntdndykJOTU+X4kSNHavHixerWrZvGjx+vLVv+k8V/8sknOnjwoMLCwhQaGqrQ0FBFRESouLj4gq2T4OBg2e12jw21rzKRiGv9vf7ngW46U1B1H1ky1G9wrtYui1VFeYP60QXOY7MZCvSrqPJYp4u+kSR9/RNJgu3ff6YG+Vd9DjQ8jbnN0aCeM3HrrbeqdevWmjdvnuLi4uRyudS5c+cLtiVuuukmHT16VCtXrlRmZqZuuOEGpaWl6ZlnnlFRUZGSkpL0xhtvnDcvKiqqtr8KfqBJSLniWn3v/hxz8fdq1/GMzhQE6uQ3Qfqfv3yq9glnNGVUV/n7GWoeWSJJOlMQqPIfJA2X9zylFi2L9f4/WJSGhiW911ZtONpKuUWhahZYplsuPaD/uvi47v/nLYq3F2jgpQe04WhrnS4OVsfIbzXhmi3a/lULff7tubucrm19VJEh32vPiSh9Vxao9hGnNO6qLO08HqvjZ/ijxmdwN0f9+/bbb5Wdna158+apd+/ekqRNmzb97LyoqCilpqYqNTVVvXv31rhx4/TMM8/oiiuu0JIlSxQdHU2FoZ51uOyMx0OnHhh/UJKU+V6s3pjTVs7rz/2VNvvt7R7zJtzbXXt2NHd/Tr4tV/t2OfTlEUq+aFgiQr7XU/0+VFSzszpTEqTPv43U/f+8RVlfxis2tEjOll/q7sv/TyEB5corClXmoXaauyPJPb+4PEC/TtynCdecUpB/hXvMyx93/4mrAg1Hg0kmmjdvrsjISL300ktq0aKFcnJy9Mgjj/zknMmTJyspKUmXXXaZSkpKtHz5ciUkJEiSUlJS9PTTT2vQoEHuhZ5Hjx7VO++8o/Hjx6tly5Z18bUgac+O5rq5a98LHv+pYz8045HLrAoJsNSkj66/4LG8olClLh38k/P/9dXFSnlniMVRoa415odWNZjGs5+fnxYvXqydO3eqc+fOSk9P19NPP/2Tc4KCgjRx4kR17dpV1157rfz9/bV48WJJUtOmTbVhwwa1atVKQ4YMUUJCgkaMGKHi4mIqFQAA6zXiuzlshuHDTZpaVlhYKIfDoRsi71GAH8/Hxy/Tkd9VfRsu8EtQUVKsg0//jwoKCmrtD8nK3xXOAVMVEFjz59+UlxUra/XkWo21tjSYNgcAAL6sMbc5SCYAALCCyzi3mZnvo0gmAACwQiN+BXmDWYAJAAB8E5UJAAAsYJPJNROWRVL3SCYAALBCI34CJm0OAABgCpUJAAAswK2hAADAHO7mAAAAqBkqEwAAWMBmGLKZWERpZm59I5kAAMAKrn9vZub7KNocAADAFCoTAABYgDYHAAAwpxHfzUEyAQCAFXgCJgAAQM2QTAAAYIHKJ2Ca2byRkZGhK6+8UmFhYYqOjtbgwYOVnZ3tMaa4uFhpaWmKjIxUaGiohg4dqvz8fI8xOTk5GjhwoJo2baro6GiNGzdO5eXlXsVCMgEAgBUq2xxmNi+sX79eaWlp2rp1qzIzM1VWVqb+/fvr7Nmz7jHp6elatmyZ3nrrLa1fv17Hjx/XkCFD3McrKio0cOBAlZaWasuWLXrttde0YMECTZ482atYWDMBAIAPWr16tcfnBQsWKDo6Wjt37tS1116rgoICvfLKK1q0aJH69u0rSZo/f74SEhK0detW9erVSx988IH27dunNWvWKCYmRt26ddO0adM0YcIETZkyRUFBQdWKhcoEAAAWsLnMb5JUWFjosZWUlFTr+gUFBZKkiIgISdLOnTtVVlamfv36ucd06tRJrVq1UlZWliQpKytLXbp0UUxMjHtMcnKyCgsLtXfv3mp/d5IJAACsYFGbIz4+Xg6Hw71lZGT87KVdLpcefvhhXX311ercubMkKS8vT0FBQQoPD/cYGxMTo7y8PPeYHyYSlccrj1UXbQ4AABqQY8eOyW63uz8HBwf/7Jy0tDR9+umn2rRpU22GdkFUJgAAsIJhwSbJbrd7bD+XTIwaNUrLly/XRx99pJYtW7r3x8bGqrS0VKdPn/YYn5+fr9jYWPeYH9/dUfm5ckx1kEwAAGCBysdpm9m8YRiGRo0apXfffVcffvih2rZt63E8KSlJgYGBWrt2rXtfdna2cnJy5HQ6JUlOp1N79uzRiRMn3GMyMzNlt9uVmJhY7VhocwAA4IPS0tK0aNEivffeewoLC3OvcXA4HAoJCZHD4dCIESM0ZswYRUREyG63a/To0XI6nerVq5ckqX///kpMTNSwYcM0Y8YM5eXl6dFHH1VaWlq12iuVSCYAALBCHT9Oe86cOZKkPn36eOyfP3++hg8fLkl69tln5efnp6FDh6qkpETJycl64YUX3GP9/f21fPlyjRw5Uk6nU82aNVNqaqqmTp3qVSwkEwAAWMGQ5DI535vh1Ug+mjRpotmzZ2v27NkXHNO6dWutXLnSu4v/CMkEAAAWaMyvIGcBJgAAMIXKBAAAVjBkcs2EZZHUOZIJAACsUMcLMBsS2hwAAMAUKhMAAFjBJclmcr6PIpkAAMAC3M0BAABQQ1QmAACwQiNegEkyAQCAFRpxMkGbAwAAmEJlAgAAKzTiygTJBAAAVuDWUAAAYAa3hgIAANQQlQkAAKzAmgkAAGCKy5BsJhICl+8mE7Q5AACAKVQmAACwAm0OAABgjslkQr6bTNDmAAAAplCZAADACrQ5AACAKS5DploV3M0BAAAaKyoTAABYwXCd28zM91EkEwAAWIE1EwAAwBTWTAAAANQMlQkAAKxAmwMAAJhiyGQyYVkkdY42BwAAMIXKBAAAVqDNAQAATHG5JJl4VoTLd58zQZsDAACYQmUCAAAr0OYAAACmNOJkgjYHAAAwhcoEAABWaMSP0yaZAADAAobhkmHizZ9m5tY3kgkAAKxgGOaqC6yZAAAAjRWVCQAArGCYXDPhw5UJkgkAAKzgckk2E+sefHjNBG0OAABgCpUJAACsQJsDAACYYbhcMky0OXz51lDaHAAAwBQqEwAAWIE2BwAAMMVlSLbGmUzQ5gAAwEdt2LBBt956q+Li4mSz2bR06VKP44ZhaPLkyWrRooVCQkLUr18/HThwwGPMyZMnlZKSIrvdrvDwcI0YMUJFRUVexUEyAQCAFQzj3LMiarx5X5k4e/asLr/8cs2ePbvK4zNmzNCsWbM0d+5cbdu2Tc2aNVNycrKKi4vdY1JSUrR3715lZmZq+fLl2rBhgx544AGv4qDNAQCABQyXIcNEm8OoQTJx00036aabbrrg+Z577jk9+uijGjRokCRp4cKFiomJ0dKlS3XHHXdo//79Wr16tbZv364ePXpIkp5//nndfPPNeuaZZxQXF1etOKhMAABgBVNVCZf7CZiFhYUeW0lJSY3COXz4sPLy8tSvXz/3PofDoZ49eyorK0uSlJWVpfDwcHciIUn9+vWTn5+ftm3bVu1rkUwAANCAxMfHy+FwuLeMjIwanScvL0+SFBMT47E/JibGfSwvL0/R0dEexwMCAhQREeEeUx20OQAAsIBVbY5jx47Jbre79wcHB5uOrbaRTAAAYAXDJcn8i77sdrtHMlFTsbGxkqT8/Hy1aNHCvT8/P1/dunVzjzlx4oTHvPLycp08edI9vzpIJn5CZZZY7iqt50iA2lNRUvzzgwAf5fr3z3dNFjd6q1xlpp5ZVa4y64KR1LZtW8XGxmrt2rXu5KGwsFDbtm3TyJEjJUlOp1OnT5/Wzp07lZSUJEn68MMP5XK51LNnz+pfzMAFHTt2rPJxZmxsbGxsPrwdO3as1n5XfP/990ZsbKwlccbGxhrff/99ta995swZY9euXcauXbsMScZf//pXY9euXcbRo0cNwzCMp556yggPDzfee+894//+7/+MQYMGGW3btvW4xoABA4zu3bsb27ZtMzZt2mR06NDBuPPOO73638BmGD78yK1a5nK5dPz4cYWFhclms9V3OI1CYWGh4uPjz+sZAr8U/IzXLcMwdObMGcXFxcnPr/buOSguLlZpqfkqdlBQkJo0aVLt8evWrdP1119/3v7U1FQtWLBAhmHoscce00svvaTTp0/rmmuu0QsvvKBLL73UPfbkyZMaNWqUli1bJj8/Pw0dOlSzZs1SaGhoteMgmUCDUlhYKIfDoYKCAv5Di18kfsbxS8StoQAAwBSSCQAAYArJBBqU4OBgPfbYYz5xXzVQE/yM45eINRMAAMAUKhMAAMAUkgkAAGAKyQQAADCFZAIAvGQYhh544AFFRETIZrNp9+7dPzn+yJEj1RoH+CqSCdSqPn366OGHH67vMABLrV69WgsWLNDy5cuVm5urzp0713dIQL3iRV+oV4ZhqKKiQgEB/CjCdxw6dEgtWrTQVVddVd+hAA0ClQnUmuHDh2v9+vWaOXOmbDabbDabFixYIJvNplWrVikpKUnBwcHatGmThg8frsGDB3vMf/jhh9WnTx/3Z5fLpYyMDLVt21YhISG6/PLL9fbbb9ftl0KjN3z4cI0ePVo5OTmy2Wxq06aNVq9erWuuuUbh4eGKjIzULbfcokOHDl3wHKdOnVJKSoqioqIUEhKiDh06aP78+e7jx44d0+23367w8HBFRERo0KBBOnLkSB18O6BmSCZQa2bOnCmn06n7779fubm5ys3NVXx8vCTpkUce0VNPPaX9+/era9eu1TpfRkaGFi5cqLlz52rv3r1KT0/XXXfdpfXr19fm1wA8zJw5U1OnTlXLli2Vm5ur7du36+zZsxozZox27NihtWvXys/PT7fddptcLleV55g0aZL27dunVatWaf/+/ZozZ44uuugiSVJZWZmSk5MVFhamjRs3avPmzQoNDdWAAQMseZEUUBuoLaPWOBwOBQUFqWnTpoqNjZUkffbZZ5KkqVOn6sYbb6z2uUpKSjR9+nStWbNGTqdTktSuXTtt2rRJL774oq677jrrvwBQBYfDobCwMPn7+7t/rocOHeox5tVXX1VUVJT27dtX5XqKnJwcde/eXT169JAktWnTxn1syZIlcrlcevnll91vK54/f77Cw8O1bt069e/fv5a+GVBzJBOoF5X/Ea2ugwcP6rvvvjsvASktLVX37t2tDA3w2oEDBzR58mRt27ZN33zzjbsikZOTU2UyMXLkSA0dOlQff/yx+vfvr8GDB7vXX3zyySc6ePCgwsLCPOYUFxf/ZOsEqE8kE6gXzZo18/js5+enHz/ZvayszP3voqIiSdKKFSt08cUXe4zjHQeob7feeqtat26tefPmKS4uTi6XS507d75gW+Kmm27S0aNHtXLlSmVmZuqGG25QWlqannnmGRUVFSkpKUlvvPHGefOioqJq+6sANUIygVoVFBSkioqKnx0XFRWlTz/91GPf7t27FRgYKElKTExUcHCwcnJyaGmgQfn222+VnZ2tefPmqXfv3pKkTZs2/ey8qKgopaamKjU1Vb1799a4ceP0zDPP6IorrtCSJUsUHR0tu91e2+EDlmABJmpVmzZttG3bNh05csSj/Ptjffv21Y4dO7Rw4UIdOHBAjz32mEdyERYWprFjxyo9PV2vvfaaDh06pI8//ljPP/+8Xnvttbr6OsB5mjdvrsjISL300ks6ePCgPvzwQ40ZM+Yn50yePFnvvfeeDh48qL1792r58uVKSEiQJKWkpOiiiy7SoEGDtHHjRh0+fFjr1q3Tgw8+qC+//LIuvhLgNZIJ1KqxY8fK399fiYmJioqKUk5OTpXjkpOTNWnSJI0fP15XXnmlzpw5o7vvvttjzLRp0zRp0iRlZGQoISFBAwYM0IoVK9S2bdu6+CpAlfz8/LR48WLt3LlTnTt3Vnp6up5++umfnBMUFKSJEyeqa9euuvbaa+Xv76/FixdLkpo2baoNGzaoVatWGjJkiBISEjRixAgVFxdTqUCDxSvIAQCAKVQmAACAKSQTAADAFJIJAABgCskEAAAwhWQCAACYQjIBAABMIZkAAACmkEwAAABTSCaABm748OEaPHiw+3OfPn308MMP13kc69atk81m0+nTpy84xmazaenSpdU+55QpU9StWzdTcR05ckQ2m027d+82dR4ANUcyAdTA8OHDZbPZZLPZFBQUpPbt22vq1KkqLy+v9Wu/8847mjZtWrXGVicBAACzeGsoUEMDBgzQ/PnzVVJSopUrVyotLU2BgYGaOHHieWNLS0sVFBRkyXUjIiIsOQ8AWIXKBFBDwcHBio2NVevWrTVy5Ej169dP//znPyX9pzXx5JNPKi4uTh07dpQkHTt2TLfffrvCw8MVERGhQYMG6ciRI+5zVlRUaMyYMQoPD1dkZKTGjx+vH78+58dtjpKSEk2YMEHx8fEKDg5W+/bt9corr+jIkSO6/vrrJZ17s6XNZtPw4cMlSS6XSxkZGWrbtq1CQkJ0+eWX6+233/a4zsqVK3XppZcqJCRE119/vUec1TVhwgRdeumlatq0qdq1a6dJkyaprKzsvHEvvvii4uPj1bRpU91+++0qKCjwOP7yyy8rISFBTZo0UadOnfTCCy94HQuA2kMyAVgkJCREpaWl7s9r165Vdna2MjMztXz5cpWVlSk5OVlhYWHauHGjNm/erNDQUA0YMMA97y9/+YsWLFigV199VZs2bdLJkyf17rvv/uR17777bv3973/XrFmztH//fr344osKDQ1VfHy8/vGPf0iSsrOzlZubq5kzZ0qSMjIytHDhQs2dO1d79+5Venq67rrrLq1fv17SuaRnyJAhuvXWW7V7927dd999euSRR7z+3yQsLEwLFizQvn37NHPmTM2bN0/PPvusx5iDBw/qzTff1LJly7R69Wrt2rVLf/jDH9zH33jjDU2ePFlPPvmk9u/fr+nTp2vSpEm8eh5oSAwAXktNTTUGDRpkGIZhuFwuIzMz0wgODjbGjh3rPh4TE2OUlJS45/ztb38zOnbsaLhcLve+kpISIyQkxHj//fcNwzCMFi1aGDNmzHAfLysrM1q2bOm+lmEYxnXXXWc89NBDhmEYRnZ2tiHJyMzMrDLOjz76yJBknDp1yr2vuLjYaNq0qbFlyxaPsSNGjDDuvPNOwzAMY+LEiUZiYqLH8QkTJpx3rh+TZLz77rsXPP70008bSUlJ7s+PPfaY4e/vb3z55ZfufatWrTL8/PyM3NxcwzAM45JLLjEWLVrkcZ5p06YZTqfTMAzDOHz4sCHJ2LVr1wWvC6B2sWYCqKHly5crNDRUZWVlcrlc+u///m9NmTLFfbxLly4e6yQ++eQTHTx4UGFhYR7nKS4u1qFDh1RQUKDc3Fz17NnTfSwgIEA9evQ4r9VRaffu3fL399d1111X7bgPHjyo7777TjfeeKPH/tLSUnXv3l2StH//fo84JMnpdFb7GpWWLFmiWbNm6dChQyoqKlJ5ebnsdrvHmFatWuniiy/2uI7L5VJ2drbCwsJ06NAhjRgxQvfff797THl5uRwOh9fxAKgdJBNADV1//fWaM2eOgoKCFBcXp4AAz/87NWvWzONzUVGRkpKS9MYbb5x3rqioqBrFEBIS4vWcoqIiSdKKFSs8folL59aBWCUrK0spKSl6/PHHlZycLIfDocWLF+svf/mL17HOmzfvvOTG39/fslgBmEMyAdRQs2bN1L59+2qPv+KKK7RkyRJFR0ef99d5pRYtWmjbtm269tprJZ37C3znzp264oorqhzfpUsXuVwurV+/Xv369TvveGVlpKKiwr0vMTFRwcHBysnJuWBFIyEhwb2YtNLWrVt//kv+wJYtW9S6dWv96U9/cu87evToeeNycnJ0/PhxxcXFua/j5+enjh07KiYmRnFxcfriiy+UkpLi1fUB1B0WYAJ1JCUlRRdddJEGDRqkjRs36vDhw1q3bp0efPBBffnll5Kkhx56SE899ZSWLl2qzz77TH/4wx9+8hkRbdq0UWpqqu69914tXbrUfc4333xTktS6dWvZbDYtX75cX3/9tYqKihQWFqaxY8cqPT1dr732mg4dOqSPP/5Yzz//vHtR4+9//3sdOHBA48aNU3Z2thYtWqQFCxZ49X07dOignJwcLV68WIcOHdKsWbOqXEzapEkTpaam6pNPPtHGjRv14IMP6vbbb1dsbKwk6fHHH1dGRoZmzZqlzz//XHv27NH8+fP117/+1at4ANQekgmgjjRt2lQbNmxQq1atNGTIECUkJGjEiBEqLi52Vyr++Mc/atiwYUpNTZXT6VRYWJhuu+22nzzvnDlz9Otf/1p/+MMf1KlTJ91///06e/asJOniiy/W448/rkceeUQxMTEaNWqUJGnatGmaNGmSMjIylJCQoAEDBmjFihVq27atpHPrGP7xj39o6dKluvzyyzV37lxNnz7dq+/7q1/9Sunp6Ro1apS6deumLVu2aNKkSeeNa9++vYYMGaKbb75Z/fv3V9euXT1u/bzvvvv08ssva/78+erSpYuuu+46LViwwB0rgPpnMy60sgsAAKAaqEwAAABTSCYAAIApJBMAAMAUkgkAAGAKyQQAADCFZAIAAJhCMgEAAEwhmQAAAKaQTAAAAFNIJgAAgCkkEwAAwJT/By+6MBYjBg8BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train, X_val, y_train, y_val = train_test_split(pheme.drop('target', axis=1), pheme['target'], train_size=0.8, random_state=42, stratify=pheme['target'])\n",
    "X_train_text = np.array([text for text in X_train['e_text']])\n",
    "X_val_text = np.array([text for text in X_val['e_text']])\n",
    "#baseline = optimize_model(\"Baseline\", X_train_text, y_train)\n",
    "baseline = SVC(random_state=42)\n",
    "baseline.fit(X_train_text, y_train)\n",
    "evaluate_model(baseline, X_val_text, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.56 %\n",
      "F1: 37.27 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = twitter.drop('target', axis=1)\n",
    "X_test_text = np.array([text for text in X_test['e_text']])\n",
    "y_test = twitter['target']\n",
    "evaluate_model(baseline, X_test_text, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.55s/trial, best loss: 0.35953307392996114]\n",
      "100%|██████████| 2/2 [00:08<00:00,  8.69s/trial, best loss: 0.35953307392996114]\n",
      "100%|██████████| 3/3 [00:07<00:00,  7.88s/trial, best loss: 0.35953307392996114]\n",
      "100%|██████████| 4/4 [00:08<00:00,  8.57s/trial, best loss: 0.35953307392996114]\n",
      "100%|██████████| 5/5 [00:09<00:00,  9.12s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 6/6 [00:08<00:00,  8.14s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 7/7 [00:07<00:00,  7.37s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 8/8 [00:09<00:00,  9.44s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 9/9 [00:08<00:00,  8.67s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 10/10 [00:10<00:00, 10.13s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 11/11 [00:08<00:00,  8.64s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 12/12 [00:33<00:00, 33.09s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 13/13 [00:08<00:00,  8.08s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 14/14 [00:08<00:00,  8.89s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 15/15 [00:10<00:00, 10.49s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 16/16 [00:13<00:00, 13.38s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 17/17 [00:08<00:00,  8.81s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 18/18 [00:07<00:00,  7.83s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 19/19 [00:12<00:00, 12.48s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 20/20 [00:09<00:00,  9.71s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 21/21 [00:11<00:00, 11.99s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 22/22 [00:19<00:00, 19.97s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 23/23 [00:09<00:00,  9.89s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 24/24 [00:12<00:00, 12.25s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 25/25 [00:08<00:00,  8.03s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 26/26 [00:08<00:00,  8.34s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 27/27 [00:13<00:00, 13.88s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 28/28 [00:09<00:00,  9.95s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 29/29 [00:11<00:00, 11.32s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 30/30 [00:09<00:00,  9.40s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 31/31 [00:08<00:00,  8.05s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 32/32 [00:09<00:00,  9.26s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 33/33 [00:14<00:00, 14.61s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 34/34 [00:11<00:00, 11.68s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 35/35 [00:07<00:00,  7.61s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 36/36 [00:08<00:00,  8.58s/trial, best loss: 0.35564202334630346]\n",
      "100%|██████████| 37/37 [00:11<00:00, 11.38s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 38/38 [00:08<00:00,  8.44s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 39/39 [00:06<00:00,  6.60s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 40/40 [00:07<00:00,  7.34s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 41/41 [00:07<00:00,  7.16s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 42/42 [00:07<00:00,  7.81s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 43/43 [00:06<00:00,  6.66s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 44/44 [00:07<00:00,  7.80s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 45/45 [00:08<00:00,  8.61s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 46/46 [00:10<00:00, 10.98s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 47/47 [00:08<00:00,  8.79s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 48/48 [00:08<00:00,  8.12s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 49/49 [00:07<00:00,  7.69s/trial, best loss: 0.35408560311284043]\n",
      "100%|██████████| 50/50 [00:06<00:00,  6.90s/trial, best loss: 0.35408560311284043]\n",
      "{'learner': SVC(C=1.2930467747652603, coef0=0.15531204802574028, degree=4, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.003788985221333045), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Accuracy: 52.21 %\n",
      "F1: 47.32 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.49 %\n",
      "F1: 57.05 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hpsklearn import svc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make baseline trained on all data\n",
    "def make_baseline():\n",
    "    X_train = pheme.drop('target', axis=1)\n",
    "    y_train = pheme['target']\n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_test1 = twitter.iloc[:1490].drop('target', axis=1)\n",
    "    X_test1_text = np.array([text for text in X_test1['e_text']])\n",
    "    X_test2 = twitter.iloc[1490:].drop('target', axis=1)\n",
    "    X_test2_text = np.array([text for text in X_test2['e_text']])\n",
    "    y_test1 = twitter.iloc[:1490]['target']\n",
    "    y_test2 = twitter.iloc[1490:]['target']\n",
    "    baseline = optimize_model(\"Baseline\", X_train_text, y_train)\n",
    "    evaluate_model(baseline, X_test1_text, y_test1)\n",
    "    evaluate_model(baseline, X_test2_text, y_test2)\n",
    "\n",
    "make_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.3038961038961039]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.19s/trial, best loss: 0.18701298701298696]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.22s/trial, best loss: 0.18701298701298696]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.46s/trial, best loss: 0.18701298701298696]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.04s/trial, best loss: 0.18701298701298696]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.26s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.10s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.05s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.98s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.34s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.06s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.15s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.94s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.08s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.99s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.40s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.08s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.12s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.21s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.34s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.15s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.88s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.11s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 31/31 [00:01<00:00,  2.00s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.90s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.11s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.24s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.12s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.87s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.91s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.06s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.19s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.15s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.99s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.98s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 43/43 [00:04<00:00,  4.70s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.17s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.97s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.17s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.16s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.06s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.89s/trial, best loss: 0.18441558441558437]\n",
      "100%|██████████| 50/50 [00:04<00:00,  4.75s/trial, best loss: 0.18441558441558437]\n",
      "{'learner': SVC(C=1.7471913774684704, coef0=0.4669858603118654,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.005570264641213312), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Accuracy: 81.08 %\n",
      "F1: 80.95 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ONLY PHEME\n",
    "from hpsklearn import svc \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make baseline trained on all data\n",
    "pheme['e_text'] = X.tolist()\n",
    "pheme_train = pheme.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(pheme, pheme['target'], test_size = 0.2, random_state = 42)\n",
    "X_train_text = np.array([text for text in X_train['e_text']])\n",
    "X_test_text = np.array([text for text in X_test['e_text']])\n",
    "baseline = optimize_model(\"Baseline\", X_train_text, y_train)\n",
    "evaluate_model(baseline, X_test_text, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"pheme_cats\\pheme_categories_organised.json\"\n",
    "f = open(file_name)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple datasets\n",
    "confidence_threshold = 0.2\n",
    "size_threshold = 50\n",
    "train_set = pheme\n",
    "\n",
    "def train_svms(dataset, confidence_threshold, size_threshold, train_set):\n",
    "    file_name = f\"{dataset}_cats\\\\{dataset}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    trained_svms = {}\n",
    "    for key in data.keys():\n",
    "        svm_name = f\"svm_{key}\"\n",
    "        cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "        if len(cat_entries) < size_threshold:\n",
    "            print(f\"Skipped category: {key} due to low numbers\")\n",
    "            continue\n",
    "        all_in_cat = train_set.filter(axis=0, items=cat_entries)\n",
    "        X_train = all_in_cat.drop('target', axis=1)\n",
    "        y_train = all_in_cat['target']\n",
    "        #print(np.unique(all_in_cat[\"target\"]))\n",
    "        if (len(np.unique(all_in_cat[\"target\"])) <= 1):\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        try:\n",
    "            svm_name = optimize_model(svm_name, X_train_text, y_train)\n",
    "        except:\n",
    "            print(f\"error training {key} svm, skipping\")\n",
    "            continue\n",
    "        trained_svms[key] = svm_name\n",
    "        print(f\"Created SVM trained in category: {key}\")\n",
    "    return trained_svms\n",
    "\n",
    "#trained_svms = train_svms(\"pheme\", confidence_threshold, size_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Subjects/War & Conflict 2432 2432\n",
      "News 2555 2555\n",
      "Sensitive Subjects/Death & Tragedy 1326 1326\n",
      "Sensitive Subjects/Violence & Abuse 2573 2573\n",
      "Arts & Entertainment 1054 1054\n",
      "Sensitive Subjects/Other 1208 1208\n",
      "People & Society 955 955\n",
      "Law & Government 1325 1325\n",
      "Online Communities 1111 1111\n",
      "Books & Literature 30 30\n",
      "Reference 97 97\n",
      "Sensitive Subjects/Firearms & Weapons 60 60\n",
      "Sensitive Subjects/Accidents & Disasters 435 435\n",
      "Jobs & Education 17 17\n",
      "Health 81 81\n",
      "Business & Industrial 38 38\n",
      "Autos & Vehicles 2 2\n",
      "Food & Drink 15 15\n",
      "Travel & Transportation 299 299\n",
      "Hobbies & Leisure 16 16\n",
      "Games 0 0\n",
      "Pets & Animals 7 7\n",
      "Sports 50 50\n",
      "Beauty & Fitness 1 1\n",
      "Science 2 2\n",
      "Computers & Electronics 10 10\n",
      "Sensitive Subjects/Recreational Drugs 1 1\n",
      "Shopping 5 5\n",
      "Internet & Telecom 3 3\n",
      "Adult 0 0\n",
      "Finance 3 3\n",
      "Sensitive Subjects/Self-Harm 0 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"pheme_cats\\\\pheme_categories_organised.json\"\n",
    "f = open(file_name)\n",
    "data = json.load(f)\n",
    "\n",
    "confidence_threshold = 0.2\n",
    "for key in data.keys():\n",
    "    entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "    all_in_cat = pheme.filter(axis=0, items=entries)\n",
    "    t = 0\n",
    "    f=0\n",
    "    for e in all_in_cat[\"target\"]:\n",
    "        if e:\n",
    "            t += 1\n",
    "        else:\n",
    "            f += 1\n",
    "    print(key, len(entries), len(all_in_cat))\n",
    "    #print(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.10526315789473684]\n",
      "{'learner': SVC(C=0.7878111597060783, coef0=0.23213917415351404,\n",
      "    decision_function_shape='ovo', degree=1, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.004836969013937995), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.1610169491525424]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.1610169491525424]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.1610169491525424]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.1610169491525424]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.1610169491525424]\n",
      "{'learner': SVC(C=0.8596848116721758, coef0=0.4042616456365805,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=2.9029958606502465e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.2666666666666667]\n",
      "{'learner': SVC(C=0.8302226827564644, coef0=0.5402281088938474,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=4.145267408167087e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.10769230769230764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.10769230769230764]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.10769230769230764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.10769230769230764]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.10769230769230764]\n",
      "{'learner': SVC(C=1.007749701845727, coef0=0.30299050788694315,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.007400211431329381), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "{'learner': SVC(C=0.940896111302461, coef0=0.08937123285588366, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.004447228771611622), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.06666666666666665]\n",
      "{'learner': SVC(C=1.0384811839293009, coef0=0.8541909066156749, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0002637150601013791), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.22499999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.026442650539698, coef0=0.2663348809560929,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0014064140838670033), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.16129032258064513]\n",
      "{'learner': SVC(C=0.9810732345002954, coef0=0.9092377730732003, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.9403152809138563e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.123713558485219, coef0=0.9206564148242938,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=8.520131898435061e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "{'learner': SVC(C=0.8329228304079312, coef0=0.3596204967033899, degree=4, probability=True,\n",
      "    random_state=42, tol=0.0047923115191107575), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "{'learner': SVC(C=0.9890668503112353, coef0=0.979939706103198, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.002846590874976982), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=1.6250680062467588, coef0=0.378290150189188, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00032257116605622943), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Shopping\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=0.9932964403433916, coef0=0.5784351784978766, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=6.146371016384973e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n"
     ]
    }
   ],
   "source": [
    "# ONLY PHEME\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "confidence_threshold = 0.2\n",
    "size_threshold = 50\n",
    "\n",
    "X_test = pd.DataFrame(columns = pheme.columns)\n",
    "y_test = []\n",
    "\n",
    "trained_svms = {}\n",
    "trained_cats = []\n",
    "for key in data.keys():\n",
    "    svm_name = f\"svm_{key}\"\n",
    "    cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "    if len(cat_entries) < size_threshold:\n",
    "        print(f\"Skipped category: {key} due to low numbers\")\n",
    "        continue\n",
    "    all_in_cat = pheme.filter(axis=0, items=cat_entries)\n",
    "    X_train, X_te, y_train, y_te = train_test_split(all_in_cat, all_in_cat['target'], test_size = 0.2, random_state = 42)\n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)\n",
    "    X_test = pd.concat([X_test, X_te])\n",
    "    for target in y_te:\n",
    "        y_test.append(target)\n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    svm_name = optimize_model(svm_name, X_train_text, y_train)\n",
    "    trained_svms[key] = svm_name\n",
    "    trained_cats.append(key)\n",
    "    print(f\"Created SVM trained in category: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_points(trained_svms, test_cats, test_data):\n",
    "    test_points = test_data\n",
    "    test_file_name = test_cats\n",
    "    f = open(test_file_name)\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    final_predictions = []\n",
    "    final_predictions2 = []\n",
    "    for i in tqdm(range(len(test_points))):\n",
    "        point = test_points.iloc[i]\n",
    "        point_text = np.array([text for text in point['e_text']])\n",
    "        topics = test_data[str(point[\"entry\"])]\n",
    "        topic_weights = {}\n",
    "        for topic in topics:\n",
    "            main_topic = topic.split(\"/\")[1]\n",
    "            if topics[topic] < confidence_threshold or main_topic not in trained_svms.keys():\n",
    "                continue\n",
    "            if main_topic in topic_weights:\n",
    "                topic_weights[main_topic] += topics[topic]\n",
    "            else:\n",
    "                topic_weights[main_topic] = topics[topic]\n",
    "        #print(topic_weights) \n",
    "        model_predictions = []\n",
    "        for topic in topic_weights:\n",
    "            model = trained_svms[topic]\n",
    "            pred = model.predict(point_text.reshape(1,-1))\n",
    "            #model_predictions.append((pred[0], topic_weights[topic]))\n",
    "            model_predictions.append((pred[0], 1))\n",
    "        #print(model_predictions)\n",
    "        true_mark = 0\n",
    "        false_mark = 0\n",
    "        for pred, score in model_predictions:    \n",
    "            if pred == True:\n",
    "                true_mark += score\n",
    "            else:\n",
    "                false_mark += score\n",
    "        #print(mark)\n",
    "        if (true_mark > false_mark):\n",
    "            final_predictions.append(True)\n",
    "        else:\n",
    "            final_predictions.append(False)\n",
    "        max = 0\n",
    "        final_pred = True\n",
    "        for pred, score in model_predictions:\n",
    "            if score > max:\n",
    "                final_pred = pred\n",
    "        final_predictions2.append(final_pred)\n",
    "    return final_predictions, final_predictions2\n",
    "             \n",
    "def check_score(test, pred):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(train_dataset, confidence_threshold, size_threshold, train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    train_set = pd.concat([X_train, y_train], axis=1)\n",
    "    svms = train_svms(train_dataset, confidence_threshold, size_threshold, train_set)\n",
    "\n",
    "    results = []\n",
    "    train_cats = f\"{train_dataset}_categories.json\"\n",
    "    predictions1, predictions2 = predict_points(svms, train_cats, X_val)\n",
    "    results.append(check_score(predictions1, y_val))\n",
    "    \n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_cat_file = f\"{test_cat}_categories.json\"\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_target = test_set[\"target\"]\n",
    "        predictions1, predictions2 = predict_points(svms, test_cat_file, test_data)\n",
    "        results.append((test_name, check_score(predictions1, test_target)))\n",
    "    return results\n",
    "\n",
    "def run_tests(tests, confidence_threshold, size_threshold):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_results(train[1], confidence_threshold, size_threshold, train[0], t)))\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")\n",
    "twitter15 = twitter.iloc[:1491]\n",
    "twitter16 = twitter.iloc[1491:]\n",
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.49s/trial, best loss: 0.2743589743589744]\n",
      " 50%|█████     | 1/2 [00:01<?, ?trial/s, best loss=?]\n",
      "{'learner': SVC(C=1.1046900780257327, coef0=0.7644086587301252, degree=4, probability=True,\n",
      "    random_state=42, tol=2.3763710716736916e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.4240196078431373]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.66s/trial, best loss: 0.4240196078431373]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.51s/trial, best loss: 0.4240196078431373]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.4240196078431373]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.31s/trial, best loss: 0.4240196078431373]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.32s/trial, best loss: 0.4142156862745098]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.71s/trial, best loss: 0.4142156862745098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  2.87s/trial, best loss: 0.4142156862745098]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.82s/trial, best loss: 0.4142156862745098]\n"
     ]
    }
   ],
   "source": [
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n",
    "results1 = run_tests(tests, 0.2, 50)\n",
    "results2 = run_tests(tests, 0.5, 20)\n",
    "results3 = run_tests(tests, 0.2, 200)\n",
    "results4 = run_tests(tests, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(76.73, 71.42),\n",
       "   ('twitter15', (51.51, 43.87)),\n",
       "   ('twitter16', (54.96, 47.21))]),\n",
       " ('twitter15',\n",
       "  [(70.23, 68.71), ('PHEME', (59.05, 49.53)), ('twitter16', (56.79, 51.14))]),\n",
       " ('twitter16',\n",
       "  [(78.66, 78.3), ('PHEME', (56.81, 55.09)), ('twitter15', (56.07, 53.25))])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.70s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 2/2 [00:08<00:00,  8.81s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 3/3 [00:05<00:00,  5.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 5/5 [00:06<00:00,  6.16s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 6/6 [00:08<00:00,  8.19s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 7/7 [00:12<00:00, 12.87s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.87s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 9/9 [00:08<00:00,  8.20s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.07s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.78s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.38s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.86s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 14/14 [00:08<00:00,  8.95s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 15/15 [00:06<00:00,  6.18s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 16/16 [00:06<00:00,  6.59s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 17/17 [00:06<00:00,  6.06s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 18/18 [00:06<00:00,  6.33s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 19/19 [00:06<00:00,  6.89s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 20/20 [00:06<00:00,  6.45s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 21/21 [00:06<00:00,  6.42s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 22/22 [00:06<00:00,  6.80s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 23/23 [00:05<00:00,  5.52s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 24/24 [00:06<00:00,  6.02s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 25/25 [00:06<00:00,  6.66s/trial, best loss: 0.15369649805447472]\n",
      "{'learner': SVC(C=1.2007340688965829, coef0=0.41195154588714744, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0021174726338347707), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:05<06:11, 185.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.14s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.03s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.20s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.13s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "{'learner': SVC(C=0.5853585639125682, coef0=0.9129795392049047,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=2.2560165272510383e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:59<01:48, 108.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "{'learner': SVC(C=0.9906379338992914, coef0=0.5764761568576748, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.617804258277811e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:46<00:00, 95.48s/it] \n"
     ]
    }
   ],
   "source": [
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc_mod*100)), float(\"{0:.2f}\".format(f1_mod*100))\n",
    "\n",
    "\n",
    "def run_baseline_tests(tests):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_baseline_results(train[0], tests)))\n",
    "    return test_results\n",
    "\n",
    "def get_baseline_results(train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_val_text = np.array([text for text in X_val['e_text']])\n",
    "    baseline = optimize_model(\"svm\", X_train_text, y_train)\n",
    "    results = []\n",
    "    results.append(evaluate_baseline(baseline, X_val_text, y_val))\n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_data_text = np.array([text for text in test_data['e_text']])\n",
    "        test_target = test_set[\"target\"]\n",
    "        results.append((test_name, evaluate_baseline(baseline, test_data_text, test_target)))\n",
    "    return results\n",
    "\n",
    "baseline_results = run_baseline_tests(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(83.5, 82.24),\n",
       "   ('PHEME', (94.09, 93.64)),\n",
       "   ('twitter15', (50.17, 47.63)),\n",
       "   ('twitter16', (61.69, 59.78))]),\n",
       " ('twitter15',\n",
       "  [(81.61, 81.6),\n",
       "   ('PHEME', (55.7, 51.97)),\n",
       "   ('twitter15', (95.91, 95.91)),\n",
       "   ('twitter16', (62.3, 60.07))]),\n",
       " ('twitter16',\n",
       "  [(74.39, 74.39),\n",
       "   ('PHEME', (61.29, 60.87)),\n",
       "   ('twitter15', (56.2, 55.43)),\n",
       "   ('twitter16', (87.52, 87.52))])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/trial, best loss: 0.4969199178644764]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.56s/trial, best loss: 0.4969199178644764]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.47s/trial, best loss: 0.4887063655030801]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.45s/trial, best loss: 0.4887063655030801]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.38s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.74s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.40s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.79s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.37s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.57s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.59s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.46s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.50s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.79s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.38s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.30s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.41s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.80s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.41s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.57s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.34s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.60s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.33s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 28/28 [00:05<00:00,  5.65s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.83s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.32s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.50s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.70s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.47s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.60s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.52s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.32s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.39s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.23s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.24s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.37s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.31s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.23s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.58s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.91s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.26s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.81s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.80s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.83s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.29s/trial, best loss: 0.2813141683778234]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.77s/trial, best loss: 0.2813141683778234]\n",
      "{'learner': SVC(C=0.6513014423079841, coef0=0.221376106013789, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00011969660070096799), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.38s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.68s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.09s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.89s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.73s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.10s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.55s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.86s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.24s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.70s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.14s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.87s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.40508806262230923]\n",
      "100%|██████████| 15/15 [00:05<00:00,  5.84s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.14s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.48s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.63s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.40s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.78s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.31s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.28s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.75s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.45s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.58s/trial, best loss: 0.40313111545988256]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.74s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.72s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.35s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 29/29 [00:03<00:00,  3.02s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.66s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.75s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.56s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.81s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.88s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.72s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.47s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.78s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.67s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.68s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.83s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.68s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.33s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.28s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.85s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 45/45 [00:03<00:00,  3.16s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.59s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.70s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 48/48 [00:05<00:00,  5.56s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.65s/trial, best loss: 0.39921722113502933]\n",
      "100%|██████████| 50/50 [00:03<00:00,  3.06s/trial, best loss: 0.39921722113502933]\n",
      "{'learner': SVC(C=1.0543080631801196, coef0=0.49084615076292926, degree=5, probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.3124251746752656e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.3308270676691729]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.03s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.27s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 10/10 [00:01<00:00,  2.00s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.19s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.89s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.87s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.82s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.99s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 21/21 [00:01<00:00,  2.00s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.94s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.02s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.85s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.07s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.83s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.87s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.90s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.99s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.89s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.08s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.93s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.82s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.96s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.02s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.95s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.95s/trial, best loss: 0.2969924812030075]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.06s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.85s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.07s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.95s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.85s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.98s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.97s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.92s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.90s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.85s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.04s/trial, best loss: 0.27819548872180455]\n",
      "{'learner': SVC(C=1.3168111038615988, coef0=0.11405124277432921, degree=2, gamma='auto',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0001598885178188241), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/trial, best loss: 0.4271844660194175]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.13s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.87s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.87s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.79s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.82s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.21s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.58s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.51s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.04s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.35s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.38s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.44s/trial, best loss: 0.4]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.31s/trial, best loss: 0.4]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.43s/trial, best loss: 0.4]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.55s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.87s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 20/20 [00:03<00:00,  3.24s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.42s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 22/22 [00:03<00:00,  3.19s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.07s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.90s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.89s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.59s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.54s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.68s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.92s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.53s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.65s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.61s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.71s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 34/34 [00:03<00:00,  3.13s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.96s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.89s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.81s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.38s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 39/39 [00:03<00:00,  3.15s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.52s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.47s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 42/42 [00:03<00:00,  3.13s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.88s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.72s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.85s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.93s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.42s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.86s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.72s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.85s/trial, best loss: 0.38834951456310685]\n",
      "{'learner': SVC(C=1.260597771109319, coef0=0.9715074722472038,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.006198525390333088), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.43s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.39336492890995256]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.77s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.74s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.79s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.71s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.72s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.69s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.78s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.82s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.78s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.80s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.70s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.78s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.72s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.71s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.79s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.76s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.37s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.72s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.79s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.76s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.82s/trial, best loss: 0.3364928909952607]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.75s/trial, best loss: 0.3364928909952607]\n",
      "{'learner': SVC(C=0.7688758047191548, coef0=0.5848159135118272,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0084288303268775), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3347107438016529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.3347107438016529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.34s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.78s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.85s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.04s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.73s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.81s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.75s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.78s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.32s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.81s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.84s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.77s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.84s/trial, best loss: 0.30578512396694213]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.74s/trial, best loss: 0.30578512396694213]\n",
      "{'learner': SVC(C=1.3308724163750734, coef0=0.17899951010308468,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.005274030850767885), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.01s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 17/17 [00:03<00:00,  3.59s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.75s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.95s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.01s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.73s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.70s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.74s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.96s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.74s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.74s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "{'learner': SVC(C=1.2743958269956628, coef0=0.8203915772527504,\n",
      "    decision_function_shape='ovo', degree=5, probability=True, random_state=42,\n",
      "    shrinking=False, tol=6.15107961077445e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.41132075471698115]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.32830188679245287]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.11s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.13s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.96s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.05s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.08s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.95s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.00s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.05s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.95s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.82s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.83s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.97s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.19s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.92s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.82s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.06s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.86s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.87s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.80s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.83s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.96s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.02s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.81s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.94s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.00s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.83s/trial, best loss: 0.2943396226415095]\n",
      "{'learner': SVC(C=0.5115133015403472, coef0=0.30905673621326335,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0001497646286017492), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.11210762331838564]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.79s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.80s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.79s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.70s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.79s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.81s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.80s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.20s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "{'learner': SVC(C=0.7584378543081679, coef0=0.9032768667157699,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.000621890807613539), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.75]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.75]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.35]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.35]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.35]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.35]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.68s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.84s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.63s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.62s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.58s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.60s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.60s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.61s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.60s/trial, best loss: 0.15000000000000002]\n",
      "{'learner': SVC(C=1.1570536243815606, coef0=0.044564701807964235, degree=4, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42,\n",
      "    tol=2.550690931541687e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.1064689039702595, coef0=0.9325793421301135, degree=1, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00025376865924578874), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.3793103448275862]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.367816091954023]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.62s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.67s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.61s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.64s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.68s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.64s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.65s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.64s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.63s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.68s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.63s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.62s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.69s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.84s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.66s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.67s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.65s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.65s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.65s/trial, best loss: 0.32183908045977017]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.68s/trial, best loss: 0.32183908045977017]\n",
      "{'learner': SVC(C=1.1968678408692033, coef0=0.7893198792529609,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0007885105156702967), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.58s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.64s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.63s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.64s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.58s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.67s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.63s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.65s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.62s/trial, best loss: 0.17647058823529416]\n",
      "{'learner': SVC(C=0.9173096718153845, coef0=0.5803409503974821, degree=2, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.5819173487868635e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.44999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.61s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.65s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.64s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.64s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.68s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.68s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.67s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.65s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.60s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.69s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.65s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.66s/trial, best loss: 0.41666666666666663]\n",
      "{'learner': SVC(C=1.0001930995324642, coef0=0.8375915287935093,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=4.035155747552827e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.948816945194368, coef0=0.08565168068233076,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.4585107971833032e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2308/2308 [00:01<00:00, 2221.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5274725274725275]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.97s/trial, best loss: 0.4908424908424909]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.92s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.94s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.92s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.88s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.92s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.96s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.82s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.96s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.87s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.87s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.84s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.87s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.91s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.98s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.85s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.96s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.98s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.95s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.81s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.79s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.91s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 44/44 [00:01<00:00,  2.00s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.88s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.88s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.82s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.82s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.99s/trial, best loss: 0.47619047619047616]\n",
      "{'learner': SVC(C=1.2856268742727377, coef0=0.023167702769803178, degree=5,\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.984701739003452e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.3835616438356164]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.3835616438356164]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.60s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.68s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.62s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.66s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.61s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.63s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.64s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.70s/trial, best loss: 0.17808219178082196]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.65s/trial, best loss: 0.17808219178082196]\n",
      "{'learner': SVC(C=0.645173107710793, coef0=0.5991628133297658,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', probability=True,\n",
      "    random_state=42, tol=2.641275981333177e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.76]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.76]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.76]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.76]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.64]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.64]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.64]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.64]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.54]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.54]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.54]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.54]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.54]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.54]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.54]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.54]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.62s/trial, best loss: 0.54]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.54]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.60s/trial, best loss: 0.52]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.62s/trial, best loss: 0.52]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.52]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.62s/trial, best loss: 0.52]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.52]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.52]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.52]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.59s/trial, best loss: 0.52]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.59s/trial, best loss: 0.52]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "{'learner': SVC(C=1.161749847175693, coef0=0.5498646417638353,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.003556690266504431), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.24336283185840712]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.24336283185840712]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.24336283185840712]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.85s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.89s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.84s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.86s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.79s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.88s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.84s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.86s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.61s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.78s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.79s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.94s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.78s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.82s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.82s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.79s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.80s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.89s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.90s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.87s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.93s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.79s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.87s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.75s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.73s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.71s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.82s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.77s/trial, best loss: 0.23451327433628322]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.78s/trial, best loss: 0.23451327433628322]\n",
      "{'learner': SVC(C=0.8208348580834891, coef0=0.382835580320222, degree=4, kernel='sigmoid',\n",
      "    probability=True, random_state=42, tol=1.4683770834711875e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5352112676056338]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.55s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.55s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.60s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.60s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.55s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.56s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.59s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.59s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.57s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.61s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.60s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.59s/trial, best loss: 0.3661971830985915]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.59s/trial, best loss: 0.3661971830985915]\n",
      "{'learner': SVC(C=0.5257999298737155, coef0=0.6883551453537111, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=2.5188955221652302e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.55s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.56s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.54s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.56s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.56s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.54s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.54s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.54s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.55s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.57s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.56s/trial, best loss: 0.18181818181818177]\n",
      "{'learner': SVC(C=1.1006337043551113, coef0=0.6967944137728588, degree=5, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0035262247200894548), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/trial, best loss: 0.022727272727272707]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0431977572886562, coef0=0.27282573721566006, degree=5, probability=True,\n",
      "    random_state=42, shrinking=False, tol=4.471431340091482e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.2948717948717948]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.2948717948717948]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2948717948717948]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.57s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.64s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.81s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.62s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.61s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.65s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.59s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.62s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.60s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.64s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.58s/trial, best loss: 0.28205128205128205]\n",
      "{'learner': SVC(C=0.9116756363128845, coef0=0.037878662572859656,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0067720448987691854), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.53s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8562898106255249, coef0=0.840840853620935, degree=2, gamma='auto',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.4941009276781259e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.4852941176470589]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.56s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.56s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.3088235294117647]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.55s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.56s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.57s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.57s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.70s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.57s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.75s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "{'learner': SVC(C=0.9499708235721182, coef0=0.6564947997037273,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0008203461559186878), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.53s/trial, best loss: 0.0]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0692510508228816, coef0=0.3486404301570366, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00010614665998132123), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.55s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.52s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.55s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.56s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.55s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.54s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.56s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.57s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.54s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.54s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.53s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.56s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.55s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.59s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.55s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.54s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.58s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.54s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.54s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.58s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.58s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.54s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.57s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.57s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.60s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.57s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.58s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.60s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.67s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.56s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.59s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.57s/trial, best loss: 0.5238095238095238]\n",
      "{'learner': SVC(C=1.3627612238401132, coef0=0.04784898590421438, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=6.482132701807342e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.61s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.57s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.57s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.57s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.57s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.54s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.62s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.59s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.53s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.58s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.55s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.56s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.57s/trial, best loss: 0.6666666666666667]\n",
      "{'learner': SVC(C=0.8346204519409784, coef0=0.17772035681096954, degree=5, probability=True,\n",
      "    random_state=42, tol=0.0028477770511268507), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2308/2308 [00:00<00:00, 3154.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/trial, best loss: 0.4989733059548255]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.3141683778234087]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.17s/trial, best loss: 0.2997946611909651]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.78s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.58s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.40s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.56s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.64s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.71s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.18s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.40s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.63s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.23s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.45s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.54s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.68s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.27s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.73s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.72s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.24s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.85s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.51s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.41s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.46s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.33s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.90s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.68s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.51s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.24s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.13s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.79s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.21s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.39s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.39s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.18s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.22s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.30s/trial, best loss: 0.29363449691991783]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.14s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.29s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.93s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.24s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.30s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.45s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.67s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.49s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.22s/trial, best loss: 0.2854209445585215]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.43s/trial, best loss: 0.2854209445585215]\n",
      "{'learner': SVC(C=0.6338939840231934, coef0=0.9021210134862492, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.00048198018135909963), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/trial, best loss: 0.47553816046966735]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.68s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.56s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.41s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.61s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.60s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.43s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.74s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.73s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.97s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.73s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.05s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.64s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.94s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.57s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 20/20 [00:03<00:00,  3.06s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.32s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.78s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.84s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.39s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.39s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.25s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.33s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 28/28 [00:03<00:00,  3.01s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.76s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.51s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.38s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 32/32 [00:03<00:00,  3.03s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.62s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.37s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.59s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 36/36 [00:03<00:00,  3.01s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.37s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.73s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.36s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.67s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.46s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.50s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.29s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.89s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.25s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.23s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.50s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.33s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.60s/trial, best loss: 0.401174168297456]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.73s/trial, best loss: 0.401174168297456]\n",
      "{'learner': SVC(C=1.1523490477840028, coef0=0.9804616013446563, degree=2, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00656562076745261), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.3721804511278195]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.00s/trial, best loss: 0.33834586466165417]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.02s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.98s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.04s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.03s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.96s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.90s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.93s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.84s/trial, best loss: 0.30827067669172936]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.04s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.78s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.02s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.84s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.89s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.84s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.87s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.81s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.92s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.97s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.95s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.82s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.84s/trial, best loss: 0.30451127819548873]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.02s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.95s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.84s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.92s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.85s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.78s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.90s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.92s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.90s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.82s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.96s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.91s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.93s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.82s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.98s/trial, best loss: 0.29323308270676696]\n",
      "{'learner': SVC(C=1.1433430331127474, coef0=0.8123766690091517, degree=4, gamma='auto',\n",
      "    probability=True, random_state=42, tol=0.00011191224093271708), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.67s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.08s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.82s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.64s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.15s/trial, best loss: 0.40582524271844655]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.51s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.70s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.33s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 11/11 [00:07<00:00,  7.37s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.84s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.80s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 14/14 [00:07<00:00,  7.38s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.04s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.65s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.81s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.92s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.48s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.47s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.72s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.44s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.40s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.42s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.43s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 26/26 [00:03<00:00,  3.12s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.54s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.83s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.81s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.92s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.58s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.60s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.41s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.71s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.41s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 36/36 [00:03<00:00,  3.05s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 37/37 [00:07<00:00,  7.23s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.67s/trial, best loss: 0.3980582524271845]\n",
      "100%|██████████| 39/39 [00:03<00:00,  3.05s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.52s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.84s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.83s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.93s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.84s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.74s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.98s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.82s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.63s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.57s/trial, best loss: 0.3961165048543689]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.84s/trial, best loss: 0.3961165048543689]\n",
      "{'learner': SVC(C=1.4786661232534128, coef0=0.9089744588527925, degree=2, gamma='auto',\n",
      "    probability=True, random_state=42, tol=7.306009386739419e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.3981042654028436]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.76s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.73s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.71s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.73s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.71s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.67s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.72s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.76s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.66s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.72s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.73s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.11s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.76s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.68s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.67s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.77s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.79s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.79s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.70s/trial, best loss: 0.35545023696682465]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.75s/trial, best loss: 0.35545023696682465]\n",
      "{'learner': SVC(C=1.1157852957621688, coef0=0.6366927606071192,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=8.340948524969364e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.3347107438016529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.31404958677685946]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.74s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.75s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.72s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.74s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.72s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.75s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.98s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.77s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.76s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.76s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.71s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.75s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.69s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.69s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.69s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.68s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.72s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.80s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.77s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.69s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.77s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.73s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.70s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.73s/trial, best loss: 0.2975206611570248]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.78s/trial, best loss: 0.2975206611570248]\n",
      "{'learner': SVC(C=1.4003212363369593, coef0=0.7897188543164322,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.007443978182312748), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.62s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.71s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.62s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.66s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.65s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.70s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.72s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.69s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.67s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.68s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.63s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.64s/trial, best loss: 0.10471204188481675]\n",
      "{'learner': SVC(C=1.1520109525017783, coef0=0.3599082837401595,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0054812476054918405), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.44150943396226416]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.00s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.98s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.25s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 19/19 [00:03<00:00,  3.27s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.77s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.87s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.90s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.94s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.87s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.79s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.02s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.80s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.96s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.13s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.90s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.93s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.06s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.91s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.86s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.92s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.96s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.79s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.77s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.82s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.01s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.89s/trial, best loss: 0.2943396226415095]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.85s/trial, best loss: 0.2943396226415095]\n",
      "{'learner': SVC(C=0.8495036803110712, coef0=0.7742221648503609, degree=2, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42,\n",
      "    tol=0.0006894467000353695), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.12s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.76s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.67s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.77s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.73s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.72s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.17s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.70s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.71s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.67s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.70s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.68s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.67s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.74s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.67s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.68s/trial, best loss: 0.013452914798206317]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.69s/trial, best loss: 0.013452914798206317]\n",
      "{'learner': SVC(C=0.9930263379166381, coef0=0.9316347410857978, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.007800933646193212), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.8275862068965517]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.8275862068965517]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.367816091954023]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.367816091954023]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.367816091954023]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.56s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.61s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.58s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.58s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.65s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.61s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.57s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.57s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.62s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.77s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.68s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.62s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.62s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.64s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.58s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.59s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.63s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.60s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.58s/trial, best loss: 0.3563218390804598]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.63s/trial, best loss: 0.3563218390804598]\n",
      "{'learner': SVC(C=0.6423753091112516, coef0=0.566606987647331, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00039790088664349286), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/trial, best loss: 0.5166666666666666]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.4833333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.56s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.55s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.43333333333333335]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.56s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.56s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.59s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.60s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.60s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.56s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.64s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.56s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.59s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.55s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.56s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.65s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.57s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.55s/trial, best loss: 0.41666666666666663]\n",
      "{'learner': SVC(C=0.7685430475825104, coef0=0.43819031653310425, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.2272618305723804e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2308/2308 [00:00<00:00, 2464.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.47s/trial, best loss: 0.28115501519756836]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.02s/trial, best loss: 0.28115501519756836]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.63s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.24s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.59s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.15s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.91s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.17s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.11s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 10/10 [00:08<00:00,  8.95s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.65s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.78s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.07s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.76s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.21s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.63s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 17/17 [00:03<00:00,  3.16s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 18/18 [00:03<00:00,  3.66s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 19/19 [00:03<00:00,  3.21s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 20/20 [00:03<00:00,  3.10s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.16s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.60s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.12s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.61s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.12s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.69s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 27/27 [00:03<00:00,  3.15s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.88s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 29/29 [00:03<00:00,  3.12s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 30/30 [00:03<00:00,  3.12s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.56s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 32/32 [00:03<00:00,  3.03s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 33/33 [00:03<00:00,  3.67s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.94s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 35/35 [00:03<00:00,  3.35s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.79s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.89s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.95s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.92s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 40/40 [00:03<00:00,  3.01s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 41/41 [00:03<00:00,  3.16s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.68s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 43/43 [00:03<00:00,  3.09s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 44/44 [00:03<00:00,  3.12s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 45/45 [00:03<00:00,  3.45s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.69s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 47/47 [00:03<00:00,  3.14s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 48/48 [00:03<00:00,  3.28s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.83s/trial, best loss: 0.2613981762917933]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.83s/trial, best loss: 0.2613981762917933]\n",
      "{'learner': SVC(C=0.8298715294805021, coef0=0.3537008941573464,\n",
      "    decision_function_shape='ovo', degree=1, kernel='poly', probability=True,\n",
      "    random_state=42, tol=2.3987987903830595e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/trial, best loss: 0.5018007202881152]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.20s/trial, best loss: 0.5018007202881152]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.60s/trial, best loss: 0.4633853541416567]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.51s/trial, best loss: 0.4633853541416567]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.60s/trial, best loss: 0.4633853541416567]\n",
      "100%|██████████| 6/6 [00:05<00:00,  5.50s/trial, best loss: 0.4633853541416567]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.93s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.30s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 9/9 [00:04<00:00,  4.70s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 10/10 [00:05<00:00,  5.21s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.76s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.59s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.47s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.49s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 15/15 [00:04<00:00,  4.61s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 16/16 [00:04<00:00,  4.65s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 17/17 [00:04<00:00,  4.54s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 18/18 [00:04<00:00,  4.58s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 19/19 [00:04<00:00,  4.04s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.15s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 21/21 [00:05<00:00,  5.37s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 22/22 [00:04<00:00,  4.36s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.52s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 24/24 [00:04<00:00,  4.82s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.79s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 26/26 [00:05<00:00,  5.76s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 27/27 [00:04<00:00,  4.43s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 28/28 [00:05<00:00,  5.35s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 29/29 [00:04<00:00,  4.98s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 30/30 [00:04<00:00,  4.50s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 31/31 [00:04<00:00,  4.43s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 32/32 [00:03<00:00,  3.93s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 33/33 [00:04<00:00,  4.19s/trial, best loss: 0.404561824729892]\n",
      "100%|██████████| 34/34 [00:04<00:00,  4.12s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 35/35 [00:04<00:00,  4.60s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 36/36 [00:04<00:00,  4.15s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 37/37 [00:03<00:00,  3.53s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 38/38 [00:03<00:00,  3.48s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 39/39 [00:04<00:00,  4.92s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 40/40 [00:04<00:00,  4.54s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 41/41 [00:04<00:00,  4.53s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 42/42 [00:04<00:00,  4.14s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 43/43 [00:03<00:00,  3.49s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 44/44 [00:03<00:00,  3.53s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 45/45 [00:04<00:00,  4.08s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 46/46 [00:03<00:00,  3.87s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 47/47 [00:03<00:00,  3.94s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 48/48 [00:03<00:00,  3.57s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 49/49 [00:04<00:00,  4.72s/trial, best loss: 0.40336134453781514]\n",
      "100%|██████████| 50/50 [00:04<00:00,  4.59s/trial, best loss: 0.40336134453781514]\n",
      "{'learner': SVC(C=1.1994761989133202, coef0=0.6256175785135298, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=1.7817620903384215e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/trial, best loss: 0.50625]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.45s/trial, best loss: 0.50625]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.26s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.58s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.76s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.30s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.57s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.56s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.61s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.53s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.85s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.32s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.62s/trial, best loss: 0.4041666666666667]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.25s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.50s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 19/19 [00:03<00:00,  3.13s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.53s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.19s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.44s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.75s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.47s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.50s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.98s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.32s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.48s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 29/29 [00:02<00:00,  2.91s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.60s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 31/31 [00:02<00:00,  2.43s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.59s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.33s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.46s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.22s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.61s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.54s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.78s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.42s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 40/40 [00:03<00:00,  3.01s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.46s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.33s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.57s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 44/44 [00:03<00:00,  3.11s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.58s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.74s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.32s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.68s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.42s/trial, best loss: 0.37083333333333335]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.69s/trial, best loss: 0.37083333333333335]\n",
      "{'learner': SVC(C=1.0262069601155521, coef0=0.9908840317406732,\n",
      "    decision_function_shape='ovo', degree=1, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=9.734120768536178e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/trial, best loss: 0.42056074766355145]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.79s/trial, best loss: 0.42056074766355145]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.73s/trial, best loss: 0.41433021806853587]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.48s/trial, best loss: 0.41433021806853587]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.78s/trial, best loss: 0.41433021806853587]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.82s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.80s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.85s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.10s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.89s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.77s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.80s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.79s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.31s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.37s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.81s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 17/17 [00:03<00:00,  3.40s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 18/18 [00:03<00:00,  3.31s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 19/19 [00:03<00:00,  3.80s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 20/20 [00:03<00:00,  3.53s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.51s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.82s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.35s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 24/24 [00:03<00:00,  3.50s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.47s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.76s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 27/27 [00:03<00:00,  3.33s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.98s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 29/29 [00:03<00:00,  3.14s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 30/30 [00:03<00:00,  3.26s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 31/31 [00:03<00:00,  3.39s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 32/32 [00:03<00:00,  3.23s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.99s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 34/34 [00:03<00:00,  3.36s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 35/35 [00:03<00:00,  3.16s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 36/36 [00:03<00:00,  3.41s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 37/37 [00:03<00:00,  3.39s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.85s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.71s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 40/40 [00:03<00:00,  3.37s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 41/41 [00:03<00:00,  3.42s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 42/42 [00:03<00:00,  3.06s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 43/43 [00:03<00:00,  3.45s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.79s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.86s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.81s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 47/47 [00:03<00:00,  3.17s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 48/48 [00:03<00:00,  3.34s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 49/49 [00:03<00:00,  3.39s/trial, best loss: 0.40965732087227413]\n",
      "100%|██████████| 50/50 [00:03<00:00,  3.56s/trial, best loss: 0.40965732087227413]\n",
      "{'learner': SVC(C=0.9839371444472563, coef0=0.458753825092329,\n",
      "    decision_function_shape='ovo', degree=1, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.428077079108385e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.3943217665615142]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96s/trial, best loss: 0.3943217665615142]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3943217665615142]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.3943217665615142]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.01s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.06s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.97s/trial, best loss: 0.3690851735015773]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.92s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.99s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.79s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.91s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.81s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.82s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.95s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.91s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.84s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.90s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.91s/trial, best loss: 0.35015772870662465]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.82s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.99s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.85s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.94s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.78s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.87s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.92s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.04s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.97s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.96s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.91s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.85s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.91s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.83s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.81s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.03s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.80s/trial, best loss: 0.34384858044164035]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.92s/trial, best loss: 0.34384858044164035]\n",
      "{'learner': SVC(C=1.3704665867819124, coef0=0.17824084096638115, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0003895169197545405), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.3880266075388027]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.38137472283813745]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.05s/trial, best loss: 0.376940133037694]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.376940133037694]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.19s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.40s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.99s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.96s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.51s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.89s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.22s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.02s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.03s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.01s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.09s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.04s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.19s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.06s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.26s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.98s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.10s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.10s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 29/29 [00:01<00:00,  2.00s/trial, best loss: 0.3725055432372506]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.15s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.96s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.04s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.98s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.02s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.21s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.01s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.00s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.05s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.98s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.04s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.20s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.95s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.00s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.02s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.22s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.21s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.21s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.05s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.03s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.98s/trial, best loss: 0.36585365853658536]\n",
      "{'learner': SVC(C=0.7934712701209737, coef0=0.13850339392887234, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=5.006883961355365e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23295454545454541]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.81s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.92s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.87s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.94s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.00s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.87s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.88s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.93s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.79s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.86s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.91s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.93s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.91s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.81s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.85s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.99s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.79s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.84s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.87s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.83s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.81s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.91s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.88s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.80s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.85s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.96s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.93s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.81s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.98s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 48/48 [00:01<00:00,  2.00s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.84s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.81s/trial, best loss: 0.2272727272727273]\n",
      "{'learner': SVC(C=1.0537211535616229, coef0=0.7848872238035122, degree=4, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.003969899073947947), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.3862433862433863]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.26s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.01s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.13s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.15s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.29s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.43s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.37830687830687826]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.01s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.12s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.96s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.13s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 19/19 [00:04<00:00,  4.03s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.00s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.97s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.15s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.41s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.28s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.05s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.08s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.94s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 29/29 [00:04<00:00,  4.03s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.15s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 31/31 [00:01<00:00,  2.00s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.23s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 33/33 [00:02<00:00,  2.07s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 34/34 [00:02<00:00,  2.04s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.50s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 36/36 [00:04<00:00,  4.01s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.06s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 38/38 [00:02<00:00,  2.25s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.25s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 40/40 [00:02<00:00,  2.07s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.16s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 42/42 [00:02<00:00,  2.14s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 43/43 [00:02<00:00,  2.26s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.02s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.26s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 46/46 [00:02<00:00,  2.01s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.95s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 48/48 [00:02<00:00,  2.51s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.00s/trial, best loss: 0.373015873015873]\n",
      "100%|██████████| 50/50 [00:02<00:00,  2.45s/trial, best loss: 0.373015873015873]\n",
      "{'learner': SVC(C=1.2371733060858812, coef0=0.15899916376974443, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0062440670999240186), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/trial, best loss: 0.13010204081632648]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.13010204081632648]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.44s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.13s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.11s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.98s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.95s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.11734693877551017]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.01s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.11s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.10s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.96s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.09s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.96s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.01s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.95s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.92s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.11s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 26/26 [00:02<00:00,  2.09s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 27/27 [00:02<00:00,  2.05s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 28/28 [00:02<00:00,  2.07s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.99s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 30/30 [00:02<00:00,  2.34s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.95s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 32/32 [00:02<00:00,  2.00s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.96s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.92s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 35/35 [00:02<00:00,  2.01s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.03s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 37/37 [00:02<00:00,  2.07s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.97s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 39/39 [00:02<00:00,  2.11s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.99s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 41/41 [00:02<00:00,  2.11s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.91s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.88s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 44/44 [00:02<00:00,  2.03s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 45/45 [00:02<00:00,  2.00s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.98s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 47/47 [00:02<00:00,  2.10s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.99s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 49/49 [00:02<00:00,  2.14s/trial, best loss: 0.10969387755102045]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.98s/trial, best loss: 0.10969387755102045]\n",
      "{'learner': SVC(C=0.7624165595050049, coef0=0.8249377490920095, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.006066937499032547), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/trial, best loss: 0.6976744186046512]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.58s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.61s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.56s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.54s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.55s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.61s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "{'learner': SVC(C=0.7127011479187709, coef0=0.48015863412371396,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=7.913517939223367e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.24]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.24]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.24]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.24]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.24]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.53s/trial, best loss: 0.24]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.24]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.56s/trial, best loss: 0.24]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.24]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.58s/trial, best loss: 0.24]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.60s/trial, best loss: 0.24]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.62s/trial, best loss: 0.24]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.79s/trial, best loss: 0.24]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.59s/trial, best loss: 0.24]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.55s/trial, best loss: 0.24]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.57s/trial, best loss: 0.24]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.54s/trial, best loss: 0.24]\n",
      "{'learner': SVC(C=0.7476674077690533, coef0=0.6194654445350904, degree=5, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.00012751849944749537), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.35238095238095235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.58s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.60s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.59s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.62s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.62s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.58s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.59s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.64s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.58s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.66s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.59s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.58s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.58s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.64s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.61s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.62s/trial, best loss: 0.3142857142857143]\n",
      "{'learner': SVC(C=1.0486055500542015, coef0=0.5386507535949301,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=3.327317822026926e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.56s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.54s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.55s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.56s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.55s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.53s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.61s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.58s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.57s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.58s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.55s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.59s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.59s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.54s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.56s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.57s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.58s/trial, best loss: 0.21739130434782605]\n",
      "{'learner': SVC(C=1.2525308498509724, coef0=0.29005504112116476, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.2910323575664665e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.9047619047619048]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.53s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.56s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.56s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.61s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.60s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.59s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.54s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.56s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.55s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.57s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.58s/trial, best loss: 0.6190476190476191]\n",
      "{'learner': SVC(C=1.3710561067552922, coef0=0.002492173213523019,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.14086294080155e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "[False  True]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.6741573033707865]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.6741573033707865]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.57s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.56s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.57s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 29/29 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 30/30 [00:01<00:00,  1.57s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.59s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 32/32 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 33/33 [00:01<00:00,  1.58s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.59s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.62s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 39/39 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.59s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.60s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.58s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 43/43 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 44/44 [00:01<00:00,  1.64s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.65s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 46/46 [00:01<00:00,  1.61s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 47/47 [00:01<00:00,  1.63s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.72s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 49/49 [00:01<00:00,  1.59s/trial, best loss: 0.3370786516853933]\n",
      "100%|██████████| 50/50 [00:01<00:00,  1.66s/trial, best loss: 0.3258426966292135]\n",
      "{'learner': SVC(C=0.9568060506938484, coef0=0.7397078634401397, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0019168484181707529), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2308/2308 [00:00<00:00, 2458.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "result1 = run_test(0.2, 50, \"pheme\", \"twitter\")\n",
    "test_results.append(result1)\n",
    "result2 = run_test(0.5, 20, \"pheme\", \"twitter\")\n",
    "test_results.append(result2)\n",
    "result3 = run_test(0.2, 200, \"pheme\", \"twitter\")\n",
    "test_results.append(result3)\n",
    "result4 = run_test(0, 100, \"pheme\", \"twitter\")\n",
    "test_results.append(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52.77, 44.99), (51.3, 40.21), (52.64, 44.22), (54.42, 49.6)]\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
