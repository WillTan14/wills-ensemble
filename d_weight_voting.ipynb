{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamically weighted voting model for Rumour Detection\n",
    "Run all of the cells in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial dataset stuff\n",
    "nlp = spacy.load(\"spacy-twitter\") # out of function so you don't load it every time (it takes a while)\n",
    "\n",
    "# function for glove embeddings\n",
    "def embed_dataset(dataset_text):\n",
    "    encoded = np.array([nlp(text).vector for text in dataset_text])\n",
    "    return encoded.tolist()\n",
    "\n",
    "# function to load dataset from folder. Also embeds the text.\n",
    "def get_dataset(name):\n",
    "    \"\"\"\n",
    "    loads a dataset and embeds the text. text must be in column named \"text\".\n",
    "    datasets are in the folder datasets/\n",
    "    name must be a string that's matches the csv file in datasets\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(f'datasets/{name}.csv')\n",
    "    dataset.rename(columns = {\"Unnamed: 0\":\"entry\"}, inplace=True) #the entry label never carries over\n",
    "    dataset['e_text'] = embed_dataset(dataset['text'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(search_space, objective, evals):\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn = objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=evals,\n",
    "        timeout=120,\n",
    "        trials=trials,\n",
    "        verbose=False\n",
    "    )\n",
    "    set_params = space_eval(search_space, best_params)\n",
    "    score = trials.best_trial['result']['loss']\n",
    "    return set_params, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(dataset_name, train_set, confidence, size_limit, model_list):\n",
    "    \"\"\"\n",
    "    trains a set of pre-optimised models in each category. returns the best model for each category, in the form {'category': [modelscore, modelname, fittedmodel]}\n",
    "\n",
    "    dataset_name: a string with the name of the training set. used for calling the category file\n",
    "    train_set: the training set to use\n",
    "    confidence: the confidence required to consider an entry part of a category\n",
    "    size_limit: the number of entries needed in a category to consider that category for training\n",
    "    model_list: the list of models to train. in the form [(\"category\", \"model_name1\", model1), etc]\n",
    "    \"\"\"\n",
    "    file_name = f\"{dataset_name}_cats/{dataset_name}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    category_models = {} #this will be returned\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for category, model_name, model in model_list:\n",
    "        cat_entries = [int(i) for i in data[category].keys() if data[category][i] > confidence]\n",
    "        \n",
    "        # skip category if size of category is below limit\n",
    "        if len(cat_entries) < size_limit:\n",
    "            print(f\"Skipped category: {category} due to low numbers\")\n",
    "            continue\n",
    "        \n",
    "        category_data = train_set.filter(axis=0, items=cat_entries)\n",
    "\n",
    "        #split validation set\n",
    "        X = category_data.drop('target', axis=1)\n",
    "        y = category_data[\"target\"]\n",
    "        try:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
    "        except:\n",
    "            print(f\"Skipped category: {category} due to class issues\")\n",
    "            continue\n",
    "\n",
    "        # skip category if split only has one class\n",
    "        if (len(np.unique(y_train)) <= 1):\n",
    "            print(f\"Skipped category: {category} due to class issues\")\n",
    "            continue\n",
    "\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        X_val_text = np.array([text for text in X_val['e_text']])\n",
    "\n",
    "        model.fit(X_train_text, y_train)\n",
    "        \n",
    "        #print(f\"Trained models on {category}, added {model_name} to list\")\n",
    "        #add best model to list\n",
    "        category_models[category] = (0, model_name, model)\n",
    "    print(\"training complete\")\n",
    "    return category_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_points(trained_models, test_cat_file, X_test):\n",
    "    \"\"\"\n",
    "    predict points using the trained models. returns an array of the predictions\n",
    "\n",
    "    trained_models: the models trained in each category, in the form {category: [modelscore, modelname, fittedmodel]}\n",
    "    test_cat_file: the filepath to the organised category file\n",
    "    X_test: the test set X values\n",
    "    \"\"\"\n",
    "    #load category data\n",
    "    f = open(test_cat_file)\n",
    "    category_data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # return arrays\n",
    "    final_predictions = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    #embedded_text = np.array([text for text in X_test['e_text']])\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        test_point = X_test.iloc[i]\n",
    "        point_text = np.array(test_point['e_text'])\n",
    "        point_categories = category_data[str(test_point[\"entry\"])]\n",
    "\n",
    "        # get weights of each point's topic\n",
    "        topic_weights = {}\n",
    "        for category in point_categories:\n",
    "            main_category = category.split(\"/\")[1]\n",
    "            if main_category not in trained_models.keys():\n",
    "                continue\n",
    "            if main_category in topic_weights:\n",
    "                topic_weights[main_category] += point_categories[category]\n",
    "            else:\n",
    "                topic_weights[main_category] = point_categories[category]\n",
    "        \n",
    "        #make topic predictions\n",
    "        model_predictions = []\n",
    "        for category in topic_weights.keys():\n",
    "            modelscore, modelname, model = trained_models[category]\n",
    "            prediction = model.predict(point_text.reshape(1,-1))\n",
    "            score = topic_weights[category]\n",
    "            model_predictions.append((prediction[0], score, modelname, category))\n",
    "        all_predictions.append(model_predictions)\n",
    "        # aggregate predictions\n",
    "        truefalse_scores = {True: 0, False:0}\n",
    "        for prediction, modelscore, modelname, category in model_predictions:\n",
    "            truefalse_scores[prediction] += modelscore\n",
    "        \n",
    "        #determine final prediction\n",
    "        if truefalse_scores[True] > truefalse_scores[False]:\n",
    "            final_predictions.append(True)\n",
    "        else:\n",
    "            final_predictions.append(False)\n",
    "    return final_predictions, all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example list of optimized models. To optimize another set, run the \"model_optimizer.ipynb\" notebook, which saves optimized models in the \"optimized_models.txt\" file\n",
    "# Confidence = 0.2, Size = 200\n",
    "pheme_list_1 = [(\"Sensitive Subjects\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"News\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Arts & Entertainment\", \"SVM\", SVC(C=4.698902975596489, coef0=0.6532286328720177, degree=1, kernel='poly',\n",
    "    random_state=42, tol=0.0002825712853669414)),\n",
    "(\"People & Society\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Law & Government\", \"SVM\", SVC(C=4.698902975596489, coef0=0.6532286328720177, degree=1, kernel='poly',\n",
    "    random_state=42, tol=0.0002825712853669414)),\n",
    "(\"Online Communities\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Travel & Transportation\", \"SGD\", SGDClassifier(alpha=6.625365951494978e-05, eta0=0.016092453443433016,\n",
    "              l1_ratio=6.274029923848162e-07, learning_rate='constant',\n",
    "              loss='squared_epsilon_insensitive', penalty=None,\n",
    "              tol=0.00016645348991346068))]\n",
    "\n",
    "twitter_list_1 = [(\"People & Society\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Arts & Entertainment\", \"Logistic Regression\", LogisticRegression(C=1.021560581731338, l1_ratio=0.053120402058503435,\n",
    "                   max_iter=1000, n_jobs=-1, random_state=42, solver='saga',\n",
    "                   tol=2.682304820469642e-05)),\n",
    "(\"Law & Government\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"News\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Sensitive Subjects\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Online Communities\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596))]\n",
    "\n",
    "weibo_list_1 = [(\"Arts & Entertainment\", \"Random Forest\", RandomForestClassifier(criterion='entropy', max_depth=98, min_samples_leaf=4,\n",
    "                       min_samples_split=0.024120833051201357,\n",
    "                       n_estimators=564)),\n",
    "(\"People & Society\", \"SVM\", SVC(C=4.698902975596489, coef0=0.6532286328720177, degree=1, kernel='poly',\n",
    "    random_state=42, tol=0.0002825712853669414)),\n",
    "(\"Food & Drink\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Health\", \"MLP\", MLPClassifier(alpha=0.002473879041464472, beta_1=0.9253454029329639,\n",
    "              beta_2=0.953840203792704, epsilon=5.520262851757021e-06,\n",
    "              learning_rate_init=0.018859925116455643,\n",
    "              momentum=0.8861986589127533, power_t=0.7470184958011787,\n",
    "              solver='lbfgs', tol=0.0047626319743369425)),\n",
    "(\"News\", \"MLP\", MLPClassifier(alpha=0.002473879041464472, beta_1=0.9253454029329639,\n",
    "              beta_2=0.953840203792704, epsilon=5.520262851757021e-06,\n",
    "              learning_rate_init=0.018859925116455643,\n",
    "              momentum=0.8861986589127533, power_t=0.7470184958011787,\n",
    "              solver='lbfgs', tol=0.0047626319743369425)),\n",
    "(\"Sensitive Subjects\", \"KNN\", KNeighborsClassifier(metric='manhattan', n_jobs=-1, n_neighbors=12,\n",
    "                     p=2.3130968982898596)),\n",
    "(\"Law & Government\", \"Random Forest\", RandomForestClassifier(criterion='entropy', max_depth=98, min_samples_leaf=4,\n",
    "                       min_samples_split=0.024120833051201357,\n",
    "                       n_estimators=564)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score(test, pred, confusion=False):\n",
    "    \"\"\"\n",
    "    Returns the accuract and F1 of a model. Set confusion = True to see the confusion matrix.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    if confusion == True:\n",
    "        cm = confusion_matrix(test, pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "        disp.plot()\n",
    "        plt.show() \n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")\n",
    "weibo = get_dataset(\"weibo\")\n",
    "\n",
    "pheme_val = pheme.drop('target', axis=1)\n",
    "pheme_val_text = np.array([text for text in pheme_val['e_text']])\n",
    "pheme_target = pheme['target']\n",
    "twitter_val = twitter.drop('target', axis=1)\n",
    "twitter_val_text = np.array([text for text in twitter_val['e_text']])\n",
    "twitter_target = twitter['target']\n",
    "weibo_val = weibo.drop('target', axis=1)\n",
    "weibo_val_text = np.array([text for text in weibo_val['e_text']])\n",
    "weibo_target = weibo['target']\n",
    "\n",
    "def run_tests(training, training_name, confidence, size, model_list):\n",
    "    X = training.drop(\"target\", axis=1)\n",
    "    y = training[\"target\"]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42) \n",
    "    models = train_models(training_name, training, confidence, size, model_list)\n",
    "    category_file = f\"{training_name}_categories.json\"\n",
    "    val_pred = predict_points(models, category_file, X_val)\n",
    "    val_score = check_score(y_val, val_pred[0])\n",
    "\n",
    "    pheme_pred = predict_points(models, \"pheme_categories.json\", pheme_val)\n",
    "    pheme_score = check_score(pheme_target, pheme_pred[0])\n",
    "    twitter_pred = predict_points(models, \"twitter_categories.json\", twitter_val)\n",
    "    twitter_score = check_score(twitter_target, twitter_pred[0])\n",
    "    weibo_pred = predict_points(models, \"weibo_categories.json\", weibo_val)\n",
    "    weibo_score = check_score(weibo_target, weibo_pred[0])\n",
    "\n",
    "    return val_score, pheme_score, twitter_score, weibo_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:04<00:00, 317.90it/s]\n",
      "100%|██████████| 6425/6425 [00:09<00:00, 657.20it/s] \n",
      "100%|██████████| 2308/2308 [00:02<00:00, 903.25it/s]\n",
      "100%|██████████| 4664/4664 [00:03<00:00, 1487.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on 0.2 and 200:\n",
      "pheme Validation:\n",
      " Accuracy:  85.53 F1:  84.68\n",
      "PHEME Test Results:\n",
      " Accuracy:  85.35 F1:  84.55\n",
      "Twitter Test Results:\n",
      " Accuracy:  57.37 F1:  54.94\n",
      "Weibo Test Results:\n",
      " Accuracy:  48.31 F1:  40.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conf = 0.2\n",
    "size = 200\n",
    "dataset = pheme\n",
    "dataset_name = \"pheme\"\n",
    "models = pheme_list_1\n",
    "\n",
    "results = run_tests(dataset, dataset_name, conf, size, models)\n",
    "print(f\"Scores on {conf} and {size}:\")\n",
    "print(f\"{dataset_name} Validation:\\n\", \"Accuracy: \", results[0][0], \"F1: \", results[0][1])\n",
    "print(\"PHEME Test Results:\\n\", \"Accuracy:\", results[1][0], \"F1:\", results[1][1])\n",
    "print(\"Twitter Test Results:\\n\", \"Accuracy:\", results[2][0], \"F1:\", results[2][1])\n",
    "print(\"Weibo Test Results:\\n\", \"Accuracy:\", results[3][0], \"F1:\", results[3][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
