{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are trained on different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from hpsklearn import svc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"spacy-twitter\")\n",
    "\n",
    "def embed_dataset(dataset_text):\n",
    "    encoded = np.array([nlp(text).vector for text in dataset_text])\n",
    "    return encoded.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    dataset = pd.read_csv(f'datasets\\\\{name}.csv')\n",
    "    dataset.rename(columns = {\"Unnamed: 0\":\"entry\"}, inplace=True)\n",
    "    dataset['e_text'] = embed_dataset(dataset['text'])\n",
    "    return dataset\n",
    "\n",
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models  \n",
    "\n",
    "SVMs trained on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import svc\n",
    "\n",
    "def optimize_model(model, X_train, y_train):\n",
    "    mod = HyperoptEstimator(classifier=model,\n",
    "                            preprocessing=[],\n",
    "                            max_evals=15,\n",
    "                            trial_timeout=50,\n",
    "                            verbose=False)\n",
    "    mod.fit(X_train, y_train, random_state=42)\n",
    "    #print(mod.best_model())\n",
    "    return mod\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    print(\"Accuracy:\", float(\"{0:.2f}\".format(acc_mod*100)), \"%\")\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    print(\"F1:\", float(\"{0:.2f}\".format(f1_mod*100)), \"%\")\n",
    "    cm = confusion_matrix(y_test, pred_y)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "    disp.plot()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple datasets\n",
    "confidence_threshold = 0.2\n",
    "size_threshold = 50\n",
    "train_set = pheme\n",
    "\n",
    "def train_svms(dataset, confidence_threshold, size_threshold, train_set):\n",
    "    file_name = f\"{dataset}_cats\\\\{dataset}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    trained_svms = {}\n",
    "    for key in data.keys():\n",
    "        svm_name = f\"svm_{key}\"\n",
    "        cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "        if len(cat_entries) < size_threshold:\n",
    "            print(f\"Skipped category: {key} due to low numbers\")\n",
    "            continue\n",
    "        all_in_cat = train_set.filter(axis=0, items=cat_entries)\n",
    "        X_train = all_in_cat.drop('target', axis=1)\n",
    "        y_train = all_in_cat['target']\n",
    "        #print(np.unique(all_in_cat[\"target\"]))\n",
    "        if (len(np.unique(all_in_cat[\"target\"])) <= 1):\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        try:\n",
    "            svm = optimize_model(svc(name=svm_name, random_state=42, probability=True), X_train_text, y_train)\n",
    "        except:\n",
    "            print(f\"error training {key} svm, skipping\")\n",
    "            continue\n",
    "        trained_svms[key] = svm\n",
    "        print(f\"Created SVM trained in category: {key}\")\n",
    "    return trained_svms\n",
    "\n",
    "#trained_svms = train_svms(\"pheme\", confidence_threshold, size_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_list = [svc(name=\"name\", random_state=42, probability=True), knn(), etc]\n",
    "\n",
    "def train_models(dataset, confidence_threshold, size_threshold, train_set, model_list):\n",
    "    file_name = f\"{dataset}_cats\\\\{dataset}_categories_organised.json\"\n",
    "    f = open(file_name)\n",
    "    data = json.load(f)\n",
    "    trained_models = {}\n",
    "    for key in data.keys():\n",
    "        cat_entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "        if len(cat_entries) < size_threshold:\n",
    "            print(f\"Skipped category: {key} due to low numbers\")\n",
    "            continue\n",
    "        all_in_cat = train_set.filter(axis=0, items=cat_entries)\n",
    "        X_train = all_in_cat.drop('target', axis=1)\n",
    "        y_train = all_in_cat['target']\n",
    "        if (len(np.unique(all_in_cat[\"target\"])) <= 1):\n",
    "            print(f\"Skipped category: {key} due to class issues\")\n",
    "            continue\n",
    "        X_train_text = np.array([text for text in X_train['e_text']])\n",
    "        trained_models[key] = {}\n",
    "        for model_name, model in model_list:\n",
    "            try:\n",
    "                m = optimize_model(model, X_train_text, y_train)\n",
    "                mod = m.best_model()['learner'].fit(X_train_text, y_train)\n",
    "            except:\n",
    "                print(f\"Error training {model_name} in category {key}, skipping\")\n",
    "                continue\n",
    "            trained_models[key][model_name] = mod\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive Subjects 2754 2754\n",
      "News 362 362\n",
      "Arts & Entertainment 354 354\n",
      "People & Society 219 219\n",
      "Law & Government 388 388\n",
      "Online Communities 115 115\n",
      "Books & Literature 5 5\n",
      "Reference 14 14\n",
      "Jobs & Education 5 5\n",
      "Health 29 29\n",
      "Business & Industrial 3 3\n",
      "Autos & Vehicles 0 0\n",
      "Food & Drink 3 3\n",
      "Travel & Transportation 103 103\n",
      "Hobbies & Leisure 5 5\n",
      "Games 0 0\n",
      "Pets & Animals 2 2\n",
      "Sports 41 41\n",
      "Beauty & Fitness 1 1\n",
      "Science 0 0\n",
      "Computers & Electronics 4 4\n",
      "Shopping 2 2\n",
      "Internet & Telecom 1 1\n",
      "Adult 0 0\n",
      "Finance 0 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"pheme_cats\\\\pheme_categories_organised.json\"\n",
    "f = open(file_name)\n",
    "data = json.load(f)\n",
    "\n",
    "confidence_threshold = 0.5\n",
    "for key in data.keys():\n",
    "    entries = [int(i) for i in data[key].keys() if data[key][i] > confidence_threshold]\n",
    "    all_in_cat = pheme.filter(axis=0, items=entries)\n",
    "    t = 0\n",
    "    f=0\n",
    "    for e in all_in_cat[\"target\"]:\n",
    "        if e:\n",
    "            t += 1\n",
    "        else:\n",
    "            f += 1\n",
    "    print(key, len(entries), len(all_in_cat))\n",
    "    #print(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SVMS\n",
    "def predict_points(trained_svms, test_cats, test_data):\n",
    "    test_points = test_data\n",
    "    test_file_name = test_cats\n",
    "    f = open(test_file_name)\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    final_predictions = []\n",
    "    final_predictions2 = []\n",
    "    for i in tqdm(range(len(test_points))):\n",
    "        point = test_points.iloc[i]\n",
    "        point_text = np.array([text for text in point['e_text']])\n",
    "        topics = test_data[str(point[\"entry\"])]\n",
    "        topic_weights = {}\n",
    "        for topic in topics:\n",
    "            main_topic = topic.split(\"/\")[1]\n",
    "            if topics[topic] < confidence_threshold or main_topic not in trained_svms.keys():\n",
    "                continue\n",
    "            if main_topic in topic_weights:\n",
    "                topic_weights[main_topic] += topics[topic]\n",
    "            else:\n",
    "                topic_weights[main_topic] = topics[topic]\n",
    "        #print(topic_weights) \n",
    "        model_predictions = []\n",
    "        for topic in topic_weights:\n",
    "            model = trained_svms[topic]\n",
    "            pred = model.predict(point_text.reshape(1,-1))\n",
    "            model_predictions.append((pred[0], topic_weights[topic]))\n",
    "            #model_predictions.append((pred[0], 1))\n",
    "        #print(model_predictions)\n",
    "        true_mark = 0\n",
    "        false_mark = 0\n",
    "        for pred, score in model_predictions:    \n",
    "            if pred == True:\n",
    "                true_mark += score\n",
    "            else:\n",
    "                false_mark += score\n",
    "        #print(mark)\n",
    "        if (true_mark > false_mark):\n",
    "            final_predictions.append(True)\n",
    "        else:\n",
    "            final_predictions.append(False)\n",
    "        max = 0\n",
    "        final_pred = True\n",
    "        for pred, score in model_predictions:\n",
    "            if score > max:\n",
    "                final_pred = pred\n",
    "        final_predictions2.append(final_pred)\n",
    "    return final_predictions, final_predictions2\n",
    "             \n",
    "def check_score(test, pred):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE MODELS\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def hard_vote(model_predictions):\n",
    "    category_votes = []\n",
    "    for category in model_predictions.keys():\n",
    "        predictions = model_predictions[category]\n",
    "        vote = 0\n",
    "        for pred, model, weight in predictions:\n",
    "            if pred[0][0] < pred[0][1]:\n",
    "                vote += 1\n",
    "            else: vote -= 1 \n",
    "        if vote > 0:\n",
    "            category_votes.append((category, True, weight))\n",
    "        else:\n",
    "            category_votes.append((category, False, weight))\n",
    "    score = 0\n",
    "    for category, vote, weight in category_votes:\n",
    "        if vote == True: score += weight\n",
    "        else: score -= weight\n",
    "    if score > 0: return True\n",
    "    else: return False\n",
    "\n",
    "def soft_vote(model_predictions):\n",
    "    category_votes = []\n",
    "    for category in model_predictions.keys():\n",
    "        predictions = model_predictions[category]\n",
    "        max_vote = [True, 0, \"\", 0]\n",
    "        for pred, model, weight in predictions:\n",
    "            false_weight = pred[0][0]\n",
    "            true_weight = pred[0][1]\n",
    "            if false_weight < true_weight:\n",
    "                vote = [True, true_weight, model, weight]\n",
    "            else:\n",
    "                vote = [False, false_weight, model, weight]\n",
    "            category_votes.append(vote)\n",
    "    score = 0\n",
    "    for pred, confidence, model, weight in category_votes:\n",
    "        vote_weight = (0.5*confidence + 1*weight)\n",
    "        if pred == True: score += vote_weight\n",
    "        else: score -= vote_weight\n",
    "    if score > 0: return True\n",
    "    else: return False\n",
    "\n",
    "def predict_points_mutiple_models(trained_models, test_cats, test_data):\n",
    "    test_points = test_data\n",
    "    test_file_name = test_cats\n",
    "    f = open(test_file_name)\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    final_predictions_hard = []\n",
    "    final_predictions_soft = []\n",
    "    for i in tqdm(range(len(test_points))):\n",
    "        point = test_points.iloc[i]\n",
    "        point_text = np.array([text for text in point['e_text']])\n",
    "        topics = test_data[str(point[\"entry\"])]\n",
    "        topic_weights = {}\n",
    "        for topic in topics:\n",
    "            main_topic = topic.split(\"/\")[1]\n",
    "            if topics[topic] < confidence_threshold or main_topic not in trained_models.keys():\n",
    "                continue\n",
    "            if main_topic in topic_weights:\n",
    "                topic_weights[main_topic] += topics[topic]\n",
    "            else:\n",
    "                topic_weights[main_topic] = topics[topic]\n",
    "        model_predictions = {}\n",
    "        for topic in topic_weights:\n",
    "            models = trained_models[topic]\n",
    "            model_predictions[topic] = []\n",
    "            #estimators = []\n",
    "            for model in models:\n",
    "                #estimators.append(model, models[model])\n",
    "                mod = models[model]\n",
    "                pred = mod.predict_proba(point_text.reshape(1,-1))\n",
    "                model_predictions[topic].append((pred, model, topic_weights[topic]))\n",
    "            #clf = VotingClassifier(estimators, voting=\"hard\")\n",
    "        #vote\n",
    "        prediction_hard = hard_vote(model_predictions)\n",
    "        prediction_soft = soft_vote(model_predictions)\n",
    "        final_predictions_hard.append(prediction_hard)\n",
    "        final_predictions_soft.append(prediction_soft)\n",
    "    return final_predictions_hard, final_predictions_soft\n",
    "\n",
    "def check_score(test, pred):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred, average=\"macro\")\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"false\"])\n",
    "    disp.plot()\n",
    "    plt.show() \n",
    "    return float(\"{0:.2f}\".format(acc*100)), float(\"{0:.2f}\".format(f1*100))   \n",
    "\n",
    "#a,b = predict_points_mutiple_models(models, \"pheme_categories.json\", X_val)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SVMS\n",
    "def get_results(train_dataset, confidence_threshold, size_threshold, train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    train_set = pd.concat([X_train, y_train], axis=1)\n",
    "    svms = train_svms(train_dataset, confidence_threshold, size_threshold, train_set)\n",
    "\n",
    "    results = []\n",
    "    train_cats = f\"{train_dataset}_categories.json\"\n",
    "    predictions1, predictions2 = predict_points(svms, train_cats, X_val)\n",
    "    results.append(check_score(predictions1, y_val))\n",
    "    \n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_cat_file = f\"{test_cat}_categories.json\"\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_target = test_set[\"target\"]\n",
    "        predictions1, predictions2 = predict_points(svms, test_cat_file, test_data)\n",
    "        results.append((test_name, check_score(predictions1, test_target)))\n",
    "    return results\n",
    "\n",
    "def run_tests(tests, confidence_threshold, size_threshold):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_results(train[1], confidence_threshold, size_threshold, train[0], t)))\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE MODELS\n",
    "def get_results_multi(train_dataset, confidence_threshold, size_threshold, train, tests, model_list): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    train_set = pd.concat([X_train, y_train], axis=1)\n",
    "    models = train_models(train_dataset, confidence_threshold, size_threshold, train_set, model_list)\n",
    "\n",
    "    results = []\n",
    "    train_cats = f\"{train_dataset}_categories.json\"\n",
    "    predictions_hard, predictions_soft = predict_points_mutiple_models(models, train_cats, X_val)\n",
    "    results.append((check_score(predictions_hard, y_val), check_score(predictions_soft, y_val)))\n",
    "    \n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_cat_file = f\"{test_cat}_categories.json\"\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_target = test_set[\"target\"]\n",
    "        predictions_hard, predictions_soft = predict_points_mutiple_models(models, test_cat_file, test_data)\n",
    "        results.append((test_name, check_score(predictions_hard, test_target), check_score(predictions_soft, test_target)))\n",
    "    return results\n",
    "\n",
    "def run_tests_multi(tests, confidence_threshold, size_threshold, model_list):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_results_multi(train[1], confidence_threshold, size_threshold, train[0], t, model_list)))\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import svc, logistic_regression, k_neighbors_classifier, ada_boost_classifier, decision_tree_classifier, mlp_classifier\n",
    "model_list = [\n",
    "    (\"SVC\", svc(\"SVC\", random_state=42, probability=True)),\n",
    "    (\"KNN\", k_neighbors_classifier(\"knn\")),\n",
    "    (\"Logistic Regression\", logistic_regression(\"LR\", random_state=42, solver=\"saga\", penalty=hp.choice(\"penalty\", {None, \"l1\", \"l2\"}))),\n",
    "    (\"Adaboost\", ada_boost_classifier(\"adaDT\", base_estimator=decision_tree_classifier(\"DT\"), random_state=42)),\n",
    "    (\"MLP\", mlp_classifier(\"MLP\", random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = get_dataset(\"pheme\")\n",
    "twitter = get_dataset(\"twitter\")\n",
    "twitter15 = twitter.iloc[:1491]\n",
    "twitter16 = twitter.iloc[1491:]\n",
    "weibo = get_dataset(\"weibo\")\n",
    "weibo = weibo.drop([1933, 3564])\n",
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n",
    "tests2 = [[pheme, \"pheme\", \"PHEME\"], [twitter, \"twitter\", \"twitterfull\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/trial, best loss: 0.41677943166441134]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.03s/trial, best loss: 0.41677943166441134]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.48s/trial, best loss: 0.41677943166441134]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.85s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.40s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.40s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.13s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.99s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 9/9 [00:04<00:00,  4.15s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.24s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.43s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.62s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.62s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.60s/trial, best loss: 0.381596752368065]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.428958051420839]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.41542625169147496]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.41542625169147496]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.91s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.3978349120433018]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.3951285520974289]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 9/9 [00:14<00:00, 14.05s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 10/10 [00:09<00:00,  9.09s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.14s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.08s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.19s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.38565629228687415]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4181326116373477]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.4181326116373477]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.01s/trial, best loss: 0.4181326116373477]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.12s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.99s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.09s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.03s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.11s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.46s/trial, best loss: 0.4127198917456022]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.69s/trial, best loss=?]\n",
      "Error training Adaboost in category Sensitive Subjects, skipping\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.45s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.74s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.58s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.34s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.63s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.40s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.01s/trial, best loss: 0.3964817320703654]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.43s/trial, best loss: 0.37889039242219213]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.24s/trial, best loss: 0.37889039242219213]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.12s/trial, best loss: 0.37889039242219213]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.13s/trial, best loss: 0.37889039242219213]\n",
      "100%|██████████| 14/14 [00:07<00:00,  7.14s/trial, best loss: 0.37889039242219213]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.12s/trial, best loss: 0.3491204330175913]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/trial, best loss: 0.5888077858880778]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.45498783454987834]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.20s/trial, best loss: 0.45498783454987834]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.47s/trial, best loss: 0.4282238442822385]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24s/trial, best loss: 0.4209245742092458]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.44s/trial, best loss: 0.4209245742092458]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.74s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.42s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.73s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.54s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.46s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.23s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.56s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.34s/trial, best loss: 0.4063260340632603]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.09s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.99s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.97s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.4136253041362531]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.02s/trial, best loss: 0.3746958637469586]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.3746958637469586]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.3746958637469586]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.3746958637469586]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.3746958637469586]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.44768856447688565]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.44768856447688565]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.43s/trial, best loss: 0.44768856447688565]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.97s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.24s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.20s/trial, best loss: 0.44525547445255476]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.15s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.44038929440389296]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/trial, best loss: 0.4282238442822385]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.4282238442822385]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.01s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 4/4 [00:21<00:00, 21.82s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.18s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.20s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 8/8 [00:08<00:00,  8.34s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 9/9 [00:17<00:00, 17.10s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.43s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.74s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 14/14 [00:10<00:00, 10.97s/trial, best loss: 0.4184914841849149]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.01s/trial, best loss: 0.4184914841849149]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/trial, best loss: 0.4209245742092458]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.49s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.26s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.90s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.3965936739659367]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.07s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.47s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.08s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.90s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.64s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.51s/trial, best loss: 0.3844282238442822]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.49696969696969695]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.87s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/trial, best loss: 0.47878787878787876]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.47878787878787876]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.4303030303030303]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.03s/trial, best loss: 0.4303030303030303]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.4303030303030303]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.47878787878787876]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.47878787878787876]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.52s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.42s/trial, best loss: 0.4424242424242424]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.10s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.05s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.15s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.13s/trial, best loss: 0.4121212121212121]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.00s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.00s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 6/6 [00:07<00:00,  8.00s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.93s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.41s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.83s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.44s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.05s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.60s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.36969696969696975]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.90s/trial, best loss: 0.36969696969696975]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.4727272727272728]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.57s/trial, best loss: 0.4727272727272728]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.75s/trial, best loss: 0.4727272727272728]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.4727272727272728]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.10s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 11/11 [00:01<00:00,  2.00s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.05s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.17s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.96s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.12337662337662336]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.34s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.07s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.06s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.43s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.50s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.11s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.00s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.01s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/trial, best loss: 0.14935064935064934]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.25s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 3/3 [00:06<00:00,  6.33s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.92s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.01s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 8/8 [00:05<00:00,  5.92s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 11/11 [00:10<00:00, 10.86s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.58s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.25s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.69s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 15/15 [00:05<00:00,  5.72s/trial, best loss: 0.11688311688311692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.94s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.09s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.01s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.99s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.12s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.12s/trial, best loss: 0.11688311688311692]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.00s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.94s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.3027522935779816]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.5091743119266054]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.77s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.58s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.56s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.45871559633027525]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.463302752293578]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.45412844036697253]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.67s/trial, best loss: 0.45412844036697253]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.40s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.50s/trial, best loss: 0.4495412844036697]\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.10s/trial, best loss: 0.44036697247706424]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.58s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 3/3 [00:21<00:00, 21.65s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.20s/trial, best loss: 0.42660550458715596]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.54s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 7/7 [00:21<00:00, 21.53s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 8/8 [00:21<00:00, 21.52s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 9/9 [00:10<00:00, 10.82s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.63s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 12/12 [00:21<00:00, 21.51s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 14/14 [00:21<00:00, 21.53s/trial, best loss: 0.37155963302752293]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.02s/trial, best loss: 0.37155963302752293]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.47706422018348627]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.4678899082568807]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.48s/trial, best loss: 0.4678899082568807]\n",
      "100%|██████████| 4/4 [00:02<00:00,  3.00s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.76s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.89s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.12s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.28s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.38s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.65s/trial, best loss: 0.3302752293577982]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/trial, best loss: 0.06857142857142862]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.06857142857142862]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.06857142857142862]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/trial, best loss: 0.2171428571428572]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.06285714285714283]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.05142857142857138]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.05142857142857138]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.05142857142857138]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.09s/trial, best loss: 0.05142857142857138]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/trial, best loss: 0.07428571428571429]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.59s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 3/3 [00:21<00:00, 21.55s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.92s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.58s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.04s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 12/12 [00:21<00:00, 21.55s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 13/13 [00:21<00:00, 21.55s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.18s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 15/15 [00:10<00:00, 10.57s/trial, best loss: 0.05714285714285716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.20s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 9/9 [00:01<00:00,  2.00s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.74s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.32s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.05714285714285716]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.05714285714285716]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.1875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.1875]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.6875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.6875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.6875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.6875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.6875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.6875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.625]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.625]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.625]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.625]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.625]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.625]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.8125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.8125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.6875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.6875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.6875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.6875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.625]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.625]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.625]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.625]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.625]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.625]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/trial, best loss: 0.625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.625]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.75]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.75]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.6875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.6875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.4375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.4375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.4375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.4375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.4375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.4375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.4375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.4375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.4375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.4375]\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.15384615384615385]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.15384615384615385]\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5833333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.5833333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.5208333333333333]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.45833333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.6041666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.4375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.4375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.4375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.4375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.4375]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.89s/trial, best loss: 0.4375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.4375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.39583333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.39583333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.39583333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.39583333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.39583333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.39583333333333337]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.08s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.00s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.45833333333333337]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:06<00:00, 199.78it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAGwCAYAAAATw+f5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCuElEQVR4nO3deXRUVbr38V8lZCJJJQQzEAkhNAhJA4LghVIZRCQgIgi3bb1BQot6GwNKaEB5GxCDkr6IjeBFUMQgV7g40xoGBZQ5IKD4IiASBAOSBBUhBN4MpM77B01pyWAq52Sozvez1lmLOmfvc55yxfDw7H32thmGYQgAAKCKfGo7AAAA4N1IJgAAgCkkEwAAwBSSCQAAYArJBAAAMIVkAgAAmEIyAQAATGlQ2wHUZU6nU8ePH1doaKhsNltthwMA8JBhGDpz5oxiY2Pl41N9/34uKSlRWVmZ6fv4+/srMDDQgohqFsnEVRw/flxxcXG1HQYAwKSjR4+qadOm1XLvkpISJcSHqOBEhel7xcTE6PDhw16XUJBMXEVoaKgk6dvPmssewogQ/jX1TR9e2yEA1eZ8eYl2fTTd9fu8OpSVlangRIW+3dVc9tCq/11RdMap+E5HVFZWRjLxr+Ti0IY9xMfUDwhQlzXw865fWkBV1MRQdUioTSGhVX+OU947nE4yAQCABSoMpypM7HZVYTitC6aGkUwAAGABpww5VfVswkzf2kbtHgAAmEJlAgAACzjllJmBCnO9axfJBAAAFqgwDFUYVR+qMNO3tjHMAQAATKEyAQCABerzBEySCQAALOCUoYp6mkwwzAEAAEyhMgEAgAUY5gAAAKbwNgcAAEAVUZkAAMACzn8eZvp7K5IJAAAsUGHybQ4zfWsbyQQAABaoMGRy11DrYqlpzJkAAACmUJkAAMACzJkAAACmOGVThWym+nsrhjkAAIApVCYAALCA07hwmOnvrUgmAACwQIXJYQ4zfWsbwxwAAMAUkgkAACxwsTJh5vBE8+bNZbPZLjnS0tIkSSUlJUpLS1Pjxo0VEhKiIUOGqLCw0O0eeXl56t+/vxo2bKioqCiNHz9e58+f9/i7M8wBAIAFnIZNTsPE2xwe9t2xY4cqKipcn7/88kvdfvvt+sMf/iBJSk9P14oVK/TWW28pLCxMo0aN0uDBg7VlyxZJUkVFhfr376+YmBht3bpV+fn5GjZsmPz8/DR9+nSPYqEyAQCAF4qMjFRMTIzryM7O1u9+9zv16NFDp0+f1sKFC/X3v/9dvXr1UqdOnZSVlaWtW7dq27ZtkqSPPvpI+/bt0+uvv64OHTqoX79+mjZtmubOnauysjKPYiGZAADAAlYNcxQVFbkdpaWlv/nssrIyvf7663rggQdks9m0a9culZeXq3fv3q42bdq0UbNmzZSTkyNJysnJUbt27RQdHe1qk5ycrKKiIu3du9ej704yAQCABSrkY/qQpLi4OIWFhbmOzMzM33z28uXLderUKQ0fPlySVFBQIH9/f4WHh7u1i46OVkFBgavNLxOJi9cvXvMEcyYAALCAYXLOhPHPvkePHpXdbnedDwgI+M2+CxcuVL9+/RQbG1vl55tBMgEAQB1it9vdkonf8u2332rt2rV69913XediYmJUVlamU6dOuVUnCgsLFRMT42rz6aefut3r4tseF9tUFsMcAABYoKZfDb0oKytLUVFR6t+/v+tcp06d5Ofnp3Xr1rnOHThwQHl5eXI4HJIkh8OhPXv26MSJE642a9askd1uV1JSkkcxUJkAAMACFYaPKoyq/xu9ogrLaTudTmVlZSk1NVUNGvz8V3pYWJhGjBihsWPHKiIiQna7XaNHj5bD4VDXrl0lSX369FFSUpLuv/9+zZgxQwUFBZo0aZLS0tIqNbTySyQTAAB4qbVr1yovL08PPPDAJddmzZolHx8fDRkyRKWlpUpOTtaLL77ouu7r66vs7GyNHDlSDodDwcHBSk1NVUZGhsdxkEwAAGABp2xympg94JTnpYk+ffrIMC7fLzAwUHPnztXcuXOv2D8+Pl4rV670+Lm/RjIBAIAF2OgLAACgiqhMAABgAfMTMKswA7OOIJkAAMACF+ZMmNjoi2EOAABQX1GZAADAAs5f7K9Rtf4McwAAUK8xZwIAAJjilE+NrzNRVzBnAgAAmEJlAgAAC1QYNlWY2ILcTN/aRjIBAIAFKkxOwKxgmAMAANRXVCYAALCA0/CR08TbHE7e5gAAoH5jmAMAAKCKqEwAAGABp8y9keG0LpQaRzIBAIAFzC9a5b2DBd4bOQAAqBOoTAAAYAHze3N477/vSSYAALCAUzY5ZWbOBCtgAgBQr9XnyoT3Rg4AAOoEKhMAAFjA/KJV3vvve5IJAAAs4DRscppZZ8KLdw313jQIAADUCVQmAACwgNPkMIc3L1pFMgEAgAXM7xrqvcmE90YOAADqBCoTAABYoEI2VZhYeMpM39pGMgEAgAUY5gAAAKgiKhMAAFigQuaGKiqsC6XGkUwAAGCB+jzMQTIBAIAF2OgLAACgiqhMAABgAUM2OU3MmTB4NRQAgPqNYQ4AAIAqojIBAIAF6vMW5CQTAABYoMLkrqFm+tY2740cAADUCSQTAABY4OIwh5nDU999952GDh2qxo0bKygoSO3atdPOnTtd1w3D0JQpU9SkSRMFBQWpd+/eOnjwoNs9Tp48qZSUFNntdoWHh2vEiBEqLi72KA6SCQAALOCUj+nDEz/99JNuvvlm+fn5adWqVdq3b5+ee+45NWrUyNVmxowZmjNnjubPn6/t27crODhYycnJKikpcbVJSUnR3r17tWbNGmVnZ2vjxo16+OGHPYqFORMAAHih//qv/1JcXJyysrJc5xISElx/NgxDzz//vCZNmqSBAwdKkhYvXqzo6GgtX75c9957r/bv36/Vq1drx44d6ty5syTphRde0B133KGZM2cqNja2UrFQmQAAwAIVhs30IUlFRUVuR2lp6WWf9/7776tz5876wx/+oKioKHXs2FELFixwXT98+LAKCgrUu3dv17mwsDB16dJFOTk5kqScnByFh4e7EglJ6t27t3x8fLR9+/ZKf3eSCQAALGDVnIm4uDiFhYW5jszMzMs+75tvvtG8efPUqlUrffjhhxo5cqQeffRRvfbaa5KkgoICSVJ0dLRbv+joaNe1goICRUVFuV1v0KCBIiIiXG0qg2EOAAAsYJjcNdT4Z9+jR4/Kbre7zgcEBFy2vdPpVOfOnTV9+nRJUseOHfXll19q/vz5Sk1NrXIcVUFlAgCAOsRut7sdV0ommjRpoqSkJLdziYmJysvLkyTFxMRIkgoLC93aFBYWuq7FxMToxIkTbtfPnz+vkydPutpUBskEAAAWqJDN9OGJm2++WQcOHHA79/XXXys+Pl7ShcmYMTExWrdunet6UVGRtm/fLofDIUlyOBw6deqUdu3a5Wrz8ccfy+l0qkuXLpWOhWEOAAAs4DTMLYntNDxrn56erptuuknTp0/XPffco08//VQvv/yyXn75ZUmSzWbTmDFj9PTTT6tVq1ZKSEjQ5MmTFRsbq0GDBkm6UMno27evHnroIc2fP1/l5eUaNWqU7r333kq/ySGRTAAA4JVuvPFGvffee5o4caIyMjKUkJCg559/XikpKa42EyZM0NmzZ/Xwww/r1KlTuuWWW7R69WoFBga62ixZskSjRo3SbbfdJh8fHw0ZMkRz5szxKBaSCVS7Yf+WpMJj/pecH5D6vUZlfqfxQ1rq/+aEuF274/4f9Nh/HbukT9FJX428vbV+yPfXO/v3KCSsotriBiojJXm3unc4rPiY0yot99WXh6I1f/m/6WhhuCQptGGJHrhzl25M+k7RjYp1qjhQm75oroXvd9bZkgv/X/zu2h+VkvyF2v+uQGEhJSr4MVT/2JSotz9pW4vfDJ5ympyAWZW+d955p+68884rXrfZbMrIyFBGRsYV20RERGjp0qUeP/uXSCZQ7easOiBnxc+lvyNfBWrivS3VbcBp17l+KT9o2PifX0MKCHJe9l5//0szJSSW6If8S5MToDZ0aJWv9zb8Xl99e418fQw9PHCHnhu9SsMy/l0lZX66Jvycrgk/pxff6aIj+Y0U0/iM/nLfZl0Tdk5TFlx4/791sx906kygpi26VSd+ClbbFoUan7JJTqdN7274fS1/Q1SWUzY5PZz38Ov+3qrOJRM9e/ZUhw4d9Pzzz9d2KLBIeGP36sEb/x2mJs1L1d7x89rvAUGGIqLOX/U+H7zWWGeLfJWSXqAdH9uv2haoKeP/u5/b5+mLe+iDZ19X62Y/6IvcJjp8PEKTX77ddf34D3YteP9GTRr+iXx9nKpw+mhlTmu3e+T/YFfbFifUveNhkgl4hTqXTPwWwzBUUVGhBg28LnRIKi+z6eN3Gmnwf56Q7RdJ+CfvNtLH7zRSo6hydb29SP8xpkCBDX+ejfTt1wFaOitGs7O/Vn7e5V+TAuqCkKAySVLRuSv/nAYHlelcib8qnFcuawcHlqnobOAVr6Pu+eUqllXt763q1Kuhw4cP14YNGzR79mzZbDbZbDYtWrRINptNq1atUqdOnRQQEKDNmzdr+PDhrtmoF40ZM0Y9e/Z0fXY6ncrMzFRCQoKCgoJ0/fXX6+23367ZLwU3W1eHqbjIV33uOek6d+vdP2nCf3+rGW/n6t7RJ7TunUaaMTredb2s1KbMR5rrwcnHFdW0vDbCBirFZjM0+g85+r+50Tp8POKybcKCS5Ta73O9v7nNFe/TtkWhenU+pA+u0gZ1z8U5E2YOb1Wn/nk/e/Zsff3112rbtq1rssjevXslSU888YRmzpypFi1auO2IdjWZmZl6/fXXNX/+fLVq1UobN27U0KFDFRkZqR49elzSvrS01G0N9KKiIgu+FX7pw/+N0I23FqlxzM9DGncM/dH154TEEkVElevxe1rq+BF/xTYvU1ZmEzVrWaLbhvxUGyEDlZZ+7xYlxP6kUTMHXPZ6w8Ay/Vfaah0pCFdWdqfLtkmIPanpf/5Ii1bcoB37m1ZnuIBl6lQyERYWJn9/fzVs2NC18tZXX30lScrIyNDtt99+te5uSktLNX36dK1du9a1OEeLFi20efNmvfTSS5dNJjIzM/XUU09Z8E1wOYXH/PT5plBNfuXwVdu1ueGcJOn4kQDFNi/T7s2hOvJVoPrFhV9o8M/Rjz+0bav7Hi10m7gJ1JYxf9yim9rmafTf79T3p0IuuR4UUKaZo1bpXKmfJs2//bJDHPExP2nWYyv1/uY2WrzqhpoIGxZyymZunQkmYFa/X+5oVhm5ubk6d+7cJQlIWVmZOnbseNk+EydO1NixY12fi4qKFBcX53mwuKyPljVW+DXn1aX31Ss+h74MkiRFRF0Y0pj8ymGVlfz8i/fA7ob6+9hmeu69g4ptXlZ9AQOVYmjMH7eqW4cjeuzvdyr/x0snBzcMLNPM0atUft5XE19MVtn5S3/1Nm9yUs+PWanV21rplfdvrInAYTHD5NscBslE9QsODnb77OPjI8NwXy6svPzn8fTi4gtvCqxYsULXXnutW7srrXMeEBBwxWswx+mUPnojQr3/cFK+v/ipO37EX5+810j/dluRQhtV6PC+QL009Vq161qsFkklknRJwnD65IUbNGtVyjoTqHXp925R7xsP6f/M76NzpX6KsF+orBX/P3+VlTdQw8AyPffoKgX6ndfTWbcqOKhMwf+cpHnqTKCcho8SYk/q+TEr9Om+pnpzXTvXPSqcNp0uDqq17wbP/HLnz6r291Z1Lpnw9/dXRcVv/wURGRmpL7/80u3c7t275efnJ0lKSkpSQECA8vLyLjukgZr1+cZQnfjOX8n3nnQ738DP0OebQvXeK5EqOeejyNhy3XLHKd03pvAKdwLqlrt77JckvTA22+389Nd6aPW263Rd3A/6fcKFjZSWTXvDrc09f71XBSdD1bPjYTUKLVFyl1wld8l1Xc//MUR/nHRfNX8DwLw6l0w0b95c27dv15EjRxQSEiKn8/KLF/Xq1UvPPvusFi9eLIfDoddff11ffvmlawgjNDRU48aNU3p6upxOp2655RadPn1aW7Zskd1ur/HtWeu7Tj3P6MPjuy85H3VtuWa+m3tph6u4/qbiy94LqA3dRz501eu7D8b+ZpusFZ2UteLyEzLhPWpjBcy6os5FPm7cOPn6+iopKUmRkZGurVR/LTk5WZMnT9aECRN044036syZMxo2bJhbm2nTpmny5MnKzMx0bWayYsUKJSQk1MRXAQDUIxeHOcwc3spm/HriAVyKiooUFhamn75uIXtoncu7AEt0H/lwbYcAVJvz5SXavmKKTp8+Lbu9elbOvfh3xcCPHpBfcNWX+i8/W6Z/9Hm1WmOtLnVumAMAAG/E3hwAAMCU+vw2B7V7AABgCpUJAAAsUJ8rEyQTAABYoD4nEwxzAAAAU6hMAABggfpcmSCZAADAAobMvd7pzYs+kUwAAGCB+lyZYM4EAAAwhcoEAAAWqM+VCZIJAAAsUJ+TCYY5AACAKVQmAACwQH2uTJBMAABgAcOwyTCREJjpW9sY5gAAAKZQmQAAwAJO2UwtWmWmb20jmQAAwAL1ec4EwxwAAMAUKhMAAFigPk/AJJkAAMAC9XmYg2QCAAAL1OfKBHMmAACAKVQmAACwgGFymMObKxMkEwAAWMCQZBjm+nsrhjkAAIApVCYAALCAUzbZWAETAABUFW9zAAAAVBGVCQAALOA0bLLV00WrqEwAAGABwzB/eGLq1Kmy2WxuR5s2bVzXS0pKlJaWpsaNGyskJERDhgxRYWGh2z3y8vLUv39/NWzYUFFRURo/frzOnz/v8XenMgEAgJf6/e9/r7Vr17o+N2jw81/r6enpWrFihd566y2FhYVp1KhRGjx4sLZs2SJJqqioUP/+/RUTE6OtW7cqPz9fw4YNk5+fn6ZPn+5RHCQTAABYoDYmYDZo0EAxMTGXnD99+rQWLlyopUuXqlevXpKkrKwsJSYmatu2beratas++ugj7du3T2vXrlV0dLQ6dOigadOm6fHHH9fUqVPl7+9f6TgY5gAAwAIXkwkzhyQVFRW5HaWlpVd85sGDBxUbG6sWLVooJSVFeXl5kqRdu3apvLxcvXv3drVt06aNmjVrppycHElSTk6O2rVrp+joaFeb5ORkFRUVae/evR59d5IJAAAscHHXUDOHJMXFxSksLMx1ZGZmXvZ5Xbp00aJFi7R69WrNmzdPhw8fVrdu3XTmzBkVFBTI399f4eHhbn2io6NVUFAgSSooKHBLJC5ev3jNEwxzAABQhxw9elR2u931OSAg4LLt+vXr5/pz+/bt1aVLF8XHx+vNN99UUFBQtcf5S1QmAACwgFVvc9jtdrfjSsnEr4WHh+u6665Tbm6uYmJiVFZWplOnTrm1KSwsdM2xiImJueTtjoufLzcP42pIJgAAsMCFhMDMnAlzzy8uLtahQ4fUpEkTderUSX5+flq3bp3r+oEDB5SXlyeHwyFJcjgc2rNnj06cOOFqs2bNGtntdiUlJXn0bIY5AADwQuPGjdOAAQMUHx+v48eP68knn5Svr6/uu+8+hYWFacSIERo7dqwiIiJkt9s1evRoORwOde3aVZLUp08fJSUl6f7779eMGTNUUFCgSZMmKS0trdLVkItIJgAAsEBNvxp67Ngx3Xffffrxxx8VGRmpW265Rdu2bVNkZKQkadasWfLx8dGQIUNUWlqq5ORkvfjii67+vr6+ys7O1siRI+VwOBQcHKzU1FRlZGR4HDvJBAAAFjD+eZjp74lly5Zd9XpgYKDmzp2ruXPnXrFNfHy8Vq5c6eGTL8WcCQAAYAqVCQAALFCftyAnmQAAwAo1Pc5Rh5BMAABgBZOVCXlxZYI5EwAAwBQqEwAAWOCXq1hWtb+3IpkAAMAC9XkCJsMcAADAFCoTAABYwbCZm0TpxZUJkgkAACxQn+dMMMwBAABMoTIBAIAVWLQKAACYUZ/f5qhUMvH+++9X+oZ33XVXlYMBAADep1LJxKBBgyp1M5vNpoqKCjPxAADgvbx4qMKMSiUTTqezuuMAAMCr1edhDlNvc5SUlFgVBwAA3s2w4PBSHicTFRUVmjZtmq699lqFhITom2++kSRNnjxZCxcutDxAAABQt3mcTDzzzDNatGiRZsyYIX9/f9f5tm3b6pVXXrE0OAAAvIfNgsM7eZxMLF68WC+//LJSUlLk6+vrOn/99dfrq6++sjQ4AAC8BsMclffdd9+pZcuWl5x3Op0qLy+3JCgAAOA9PE4mkpKStGnTpkvOv/322+rYsaMlQQEA4HXqcWXC4xUwp0yZotTUVH333XdyOp169913deDAAS1evFjZ2dnVESMAAHVfPd411OPKxMCBA/XBBx9o7dq1Cg4O1pQpU7R//3598MEHuv3226sjRgAAUIdVaW+Obt26ac2aNVbHAgCA16rPW5BXeaOvnTt3av/+/ZIuzKPo1KmTZUEBAOB12DW08o4dO6b77rtPW7ZsUXh4uCTp1KlTuummm7Rs2TI1bdrU6hgBAEAd5vGciQcffFDl5eXav3+/Tp48qZMnT2r//v1yOp168MEHqyNGAADqvosTMM0cXsrjysSGDRu0detWtW7d2nWudevWeuGFF9StWzdLgwMAwFvYjAuHmf7eyuNkIi4u7rKLU1VUVCg2NtaSoAAA8Dr1eM6Ex8Mczz77rEaPHq2dO3e6zu3cuVOPPfaYZs6caWlwAACg7qtUZaJRo0ay2X4eyzl79qy6dOmiBg0udD9//rwaNGigBx54QIMGDaqWQAEAqNPq8aJVlUomnn/++WoOAwAAL1ePhzkqlUykpqZWdxwAAMBLVXnRKkkqKSlRWVmZ2zm73W4qIAAAvFI9rkx4PAHz7NmzGjVqlKKiohQcHKxGjRq5HQAA1Ev1eNdQj5OJCRMm6OOPP9a8efMUEBCgV155RU899ZRiY2O1ePHi6ogRAADUYR4Pc3zwwQdavHixevbsqT/96U/q1q2bWrZsqfj4eC1ZskQpKSnVEScAAHVbPX6bw+PKxMmTJ9WiRQtJF+ZHnDx5UpJ0yy23aOPGjdZGBwCAl7i4AqaZw1t5nEy0aNFChw8fliS1adNGb775pqQLFYuLG38BAID6w+Nk4k9/+pO++OILSdITTzyhuXPnKjAwUOnp6Ro/frzlAQIA4BXq8QRMj+dMpKenu/7cu3dvffXVV9q1a5datmyp9u3bWxocAACo+zyuTPxafHy8Bg8eTCIBAKjXbDI5Z8Lk8//2t7/JZrNpzJgxrnMlJSVKS0tT48aNFRISoiFDhqiwsNCtX15envr376+GDRsqKipK48eP1/nz5z16dqUqE3PmzKn0DR999FGPAgAAAObs2LFDL7300iX/sE9PT9eKFSv01ltvKSwsTKNGjdLgwYO1ZcsWSRd2/O7fv79iYmK0detW5efna9iwYfLz89P06dMr/fxKJROzZs2q1M1sNtu/ZDJx93Xt1MDmV9thANWibKjpAiVQZ1WU1eDPt0WvhhYVFbmdDggIUEBAwBW7FRcXKyUlRQsWLNDTTz/tOn/69GktXLhQS5cuVa9evSRJWVlZSkxM1LZt29S1a1d99NFH2rdvn9auXavo6Gh16NBB06ZN0+OPP66pU6fK39+/UqFX6r/y4cOHK3V88803lXooAAD/ciyagBkXF6ewsDDXkZmZedXHpqWlqX///urdu7fb+V27dqm8vNztfJs2bdSsWTPl5ORIknJyctSuXTtFR0e72iQnJ6uoqEh79+6t9Fc3tTcHAACw1tGjR932ubpaVWLZsmX67LPPtGPHjkuuFRQUyN/f/5JlG6Kjo1VQUOBq88tE4uL1i9cqi2QCAAArWLTRl91ur9SmmUePHtVjjz2mNWvWKDAw0MSDzWOwFAAAC9T0Cpi7du3SiRMndMMNN6hBgwZq0KCBNmzYoDlz5qhBgwaKjo5WWVmZTp065davsLBQMTExkqSYmJhL3u64+Plim8ogmQAAwAvddttt2rNnj3bv3u06OnfurJSUFNef/fz8tG7dOlefAwcOKC8vTw6HQ5LkcDi0Z88enThxwtVmzZo1stvtSkpKqnQsDHMAAGAFi4Y5Kis0NFRt27Z1OxccHKzGjRu7zo8YMUJjx45VRESE7Ha7Ro8eLYfDoa5du0qS+vTpo6SkJN1///2aMWOGCgoKNGnSJKWlpV11rsavVakysWnTJg0dOlQOh0PfffedJOl//ud/tHnz5qrcDgAA71cHl9OeNWuW7rzzTg0ZMkTdu3dXTEyM3n33Xdd1X19fZWdny9fXVw6HQ0OHDtWwYcOUkZHh0XM8rky88847uv/++5WSkqLPP/9cpaWlki68zzp9+nStXLnS01sCAAALrF+/3u1zYGCg5s6dq7lz516xT3x8vOm/uz2uTDz99NOaP3++FixYID+/nxdyuvnmm/XZZ5+ZCgYAAG9Vn7cg97gyceDAAXXv3v2S82FhYZfMGAUAoN6waAVMb+RxZSImJka5ubmXnN+8ebNatGhhSVAAAHidOjhnoqZ4nEw89NBDeuyxx7R9+3bZbDYdP35cS5Ys0bhx4zRy5MjqiBEAANRhHg9zPPHEE3I6nbrtttt07tw5de/eXQEBARo3bpxGjx5dHTECAFDnmZ33UK/mTNhsNv31r3/V+PHjlZubq+LiYiUlJSkkJKQ64gMAwDvU8DoTdUmVF63y9/f3aHUsAADwr8njZOLWW2+VzXblGacff/yxqYAAAPBKZl/vrE+ViQ4dOrh9Li8v1+7du/Xll18qNTXVqrgAAPAuDHNU3qxZsy57furUqSouLjYdEAAA8C6W7Ro6dOhQvfrqq1bdDgAA71KP15mwbNfQnJwcBQYGWnU7AAC8Cq+GemDw4MFunw3DUH5+vnbu3KnJkydbFhgAAPAOHicTYWFhbp99fHzUunVrZWRkqE+fPpYFBgAAvINHyURFRYX+9Kc/qV27dmrUqFF1xQQAgPepx29zeDQB09fXV3369GF3UAAAfqU+b0Hu8dscbdu21TfffFMdsQAAAC/kcTLx9NNPa9y4ccrOzlZ+fr6KiorcDgAA6q16+Fqo5MGciYyMDP3lL3/RHXfcIUm666673JbVNgxDNptNFRUV1kcJAEBdV4/nTFQ6mXjqqaf05z//WZ988kl1xgMAALxMpZMJw7iQMvXo0aPaggEAwFuxaFUlXW23UAAA6jWGOSrnuuuu+82E4uTJk6YCAgAA3sWjZOKpp566ZAVMAADAMEel3XvvvYqKiqquWAAA8F71eJij0utMMF8CAABcjsdvcwAAgMuox5WJSicTTqezOuMAAMCrMWcCAACYU48rEx7vzQEAAPBLVCYAALBCPa5MkEwAAGCB+jxngmEOAABgCpUJAACswDAHAAAwg2EOAACAKqIyAQCAFRjmAAAAptTjZIJhDgAAYAqVCQAALGD752Gmv7cimQAAwAoMcwAAADMuvhpq5vDEvHnz1L59e9ntdtntdjkcDq1atcp1vaSkRGlpaWrcuLFCQkI0ZMgQFRYWut0jLy9P/fv3V8OGDRUVFaXx48fr/PnzHn93kgkAALxQ06ZN9be//U27du3Szp071atXLw0cOFB79+6VJKWnp+uDDz7QW2+9pQ0bNuj48eMaPHiwq39FRYX69++vsrIybd26Va+99poWLVqkKVOmeBwLwxwAAFihhoc5BgwY4Pb5mWee0bx587Rt2zY1bdpUCxcu1NKlS9WrVy9JUlZWlhITE7Vt2zZ17dpVH330kfbt26e1a9cqOjpaHTp00LRp0/T4449r6tSp8vf3r3QsVCYAALCKYeL4p6KiIrejtLT0Nx9bUVGhZcuW6ezZs3I4HNq1a5fKy8vVu3dvV5s2bdqoWbNmysnJkSTl5OSoXbt2io6OdrVJTk5WUVGRq7pRWSQTAADUIXFxcQoLC3MdmZmZV2y7Z88ehYSEKCAgQH/+85/13nvvKSkpSQUFBfL391d4eLhb++joaBUUFEiSCgoK3BKJi9cvXvMEwxwAAFjAqr05jh49Krvd7jofEBBwxT6tW7fW7t27dfr0ab399ttKTU3Vhg0bqh5EFZFMAABgBYvmTFx8O6My/P391bJlS0lSp06dtGPHDs2ePVt//OMfVVZWplOnTrlVJwoLCxUTEyNJiomJ0aeffup2v4tve1xsU1kMcwAA8C/C6XSqtLRUnTp1kp+fn9atW+e6duDAAeXl5cnhcEiSHA6H9uzZoxMnTrjarFmzRna7XUlJSR49l8oEAAAWqOktyCdOnKh+/fqpWbNmOnPmjJYuXar169frww8/VFhYmEaMGKGxY8cqIiJCdrtdo0ePlsPhUNeuXSVJffr0UVJSku6//37NmDFDBQUFmjRpktLS0q46tHI5JBMAAFihhl8NPXHihIYNG6b8/HyFhYWpffv2+vDDD3X77bdLkmbNmiUfHx8NGTJEpaWlSk5O1osvvujq7+vrq+zsbI0cOVIOh0PBwcFKTU1VRkaGx6GTTAAA4IUWLlx41euBgYGaO3eu5s6de8U28fHxWrlypelYSCYAALBATQ9z1CUkEwAAWKEeb/RFMgEAgBXqcTLBq6EAAMAUKhMAAFiAORMAAMAchjkAAACqhsoEAAAWsBmGbEbVywtm+tY2kgkAAKzAMAcAAEDVUJkAAMACvM0BAADMYZgDAACgaqhMAABgAYY5AACAOfV4mINkAgAAC9TnygRzJgAAgClUJgAAsALDHAAAwCxvHqowg2EOAABgCpUJAACsYBgXDjP9vRTJBAAAFuBtDgAAgCqiMgEAgBV4mwMAAJhhc144zPT3VgxzAAAAU6hMoMYN/UuB7v9Lodu5o7kBerB7G0lSv5QfdevdP6llu/+n4FCnBrdpq7NFvrURKvCbht36uXq2Paz4qFMqLffVniMxmruqi/K+D3e1efE/39cNv8t36/futkTNeLe763Ni0xN6pN92tWn6gwxD2nc0Sv+9sqty8xvX1FeBWQxz1A7DMPSf//mfevvtt/XTTz/p888/V4cOHa7Y/siRI0pISPjNdqj7jnwVqCf+2ML1uaLC5vpzYJBTO9eHauf6UI34PwW1ER5QaR1bHNc7W3+vfcci5etjaGTfTzX7wRW6b+Y9Kin3c7Vbvr2NXv7wRtfnkvKff/0G+Zfr+RErtWlfvJ5d3k2+Pk49dPtOzX5whe56JkUVTpJpb1Cf3+ao1WRi9erVWrRokdavX68WLVrommuuqc1wUIMqKqSfvve77LX3XomUJLV3FNdkSECVpC/s7/Z52ps9tfrJxWrT9HvtPhzrOl9S1kAnixte9h7xUacUFlyqlz+6USdOh0iSFq7tpCVj31aTRsU69mNY9X0BWId1JmrHoUOH1KRJE9100021GQZqwbUJZVr62V6Vlfpo/66GejWzib7/zr+2wwJMCwkskyQVnQt0O5/cMVd9b8jVj2eCtHlfvF5dd4NK/1m5yPs+TKfOBuquf/tKiz7uKF+boQE3fqXDheHK/ym0xr8D4Klam4A5fPhwjR49Wnl5ebLZbGrevLlWr16tW265ReHh4WrcuLHuvPNOHTp06Ir3+Omnn5SSkqLIyEgFBQWpVatWysrKcl0/evSo7rnnHoWHhysiIkIDBw7UkSNHrni/0tJSFRUVuR2w3lefNdTMMXH6a0oLvfDEtYppVqbn3stVUHBFbYcGmGKzGRpz11Z9cThG3xRGuM5/uLulpi7rpbSX7tTiTzqq3w0H9dS9H7uunyv11yPzByi540FteGahPn76VXVtfUzpC+9QhZN58t7i4jCHmcNb1dpP6ezZs5WRkaGmTZsqPz9fO3bs0NmzZzV27Fjt3LlT69atk4+Pj+6++245nZd/X2by5Mnat2+fVq1apf3792vevHmuoZLy8nIlJycrNDRUmzZt0pYtWxQSEqK+ffuqrKzssvfLzMxUWFiY64iLi6u271+f7fzErk3Z4Tq8P0i7Ntg1aWgLhdgr1P2uU7UdGmDK+EGb9bvok5q09Da38//YnqTtX8fpUEFjffh5Kz31xq3q2e6Iro04LUkKaHBef/3DBv3fIzF68L8H6eEXB+qbgkZ67oFVCmhwvja+CqrCsODwUrU2zBEWFqbQ0FD5+voqJiZGkjRkyBC3Nq+++qoiIyO1b98+tW3b9pJ75OXlqWPHjurcubMkqXnz5q5rb7zxhpxOp1555RXZbBcm92VlZSk8PFzr169Xnz59LrnfxIkTNXbsWNfnoqIiEooacLbIV8e+CVBs88sneYA3+MvAzbo58Vv9ed5d+v6f8x6uZG9elCSp6TVF+u5kmPp0zFWTRmf04NxBMowLv6+m/O9tWvPUInX7/RGt/aJltccPmFGn6mcHDx7UfffdpxYtWshut7uSg7y8vMu2HzlypJYtW6YOHTpowoQJ2rp1q+vaF198odzcXIWGhiokJEQhISGKiIhQSUnJFYdOAgICZLfb3Q5Uv8CGFYqNL9PJE7ypDG9k6C8DN6tH28Ma9fIA5f/02783rov9UZL0Y9GFCZmBfuflNGxu8++Mf3728ebadz1Tn4c56tRv7wEDBig+Pl4LFixQbGysnE6n2rZte8VhiX79+unbb7/VypUrtWbNGt12221KS0vTzJkzVVxcrE6dOmnJkiWX9IuMjKzur4KreGjKcW37yK4Tx/zVOKZc948rUIVTWv9eI0lSo8hyNYo6r9iEUklSQpv/p3NnffX9d346c6pO/cgCGj9os/p0zNWE15J1tsRPESHnJElnS/xVer6Bro04rT4dc7X1q2YqOheolk1+1GMDcvTZN02UW3BhDYlPD16rUf23afygzXpra1vZbIaG9dytCqePdh2KvdrjUZfwNkft+/HHH3XgwAEtWLBA3bp1kyRt3rz5N/tFRkYqNTVVqamp6tatm8aPH6+ZM2fqhhtu0BtvvKGoqCgqDHXMNU3KNfHFbxXaqEKnf2ygvTuCNebOVjp98sKPY/9hP7otavXc8guVpJlj4rTmzYjL3hOoLUNu2idJmvfnD9zOT3ujp1bsaq3yCl/d2Oo73XvLHgX6n9eJ08FavydBr667wdX22+8bafyivhrRe5cWpC2X07Dp6+8aa8zCO/TjmeAa/T5AVdSZZKJRo0Zq3LixXn75ZTVp0kR5eXl64oknrtpnypQp6tSpk37/+9+rtLRU2dnZSkxMlCSlpKTo2Wef1cCBA10TPb/99lu9++67mjBhgpo2bVoTXwuXkTky/qrXX38uRq8/F1ND0QDmdJ3wn1e9fuJ0iB6Zf9dv3ufTg0316UF+L3mz+rxoVZ2ZM+Hj46Nly5Zp165datu2rdLT0/Xss89etY+/v78mTpyo9u3bq3v37vL19dWyZcskSQ0bNtTGjRvVrFkzDR48WImJiRoxYoRKSkqoVAAArFeP3+awGYYXD9JUs6KiIoWFhamnBqqB7fKrNQLe7vTQrrUdAlBtKspK9Nkbk3T69Olq+4fkxb8rHH0z1MAv8Lc7XMH58hLlrJ5SrbFWlzozzAEAgDerz8McJBMAAFjBaVw4zPT3UiQTAABYoR5vQV5nJmACAIDKy8zM1I033qjQ0FBFRUVp0KBBOnDggFubkpISpaWlqXHjxgoJCdGQIUNUWFjo1iYvL0/9+/dXw4YNFRUVpfHjx+v8ec+WcSeZAADAAjaZXAHTw+dt2LBBaWlp2rZtm9asWaPy8nL16dNHZ8+edbVJT0/XBx98oLfeeksbNmzQ8ePHNXjwYNf1iooK9e/fX2VlZdq6datee+01LVq0SFOmTPEoFoY5AACwgkUrYP56x+qAgAAFBARc0nz16tVunxctWqSoqCjt2rVL3bt31+nTp7Vw4UItXbpUvXr1knRhj6rExERt27ZNXbt21UcffaR9+/Zp7dq1io6OVocOHTRt2jQ9/vjjmjp1qvz9/SsVOpUJAADqkLi4OLcdrDMzMyvV7/TpC7vQRkRcWCl4165dKi8vV+/evV1t2rRpo2bNmiknJ0eSlJOTo3bt2ik6OtrVJjk5WUVFRdq7d2+lY6YyAQCABax6NfTo0aNu60xcrirxa06nU2PGjNHNN9/s2mW7oKBA/v7+Cg8Pd2sbHR2tgoICV5tfJhIXr1+8VlkkEwAAWMGitzmqsmt1Wlqavvzyy0rtaVUdGOYAAMCLjRo1StnZ2frkk0/c9p2KiYlRWVmZTp065da+sLBQMTExrja/frvj4ueLbSqDZAIAAAvYDMP04QnDMDRq1Ci99957+vjjj5WQkOB2vVOnTvLz89O6detc5w4cOKC8vDw5HA5JksPh0J49e3TixAlXmzVr1shutyspKanSsTDMAQCAFZz/PMz090BaWpqWLl2qf/zjHwoNDXXNcQgLC1NQUJDCwsI0YsQIjR07VhEREbLb7Ro9erQcDoe6dr2wJ0+fPn2UlJSk+++/XzNmzFBBQYEmTZqktLS0Ss3VuIhkAgAALzRv3jxJUs+ePd3OZ2Vlafjw4ZKkWbNmycfHR0OGDFFpaamSk5P14osvutr6+voqOztbI0eOlMPhUHBwsFJTU5WRkeFRLCQTAABYoCpDFb/u74nKbPodGBiouXPnau7cuVdsEx8fr5UrV3r07F8jmQAAwAr1eG8OkgkAAKxg0QqY3oi3OQAAgClUJgAAsIBVK2B6I5IJAACswDAHAABA1VCZAADAAjbnhcNMf29FMgEAgBUY5gAAAKgaKhMAAFiBRasAAIAZNb2cdl3CMAcAADCFygQAAFaoxxMwSSYAALCCIcnM653em0uQTAAAYAXmTAAAAFQRlQkAAKxgyOScCcsiqXEkEwAAWKEeT8BkmAMAAJhCZQIAACs4JdlM9vdSJBMAAFiAtzkAAACqiMoEAABWqMcTMEkmAACwQj1OJhjmAAAAplCZAADACvW4MkEyAQCAFXg1FAAAmMGroQAAAFVEZQIAACswZwIAAJjiNCSbiYTA6b3JBMMcAADAFCoTAABYgWEOAABgjslkQt6bTDDMAQAATKEyAQCAFRjmAAAApjgNmRqq4G0OAABQX1GZAADACobzwmGmv5cimQAAwArMmQAAAKYwZwIAAHibjRs3asCAAYqNjZXNZtPy5cvdrhuGoSlTpqhJkyYKCgpS7969dfDgQbc2J0+eVEpKiux2u8LDwzVixAgVFxd7FAfJBAAAVrg4zGHm8NDZs2d1/fXXa+7cuZe9PmPGDM2ZM0fz58/X9u3bFRwcrOTkZJWUlLjapKSkaO/evVqzZo2ys7O1ceNGPfzwwx7FwTAHAABWMGRyzoTnXfr166d+/fpd/naGoeeff16TJk3SwIEDJUmLFy9WdHS0li9frnvvvVf79+/X6tWrtWPHDnXu3FmS9MILL+iOO+7QzJkzFRsbW6k4qEwAAFCHFBUVuR2lpaVVus/hw4dVUFCg3r17u86FhYWpS5cuysnJkSTl5OQoPDzclUhIUu/eveXj46Pt27dX+lkkEwAAWMGiYY64uDiFhYW5jszMzCqFU1BQIEmKjo52Ox8dHe26VlBQoKioKLfrDRo0UEREhKtNZTDMAQCAFZxOSSbWinBe6Hv06FHZ7XbX6YCAAJOBVT8qEwAA1CF2u93tqGoyERMTI0kqLCx0O19YWOi6FhMToxMnTrhdP3/+vE6ePOlqUxkkEwAAWKEW3ua4moSEBMXExGjdunWuc0VFRdq+fbscDockyeFw6NSpU9q1a5erzccffyyn06kuXbpU+lkMcwAAYIVaWAGzuLhYubm5rs+HDx/W7t27FRERoWbNmmnMmDF6+umn1apVKyUkJGjy5MmKjY3VoEGDJEmJiYnq27evHnroIc2fP1/l5eUaNWqU7r333kq/ySGRTAAA4LV27typW2+91fV57NixkqTU1FQtWrRIEyZM0NmzZ/Xwww/r1KlTuuWWW7R69WoFBga6+ixZskSjRo3SbbfdJh8fHw0ZMkRz5szxKA6SCQAArFALy2n37NlTxlUqGjabTRkZGcrIyLhim4iICC1dutTjZ/8SyQQAABYwDKcMEzt/mulb20gmAACwgmGY26zLi3cN5W0OAABgCpUJAACsYJicM+HFlQmSCQAArOB0SjYT8x68eM4EwxwAAMAUKhMAAFiBYQ4AAGCG4XTKMDHM4c2vhjLMAQAATKEyAQCAFRjmAAAApjgNyVY/kwmGOQAAgClUJgAAsIJhSDKzzoT3ViZIJgAAsIDhNGSYGOa42u6fdR3JBAAAVjCcMleZ4NVQAABQT1GZAADAAgxzAAAAc+rxMAfJxFVczBLPq9zUOiRAXVZRVlLbIQDVpqL8ws93Tfyr3+zfFedVbl0wNcxmeHNdpZodO3ZMcXFxtR0GAMCko0ePqmnTptVy75KSEiUkJKigoMD0vWJiYnT48GEFBgZaEFnNIZm4CqfTqePHjys0NFQ2m622w6kXioqKFBcXp6NHj8put9d2OIDl+BmvWYZh6MyZM4qNjZWPT/W9c1BSUqKysjLT9/H39/e6REJimOOqfHx8qi2TxdXZ7XZ+0eJfGj/jNScsLKzanxEYGOiVSYBVeDUUAACYQjIBAABMIZlAnRIQEKAnn3xSAQEBtR0KUC34Gce/IiZgAgAAU6hMAAAAU0gmAACAKSQTAADAFJIJAPCQYRh6+OGHFRERIZvNpt27d1+1/ZEjRyrVDvBWJBOoVj179tSYMWNqOwzAUqtXr9aiRYuUnZ2t/Px8tW3btrZDAmoVK2CiVhmGoYqKCjVowI8ivMehQ4fUpEkT3XTTTbUdClAnUJlAtRk+fLg2bNig2bNny2azyWazadGiRbLZbFq1apU6deqkgIAAbd68WcOHD9egQYPc+o8ZM0Y9e/Z0fXY6ncrMzFRCQoKCgoJ0/fXX6+23367ZL4V6b/jw4Ro9erTy8vJks9nUvHlzrV69WrfccovCw8PVuHFj3XnnnTp06NAV7/HTTz8pJSVFkZGRCgoKUqtWrZSVleW6fvToUd1zzz0KDw9XRESEBg4cqCNHjtTAtwOqhmQC1Wb27NlyOBx66KGHlJ+fr/z8fNcurE888YT+9re/af/+/Wrfvn2l7peZmanFixdr/vz52rt3r9LT0zV06FBt2LChOr8G4Gb27NnKyMhQ06ZNlZ+frx07dujs2bMaO3asdu7cqXXr1snHx0d33323nE7nZe8xefJk7du3T6tWrdL+/fs1b948XXPNNZKk8vJyJScnKzQ0VJs2bdKWLVsUEhKivn37WrKRFFAdqC2j2oSFhcnf318NGzZUTEyMJOmrr76SJGVkZOj222+v9L1KS0s1ffp0rV27Vg6HQ5LUokULbd68WS+99JJ69Ohh/RcALiMsLEyhoaHy9fV1/VwPGTLErc2rr76qyMhI7du377LzKfLy8tSxY0d17txZktS8eXPXtTfeeENOp1OvvPKKa7firKwshYeHa/369erTp081fTOg6kgmUCsu/hKtrNzcXJ07d+6SBKSsrEwdO3a0MjTAYwcPHtSUKVO0fft2/fDDD66KRF5e3mWTiZEjR2rIkCH67LPP1KdPHw0aNMg1/+KLL75Qbm6uQkND3fqUlJRcdegEqE0kE6gVwcHBbp99fHz065Xdy8vLXX8uLi6WJK1YsULXXnutWzv2OEBtGzBggOLj47VgwQLFxsbK6XSqbdu2VxyW6Nevn7799lutXLlSa9as0W233aa0tDTNnDlTxcXF6tSpk5YsWXJJv8jIyOr+KkCVkEygWvn7+6uiouI320VGRurLL790O7d79275+flJkpKSkhQQEKC8vDyGNFCn/Pjjjzpw4IAWLFigbt26SZI2b978m/0iIyOVmpqq1NRUdevWTePHj9fMmTN1ww036I033lBUVJTsdnt1hw9YggmYqFbNmzfX9u3bdeTIEbfy76/16tVLO3fu1OLFi3Xw4EE9+eSTbslFaGioxo0bp/T0dL322ms6dOiQPvvsM73wwgt67bXXaurrAJdo1KiRGjdurJdfflm5ubn6+OOPNXbs2Kv2mTJliv7xj38oNzdXe/fuVXZ2thITEyVJKSkpuuaaazRw4EBt2rRJhw8f1vr16/Xoo4/q2LFjNfGVAI+RTKBajRs3Tr6+vkpKSlJkZKTy8vIu2y45OVmTJ0/WhAkTdOONN+rMmTMaNmyYW5tp06Zp8uTJyszMVGJiovr27asVK1YoISGhJr4KcFk+Pj5atmyZdu3apbZt2yo9PV3PPvvsVfv4+/tr4sSJat++vbp37y5fX18tW7ZMktSwYUNt3LhRzZo10+DBg5WYmKgRI0aopKSESgXqLLYgBwAAplCZAAAAppBMAAAAU0gmAACAKSQTAADAFJIJAABgCskEAAAwhWQCAACYQjIBAABMIZkA6rjhw4dr0KBBrs89e/bUmDFjajyO9evXy2az6dSpU1dsY7PZtHz58krfc+rUqerQoYOpuI4cOSKbzabdu3ebug+AqiOZAKpg+PDhstlsstls8vf3V8uWLZWRkaHz589X+7PfffddTZs2rVJtK5MAAIBZ7BoKVFHfvn2VlZWl0tJSrVy5UmlpafLz89PEiRMvaVtWViZ/f39LnhsREWHJfQDAKlQmgCoKCAhQTEyM4uPjNXLkSPXu3Vvvv/++pJ+HJp555hnFxsaqdevWkqSjR4/qnnvuUXh4uCIiIjRw4EAdOXLEdc+KigqNHTtW4eHhaty4sSZMmKBfb5/z62GO0tJSPf7444qLi1NAQIBatmyphQsX6siRI7r11lslXdjZ0mazafjw4ZIkp9OpzMxMJSQkKCgoSNdff73efvttt+esXLlS1113nYKCgnTrrbe6xVlZjz/+uK677jo1bNhQLVq00OTJk1VeXn5Ju5deeklxcXFq2LCh7rnnHp0+fdrt+iuvvKLExEQFBgaqTZs2evHFFz2OBUD1IZkALBIUFKSysjLX53Xr1unAgQNas2aNsrOzVV5eruTkZIWGhmrTpk3asmWLQkJC1LdvX1e/5557TosWLdKrr76qzZs36+TJk3rvvfeu+txhw4bpf//3fzVnzhzt379fL730kkJCQhQXF6d33nlHknTgwAHl5+dr9uzZkqTMzEwtXrxY8+fP1969e5Wenq6hQ4dqw4YNki4kPYMHD9aAAQO0e/duPfjgg3riiSc8/m8SGhqqRYsWad++fZo9e7YWLFigWbNmubXJzc3Vm2++qQ8++ECrV6/W559/rkceecR1fcmSJZoyZYqeeeYZ7d+/X9OnT9fkyZPZeh6oSwwAHktNTTUGDhxoGIZhOJ1OY82aNUZAQIAxbtw41/Xo6GijtLTU1ed//ud/jNatWxtOp9N1rrS01AgKCjI+/PBDwzAMo0mTJsaMGTNc18vLy42mTZu6nmUYhtGjRw/jscceMwzDMA4cOGBIMtasWXPZOD/55BNDkvHTTz+5zpWUlBgNGzY0tm7d6tZ2xIgRxn333WcYhmFMnDjRSEpKcrv++OOPX3KvX5NkvPfee1e8/uyzzxqdOnVyfX7yyScNX19f49ixY65zq1atMnx8fIz8/HzDMAzjd7/7nbF06VK3+0ybNs1wOByGYRjG4cOHDUnG559/fsXnAqhezJkAqig7O1shISEqLy+X0+nUf/zHf2jq1Kmu6+3atXObJ/HFF18oNzdXoaGhbvcpKSnRoUOHdPr0aeXn56tLly6uaw0aNFDnzp0vGeq4aPfu3fL19VWPHj0qHXdubq7OnTun22+/3e18WVmZOnbsKEnav3+/WxyS5HA4Kv2Mi9544w3NmTNHhw4dUnFxsc6fPy+73e7WplmzZrr22mvdnuN0OnXgwAGFhobq0KFDGjFihB566CFXm/PnzyssLMzjeABUD5IJoIpuvfVWzZs3T/7+/oqNjVWDBu7/OwUHB7t9Li4uVqdOnbRkyZJL7hUZGVmlGIKCgjzuU1xcLElasWKF21/i0oV5IFbJyclRSkqKnnrqKSUnJyssLEzLli3Tc88953GsCxYsuCS58fX1tSxWAOaQTABVFBwcrJYtW1a6/Q033KA33nhDUVFRl/zr/KImTZpo+/bt6t69u6QL/wLftWuXbrjhhsu2b9eunZxOpzZs2KDevXtfcv1iZaSiosJ1LikpSQEBAcrLy7tiRSMxMdE1mfSibdu2/faX/IWtW7cqPj5ef/3rX13nvv3220va5eXl6fjx44qNjXU9x8fHR61bt1Z0dLRiY2P1zTffKCUlxaPnA6g5TMAEakhKSoquueYaDRw4UJs2bdLhw4e1fv16Pfroozp27Jgk6bHHHtPf/vY3LV++XF999ZUeeeSRq64R0bx5c6WmpuqBBx7Q8uXLXfd88803JUnx8fGy2WzKzs7W999/r+LiYoWGhmrcuHFKT0/Xa6+9pkOHDumzzz7TCy+84JrU+Oc//1kHDx7U+PHjdeDAAS1dulSLFi3y6Pu2atVKeXl5WrZsmQ4dOqQ5c+ZcdjJpYGCgUlNT9cUXX2jTpk169NFHdc899ygmJkaS9NRTTykzM1Nz5szR119/rT179igrK0t///vfPYoHQPUhmQBqSMOGDbVx40Y1a9ZMgwcPVmJiokaMGKGSkhJXpeIvf/mL7r//fqWmpsrhcCg0NFR33333Ve87b948/fu//7seeeQRtWnTRg899JDOnj0rSbr22mv11FNP6YknnlB0dLRGjRolSZo2bZomT56szMxMJSYmqm/fvlqxYoUSEhIkXZjH8M4772j58uW6/vrrNX/+fE2fPt2j73vXXXcpPT1do0aNUocOHbR161ZNnjz5knYtW7bU4MGDdccdd6hPnz5q376926ufDz74oF555RVlZWWpXbt26tGjhxYtWuSKFUDtsxlXmtkFAABQCVQmAACAKSQTAADAFJIJAABgCskEAAAwhWQCAACYQjIBAABMIZkAAACmkEwAAABTSCYAAIApJBMAAMAUkgkAAGDK/wc2/l4TCbsYTgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1491/1491 [00:08<00:00, 184.09it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:06<00:00, 133.27it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pheme_results_1 = get_results_multi(\"pheme\", 0.2, 50, pheme, [[twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]], model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.74s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.29s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.44s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.84s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.48s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.70s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.20s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.53s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.38s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.60s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.59s/trial, best loss: 0.44495412844036697]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.4977064220183486]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.4977064220183486]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.69s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.05s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.60s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.44036697247706424]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.44036697247706424]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.07s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.88s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.73s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.4701834862385321]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 9/9 [00:01<00:00,  2.00s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.03s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.4472477064220184]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.21s/trial, best loss: 0.481651376146789]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.36s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.85s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.56s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.45s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 8/8 [00:21<00:00, 21.52s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 9/9 [00:21<00:00, 21.56s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 10/10 [00:21<00:00, 21.57s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.08s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 13/13 [00:07<00:00,  7.35s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.52s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.66s/trial, best loss: 0.4357798165137615]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/trial, best loss: 0.47477064220183485]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.47477064220183485]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.70s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.95s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.15s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.78s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.52s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.69s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.64s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.14s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.66s/trial, best loss: 0.4357798165137615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.6166666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.35]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.35]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.35]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.35]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.35]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.56s/trial, best loss: 0.35]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.35]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.35]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.53s/trial, best loss: 0.35]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.35]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.35]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.35]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.35]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.35]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.53s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.54s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 9/9 [00:07<00:00,  7.06s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.04s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 13/13 [00:14<00:00, 14.13s/trial, best loss: 0.35]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.35]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5166666666666666]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.5166666666666666]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.10s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.6428571428571428]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.92s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.5535714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.5535714285714286]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.33s/trial, best loss: 0.5535714285714286]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.39s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.27s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.70s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.97s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:17<00:00, 17.08s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.05s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.390625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.328125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.328125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.328125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.328125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.328125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.328125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.328125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.328125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.328125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.328125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.328125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.328125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.328125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.328125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.40625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.40625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.40625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.359375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.359375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.359375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.359375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.359375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.359375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.359375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.359375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.359375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.359375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.359375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.40625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.40625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.34375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.34375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.34375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.34375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.34375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.34375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.34375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.34375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.34375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.34375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.34375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.34375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.34375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.359375]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.30s/trial, best loss: 0.359375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.359375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.359375]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.51s/trial, best loss: 0.359375]\n",
      "100%|██████████| 7/7 [00:05<00:00,  5.24s/trial, best loss: 0.359375]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.90s/trial, best loss: 0.34375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.3125]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.12s/trial, best loss: 0.296875]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.296875]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.23s/trial, best loss: 0.296875]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.296875]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.14s/trial, best loss: 0.296875]\n",
      "100%|██████████| 15/15 [00:21<00:00, 21.55s/trial, best loss: 0.296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.328125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.328125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.328125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.328125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.328125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.328125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.328125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.328125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.328125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.328125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.328125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.296875]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.296875]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.296875]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.296875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.25s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:05<00:00,  5.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.05882352941176472]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.05882352941176472]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.05882352941176472]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.05882352941176472]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.05882352941176472]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.5882352941176471]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.6470588235294117]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.6470588235294117]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.4117647058823529]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:13<00:00, 96.69it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1491/1491 [00:19<00:00, 77.79it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:13<00:00, 59.03it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pheme_results_2 = get_results_multi(\"pheme\", 0.5, 20, pheme, [[twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]], model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/trial, best loss: 0.47432432432432436]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.40s/trial, best loss: 0.4472972972972973]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.69s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.43s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.47s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.57s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.35s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.37s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.11s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.43s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.41s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.57s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.41s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.39s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.14s/trial, best loss: 0.3756756756756757]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.41081081081081083]\n",
      "100%|██████████| 2/2 [00:13<00:00, 13.11s/trial, best loss: 0.41081081081081083]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.25s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.4067567567567567]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.13s/trial, best loss: 0.4027027027027027]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.4027027027027027]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.08s/trial, best loss: 0.4027027027027027]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.4027027027027027]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.18s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.16s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.4162162162162162]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.10s/trial, best loss: 0.4162162162162162]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.29s/trial, best loss: 0.4162162162162162]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.4162162162162162]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.93s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.07s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.70s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.39s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.87s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.05s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.4094594594594595]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.72s/trial, best loss: 0.44324324324324327]\n",
      "100%|██████████| 2/2 [00:09<00:00,  9.11s/trial, best loss: 0.43513513513513513]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.93s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 4/4 [00:21<00:00, 21.53s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.51s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 7/7 [00:21<00:00, 21.52s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 8/8 [00:08<00:00,  8.67s/trial, best loss: 0.41486486486486485]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.33s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 11/11 [00:05<00:00,  5.48s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 12/12 [00:21<00:00, 21.51s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.39s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.40135135135135136]\n",
      "100%|██████████| 15/15 [00:21<00:00, 21.53s/trial, best loss: 0.40135135135135136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.75s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.97s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.83s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.02s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.04s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.16s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.27s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.21s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.86s/trial, best loss: 0.3878378378378379]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.03s/trial, best loss: 0.3783783783783784]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.35s/trial, best loss: 0.35]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.35]\n",
      "100%|██████████| 15/15 [00:04<00:00,  4.21s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.47317073170731705]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.67s/trial, best loss: 0.47317073170731705]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.28s/trial, best loss: 0.47317073170731705]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.44s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.61s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.75s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.27s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.52s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.36s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.64s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.34s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.56s/trial, best loss: 0.40487804878048783]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.94s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.3926829268292683]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.37317073170731707]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.37317073170731707]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.37317073170731707]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.37317073170731707]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.36829268292682926]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.36829268292682926]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.36829268292682926]\n",
      "100%|██████████| 14/14 [00:05<00:00,  5.05s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.36585365853658536]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.63s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.38s/trial, best loss: 0.4512195121951219]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.37s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.56s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.4463414634146341]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.51s/trial, best loss=?]\n",
      "Error training Adaboost in category News, skipping\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.30s/trial, best loss: 0.3975609756097561]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.04s/trial, best loss: 0.3829268292682927]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3829268292682927]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.84s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.61s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.88s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.12s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.51s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.73s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.57s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.45s/trial, best loss: 0.3780487804878049]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.77s/trial, best loss: 0.36341463414634145]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.57s/trial, best loss: 0.36341463414634145]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.45s/trial, best loss: 0.36341463414634145]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5089820359281437]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.437125748502994]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.5149700598802396]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.46706586826347307]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.46706586826347307]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.94s/trial, best loss: 0.46706586826347307]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.46706586826347307]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.46706586826347307]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.45508982035928147]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/trial, best loss: 0.5149700598802396]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.5089820359281437]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.5029940119760479]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5029940119760479]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.5029940119760479]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.26s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.01s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.4850299401197605]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.437125748502994]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.87s/trial, best loss: 0.437125748502994]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.437125748502994]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.4610778443113772]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.57s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 4/4 [00:14<00:00, 14.63s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.58s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.98s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 9/9 [00:07<00:00,  7.70s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.12s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 13/13 [00:21<00:00, 21.53s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 14/14 [00:09<00:00,  9.60s/trial, best loss: 0.3892215568862275]\n",
      "100%|██████████| 15/15 [00:21<00:00, 21.42s/trial, best loss: 0.3892215568862275]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5209580838323353]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.50s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.39520958083832336]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.12337662337662336]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.09740259740259738]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.09740259740259738]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.06s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.13s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.96s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.15s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.11038961038961037]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.23s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.55s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 3/3 [00:07<00:00,  7.39s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.41s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 5/5 [00:07<00:00,  7.52s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.81s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.15s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 9/9 [00:21<00:00, 21.50s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.43s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.07s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.46s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.09s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 15/15 [00:10<00:00, 10.60s/trial, best loss: 0.10389610389610393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.94s/trial, best loss: 0.1298701298701299]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.12337662337662336]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.01s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 11/11 [00:01<00:00,  2.00s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.12s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.10389610389610393]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.4292452830188679]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4811320754716981]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.36s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.4575471698113207]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.94s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.25s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.44339622641509435]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.51s/trial, best loss=?]\n",
      "Error training Adaboost in category Law & Government, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.37s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.60s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.72s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.75s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.15s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.00s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.06s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.45s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.12s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2971698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.011111111111111072]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.18888888888888888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 7/7 [00:01<00:00,  2.00s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.02777777777777779]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.07777777777777772]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.97s/trial, best loss: 0.07777777777777772]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.14s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.15s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.09s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.01666666666666672]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.061111111111111116]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 4/4 [00:09<00:00,  9.91s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 5/5 [00:21<00:00, 21.55s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.67s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.11s/trial, best loss: 0.005555555555555536]\n",
      "100%|██████████| 8/8 [00:13<00:00, 13.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:12<00:00, 12.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.36s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:10<00:00, 10.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.07s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.011111111111111072]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.07s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.5098039215686274]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.5098039215686274]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.5098039215686274]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4901960784313726]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4901960784313726]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.4901960784313726]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.4901960784313726]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.4901960784313726]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.3921568627450981]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.37254901960784315]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.6274509803921569]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.54s/trial, best loss: 0.5490196078431373]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.5490196078431373]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.5490196078431373]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.13s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4509803921568627]\n",
      "100%|██████████| 15/15 [00:21<00:00, 21.51s/trial, best loss: 0.4509803921568627]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.43137254901960786]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:14<00:00, 89.27it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1491/1491 [00:14<00:00, 99.57it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:10<00:00, 77.66it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pheme_results_3 = get_results_multi(\"pheme\", 0.2, 200, pheme, [[twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]], model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.96s/trial, best loss: 0.37621359223300976]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.03s/trial, best loss: 0.37621359223300976]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.23s/trial, best loss: 0.37621359223300976]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.80s/trial, best loss: 0.37621359223300976]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.28s/trial, best loss: 0.37621359223300976]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.28s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.31s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.90s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.39s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.72s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.28s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.38s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.00s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.50s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.67s/trial, best loss: 0.36407766990291257]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.97s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.34466019417475724]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.34466019417475724]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.18s/trial, best loss: 0.3398058252427184]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 7/7 [00:10<00:00, 10.51s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.82s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.27s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.3191747572815534]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.4004854368932039]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.22s/trial, best loss: 0.4004854368932039]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.98s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.57s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.13s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.55s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.00s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.61s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.39077669902912626]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.38834951456310685]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.52s/trial, best loss=?]\n",
      "Error training Adaboost in category Sensitive Subjects, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.4162621359223301]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.4004854368932039]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.40s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.34s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.23s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.74s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.13s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 9/9 [00:04<00:00,  4.86s/trial, best loss: 0.366504854368932]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.06s/trial, best loss: 0.3628640776699029]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.51s/trial, best loss: 0.3628640776699029]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.41s/trial, best loss: 0.3628640776699029]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.64s/trial, best loss: 0.3628640776699029]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.43s/trial, best loss: 0.3543689320388349]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.24s/trial, best loss: 0.3543689320388349]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.97s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.02s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.02s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.93s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.30s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.32s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.18s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.91s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 9/9 [00:04<00:00,  4.02s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.60s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.78s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.18s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.20s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.89s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.42s/trial, best loss: 0.41467065868263475]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.45s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.99s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.03s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.04s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.01s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.07s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.05s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.09s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.75s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.11s/trial, best loss: 0.37574850299401197]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/trial, best loss: 0.4610778443113772]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.95s/trial, best loss: 0.4565868263473054]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.77s/trial, best loss: 0.4565868263473054]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.4416167664670658]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.61s/trial, best loss: 0.4416167664670658]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.4416167664670658]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.4416167664670658]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.40s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.85s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.4401197604790419]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.43862275449101795]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.43862275449101795]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.4640718562874252]\n",
      "100%|██████████| 2/2 [00:21<00:00, 21.49s/trial, best loss: 0.4640718562874252]\n",
      "100%|██████████| 3/3 [00:21<00:00, 21.52s/trial, best loss: 0.4640718562874252]\n",
      "100%|██████████| 4/4 [00:09<00:00,  9.76s/trial, best loss: 0.4595808383233533]\n",
      "100%|██████████| 5/5 [00:21<00:00, 21.54s/trial, best loss: 0.4595808383233533]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.67s/trial, best loss: 0.4595808383233533]\n",
      "100%|██████████| 7/7 [00:11<00:00, 11.81s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 8/8 [00:21<00:00, 21.54s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.57s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.83s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 11/11 [00:21<00:00, 21.55s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.67s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.64s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.09s/trial, best loss: 0.38772455089820357]\n",
      "100%|██████████| 15/15 [00:10<00:00, 10.24s/trial, best loss: 0.38772455089820357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.92s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.23s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.67s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.76s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.77s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.12s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 11/11 [00:05<00:00,  5.80s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.61s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.77s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.47s/trial, best loss: 0.34730538922155685]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.86s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.4126984126984127]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.76s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.29s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.3849206349206349]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.34s/trial, best loss: 0.36904761904761907]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.16s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.24s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.40s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.3650793650793651]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.3650793650793651]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.4007936507936508]\n",
      "100%|██████████| 2/2 [00:08<00:00,  8.98s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 3/3 [00:21<00:00, 21.53s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.78s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.70s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.12s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 14/14 [00:21<00:00, 21.42s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 15/15 [00:08<00:00,  8.60s/trial, best loss: 0.38888888888888884]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.56s/trial, best loss: 0.39682539682539686]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.32s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.47s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.99s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.41s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.09s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.81s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.01s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.27956989247311825]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.2616487455197133]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.18s/trial, best loss: 0.21863799283154117]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.21863799283154117]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.21863799283154117]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.90s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.21505376344086025]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.11s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.39s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.49s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.13s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.50s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 4/4 [00:08<00:00,  8.54s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.57s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.13s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 9/9 [00:06<00:00,  6.06s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 12/12 [00:09<00:00,  9.50s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 13/13 [00:08<00:00,  8.17s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.31s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.57s/trial, best loss: 0.20788530465949817]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/trial, best loss: 0.2437275985663082]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.23655913978494625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.06s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.08s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.41s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.58s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.07s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.26s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.20788530465949817]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.3701298701298701]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.22s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.08s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.17s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.16s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.98s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.14s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.13s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.29s/trial, best loss: 0.31493506493506496]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.474025974025974]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.66s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.27s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.4415584415584416]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.4253246753246753]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.39s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.76s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.41s/trial, best loss: 0.42207792207792205]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.26s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.40s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.3831168831168831]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.53s/trial, best loss=?]\n",
      "Error training Adaboost in category Law & Government, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.25s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.41s/trial, best loss: 0.37662337662337664]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.74s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.06s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.49s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.33s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.98s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.04s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.20s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.52s/trial, best loss: 0.35064935064935066]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.1273885350318471]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.1273885350318471]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 7/7 [00:01<00:00,  2.00s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.02s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.94s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.10828025477707004]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.05s/trial, best loss: 0.10828025477707004]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.10828025477707004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.26751592356687903]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.13057324840764328]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.92s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.12420382165605093]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.12101910828025475]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.12101910828025475]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.12101910828025475]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.10509554140127386]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.10509554140127386]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.79s/trial, best loss: 0.10509554140127386]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.10509554140127386]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.10509554140127386]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.16s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 2/2 [00:18<00:00, 18.75s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.14s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.96s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 5/5 [00:21<00:00, 21.58s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 6/6 [00:21<00:00, 21.54s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.95s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.67s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 10/10 [00:21<00:00, 21.50s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 11/11 [00:21<00:00, 21.54s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 12/12 [00:21<00:00, 21.53s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 14/14 [00:21<00:00, 21.51s/trial, best loss: 0.10191082802547768]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.10191082802547768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/trial, best loss: 0.16560509554140124]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.05s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.40s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.48s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.72s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.13s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.10s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.31s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.76s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.22s/trial, best loss: 0.11146496815286622]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.11146496815286622]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.5294117647058824]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.5294117647058824]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.8823529411764706]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.8235294117647058]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.7941176470588236]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.7941176470588236]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.7941176470588236]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.7941176470588236]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.7352941176470589]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.7352941176470589]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.7352941176470589]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.7352941176470589]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.7058823529411764]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.19s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.13s/trial, best loss: 0.3529411764705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6764705882352942]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.6176470588235294]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.20588235294117652]\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5789473684210527]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:09<00:00,  9.38s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.21052631578947367]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.7222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.7222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.7222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.9444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.7777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.6111111111111112]\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.3913043478260869]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.6231884057971014]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.6231884057971014]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.6086956521739131]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.5507246376811594]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.5507246376811594]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5507246376811594]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.5507246376811594]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.5507246376811594]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.536231884057971]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.37681159420289856]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.37681159420289856]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.37681159420289856]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.37681159420289856]\n",
      "100%|██████████| 14/14 [00:01<00:00,  2.00s/trial, best loss: 0.37681159420289856]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.37681159420289856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.5072463768115942]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.5072463768115942]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.4057971014492754]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.22s/trial, best loss: 0.42028985507246375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.35s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.4057971014492754]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.4057971014492754]\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:07<00:00, 177.95it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAGwCAYAAAATw+f5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDpUlEQVR4nO3de3gV1b3/8c9OyJVkJyTmQiSEUBSSAoLgD7aKIiJBUUE4tdogoaK2NKCEcpEWEIMSD2gRPAiKGKSFg3eq4aKAcg8IKB4EjIBAUEhQuYSAue75/UHZdsvF7Mzkspv363nmedgza818p43Jd3/XmjU2wzAMAQAAVJNPXQcAAAC8G8kEAAAwhWQCAACYQjIBAABMIZkAAACmkEwAAABTSCYAAIApjeo6gPrM6XTqyJEjCg0Nlc1mq+twAAAeMgxDp0+fVlxcnHx8au77c0lJicrKykyfx9/fX4GBgRZEVLtIJi7jyJEjio+Pr+swAAAmHT58WM2aNauRc5eUlCgxIUQFxypNnys2NlYHDhzwuoSCZOIyQkNDJUmHPm0hewgjQvjPdMewtLoOAagxFRUl2vpRluv3eU0oKytTwbFKHdreQvbQ6v+tKDrtVEKngyorKyOZ+E9yfmjDHuJj6gcEqM8a+XnXLy2gOmpjqDok1KaQ0OpfxynvHU4nmQAAwAKVhlOVJt52VWk4rQumlpFMAABgAacMOVX9bMJM37pG7R4AAJhCZQIAAAs45ZSZgQpzvesWyQQAABaoNAxVGtUfqjDTt64xzAEAAEyhMgEAgAUa8gRMkgkAACzglKHKBppMMMwBAABMoTIBAIAFGOYAAACm8DQHAABANVGZAADAAs5/bWb6eyuSCQAALFBp8mkOM33rGskEAAAWqDRk8q2h1sVS25gzAQCAF2rRooVsNtsFW3p6uiSppKRE6enpioyMVEhIiAYMGKDCwkK3c+Tn56tPnz4KDg5WdHS0Ro8erYqKCo9jIZkAAMACTgs2T2zdulVHjx51bStXrpQk/eY3v5EkZWRk6P3339ebb76ptWvX6siRI+rfv7+rf2Vlpfr06aOysjJt2rRJr732mubPn6+JEyd6fO8McwAAYAGnbKqUzVR/T0RFRbl9fuaZZ/SrX/1KN998s06dOqV58+Zp0aJF6tGjhyQpOztbSUlJ2rx5s7p27aoPP/xQu3fv1qpVqxQTE6MOHTpo8uTJGjt2rCZNmiR/f/8qx0JlAgCAeqSoqMhtKy0t/cU+ZWVl+sc//qEHH3xQNptN27dvV3l5uXr27Olq06ZNGzVv3ly5ubmSpNzcXLVr104xMTGuNikpKSoqKtKuXbs8iplkAgAACzgN85skxcfHKywszLVlZWX94rWXLFmikydPavDgwZKkgoIC+fv7Kzw83K1dTEyMCgoKXG3+PZE4f/z8MU8wzAEAgAUqTQ5znO97+PBh2e121/6AgIBf7Dtv3jzdfvvtiouLq/b1zSCZAACgHrHb7W7JxC85dOiQVq1apXfeece1LzY2VmVlZTp58qRbdaKwsFCxsbGuNp988onbuc4/7XG+TVUxzAEAgAXOVybMbNWRnZ2t6Oho9enTx7WvU6dO8vPz0+rVq1378vLylJ+fL4fDIUlyOBzauXOnjh075mqzcuVK2e12JScnexQDlQkAACzgNGxyGiae5qhGX6fTqezsbKWlpalRo5/+pIeFhWnIkCEaOXKkIiIiZLfbNXz4cDkcDnXt2lWS1KtXLyUnJ+uBBx7Q1KlTVVBQoPHjxys9Pb1KQyv/jmQCAAAvtWrVKuXn5+vBBx+84Nj06dPl4+OjAQMGqLS0VCkpKXrxxRddx319fZWTk6OhQ4fK4XCocePGSktLU2ZmpsdxkEwAAGABqyZgeqJXr14yLvHq8sDAQM2aNUuzZs26ZP+EhAQtW7bM4+v+HMkEAAAWqJSPKk1MRay0MJbaRjIBAIAFDJNzJgwTfesaT3MAAABTqEwAAGCBupgzUV+QTAAAYIFKw0eVhok5ExefR+kVGOYAAACmUJkAAMACTtnkNPEd3SnvLU2QTAAAYIGGPGeCYQ4AAGAKlQkAACxgfgImwxwAADRo5+ZMmHjRF8McAACgoaIyAQCABZwm383B0xwAADRwzJkAAACmOOXTYNeZYM4EAAAwhcoEAAAWqDRsqjTxGnEzfesayQQAABaoNDkBs5JhDgAA0FBRmQAAwAJOw0dOE09zOHmaAwCAho1hDgAAgGqiMgEAgAWcMvdEhtO6UGodyQQAABYwv2iV9w4WeG/kAACgXqAyAQCABcy/m8N7v9+TTAAAYAGnbHLKzJwJVsAEAKBBa8iVCe+NHAAA1AtUJgAAsID5Rau89/s9yQQAABZwGjY5zawz4cVvDfXeNAgAANQLVCYAALCA0+QwhzcvWkUyAQCABcy/NdR7kwnvjRwAANQLVCYAALBApWyqNLHwlJm+dY1kAgAACzDMAQAAUE1UJgAAsEClzA1VVFoXSq0jmQAAwAINeZiDZAIAAAvwoi8AAIBqojIBAIAFDNnkNDFnwuDRUAAAGjaGOQAAgNf59ttvNXDgQEVGRiooKEjt2rXTtm3bXMcNw9DEiRPVtGlTBQUFqWfPntq7d6/bOY4fP67U1FTZ7XaFh4dryJAhKi4u9igOkgkAACxw/hXkZjZPnDhxQjfccIP8/Py0fPly7d69W88995yaNGniajN16lTNnDlTc+bM0ZYtW9S4cWOlpKSopKTE1SY1NVW7du3SypUrlZOTo3Xr1umRRx7xKBaGOQAAsEClybeGetr3v//7vxUfH6/s7GzXvsTERNe/DcPQ888/r/Hjx6tv376SpAULFigmJkZLlizRfffdpz179mjFihXaunWrOnfuLEl64YUXdMcdd+jZZ59VXFxclWKhMgEAQD1SVFTktpWWll603XvvvafOnTvrN7/5jaKjo9WxY0fNnTvXdfzAgQMqKChQz549XfvCwsLUpUsX5ebmSpJyc3MVHh7uSiQkqWfPnvLx8dGWLVuqHDPJBAAAFrBqmCM+Pl5hYWGuLSsr66LX+/rrrzV79mxdddVV+uCDDzR06FA9+uijeu211yRJBQUFkqSYmBi3fjExMa5jBQUFio6OdjveqFEjRUREuNpUBcMcAABYwCkfOU18Rz/f9/Dhw7Lb7a79AQEBF2/vdKpz586aMmWKJKljx4764osvNGfOHKWlpVU7juqgMgEAQD1it9vdtkslE02bNlVycrLbvqSkJOXn50uSYmNjJUmFhYVubQoLC13HYmNjdezYMbfjFRUVOn78uKtNVZBMAABggUrDZnrzxA033KC8vDy3fV999ZUSEhIknZuMGRsbq9WrV7uOFxUVacuWLXI4HJIkh8OhkydPavv27a42H330kZxOp7p06VLlWBjmAADAAtV5vPPn/T2RkZGh66+/XlOmTNG9996rTz75RC+//LJefvllSZLNZtOIESP01FNP6aqrrlJiYqImTJiguLg49evXT9K5Skbv3r318MMPa86cOSovL9ewYcN03333VflJDolkAgAASxgm3xpqeNj3uuuu07vvvqtx48YpMzNTiYmJev7555WamupqM2bMGJ05c0aPPPKITp48qRtvvFErVqxQYGCgq83ChQs1bNgw3XrrrfLx8dGAAQM0c+ZMj2IhmQAAwEvdeeeduvPOOy953GazKTMzU5mZmZdsExERoUWLFpmKg2QCAAALVMqmShMv6zLTt66RTAAAYAGn4fm8h5/391Y8zQEAAEyhMoEaN+j/JavwG/8L9t+V9p2GZX3r+mwY0viBLbXtY7uemHdA199+ynXs2Dd+emFcM32+MVSBjSt1229O6MG/HJEvP8GoY7+7fYduuvagmjc9pdIyX+3aH6OX3rpOhwvDJUmhjUv0+7s/Vedff6uYiGKdPB2oDTsS9OqSzjrz40//XURHFCtj4EZ1bH1EP5b66YNNV2nuO9ep0sl3Pm/hNDkB00zfusavYtS4mcvz5Kz8qfR38MtAjbuvlbrddcqt3btzo2S7SIWwslKaMKilmkRVaPp7e3X8WCNNezRBvn6GHhx3tKbDBy6rQ+sCLfk4WV8ejJKvj1MP9d+maSNXaPCEASop89MVYWcVGX5Ws9/8fzp0pIliIos1cuAGXRF2Vk/MOffOBB+bU888+oGOFwVp2DN3KyLsrP4yZK0qKn30yrvX1fEdoqqcsslpYt6Dmb51rd6lQd27d9eIESPqOgxYKDyyUhHRFa5ty6owNW1RqvaOYleb/V8E6e2XojTyb/kX9P90bajyvwrU2P85pF+1/VHX9TitQWOO6v35V6i8zHv/48N/hjHP99aKTVfr4JEm2v9NpJ559SbFRhbr6oTvJUkHjkToidk9lft5go58Z9dnX8bplXc7y3FNvnx9nJKkzr/+VglxJ/X0K92173CkPvkiXq8u6aR+t+xWI9/Kurw9oErqXTLxSwzDUEVFRV2HgWoqL7Ppo7ebKOW+H1xViJKzNj2TnqD0p79RRPSF/9/u3tZYLdqUqEnUT8c6dz+ts6d9dSgv8IL2QF0KCS6TJJ0+c/ElkM+3OVvi7xrC+PWvjunAN010oijY1eaTXc0UElyuFnEnajZgWKa2V8CsT+pVMjF48GCtXbtWM2bMkM1mk81m0/z582Wz2bR8+XJ16tRJAQEB2rBhgwYPHuxaweu8ESNGqHv37q7PTqdTWVlZSkxMVFBQkK655hq99dZbtXtTcLNpRZiKi3zV697jrn0vTbpSyZ3P6PreRRftc+K7RmoSVe62L/yKctcxoL6w2QwN++1m7dwbowNHIi7aJiykRA/cuUPvr2vt2hdhP6vjRUFu7U7863NE2I81FzAsdX7OhJnNW9Wr38QzZszQV199pbZt27oW2Ni1a5ck6fHHH9ezzz6rli1bqkmTJlU6X1ZWlv7xj39ozpw5uuqqq7Ru3ToNHDhQUVFRuvnmmy9oX1pa6vbe+KKii/9xQ/V98L8Ruu6WIkXGnqsy5H5g146NoXrxw7xf6AnUfyNSNyrxyhMa/t93XfR4cGCZsh79QIeOhGv+e51qOTqg5tSrZCIsLEz+/v4KDg52va3syy+/lCRlZmbqtttuq/K5SktLNWXKFK1atcr1QpOWLVtqw4YNeumlly6aTGRlZenJJ5+04E5wMYXf+Omz9aGa8MoB174dG0N19KC/+rdp59Z28sMt1LbLGU17e5+aRFUo77PGbsdPfu8nSW5DH0Bdeux3m+Rof1iPTr1T351ofMHxoIAyTR2xQj+W+GnCrJ6qrPzpW+jxomAlJX7n1r6J/VxF4vgp94oF6i+nTL6bw4snYNarZOJyOnfu7FH7ffv26ezZsxckIGVlZerYseNF+4wbN04jR450fS4qKlJ8fLznweKiPlwcqfArKtSl508Vn98OK9Ttv/vBrd0ferTRHyZ9q669zrVL7nxGi2fG6OT3jRR+xbnk4dN1oQoOrVTzq0tq7waAizL02O9ydWPHgxoxrY8Kvg+9oEVwYJmmZaxQeYWP/vI/vVRW4f6rd9f+aA3ss0PhoT/q5OlzyUPn5G9VfNZPh45WrRKLumeYfJrDIJmoeY0bu2f6Pj4+Mgz35cLKy38aVy8uPvekwNKlS3XllVe6tbvUu+EDAgIueQzmOJ3Sh69HqOdvjrutDXH+CY+fi76yXLHNz01ku/bm02p+dYmmDm+uIeOP6MR3fpr/37G6a/D38g/w4iXj8B9hROom9eyyX3/9n9v0Y4mfIuxnJUnFP/qrrLyRggPL9GzGcgUEVOjpV25T48AyNQ4897N98nSgnIaPtu26UoeOhOsvQ9bopbf+nyLCftSQftu05ONklVf41uHdwRO1/dbQ+qTeJRP+/v6qrPzlR6GioqL0xRdfuO3bsWOH/PzOlb+Tk5MVEBCg/Pz8iw5poHZ9ti5Ux771V8p9x3+58c/4+kqZC77WC4/HK+OuqxUY7FTP3xxX2mjWmEDd63fLHknSjDFL3fY/8+pNWrHpal2d8L2Sf3VuCGNR1htube4b+1sV/BAqp+GjcTN7KeOBjZo17j2VlJ1btCr7n8yrgHeod8lEixYttGXLFh08eFAhISFyOp0XbdejRw9NmzZNCxYskMPh0D/+8Q998cUXriGM0NBQjRo1ShkZGXI6nbrxxht16tQpbdy4UXa7XWlpabV5Ww1ep+6n9cGRHVVqe7F2Mc3K9dQ/vrY2KMAC3R966LLHd+TF/WIbSSo8HqrHZ/S2KizUgYa8Ama9i3zUqFHy9fVVcnKyoqKilJ9/4SJGkpSSkqIJEyZozJgxuu6663T69GkNGjTIrc3kyZM1YcIEZWVlKSkpSb1799bSpUuVmJhYG7cCAGhAzg9zmNm8lc34+cQDuBQVFSksLEwnvmope2i9y7sAS3R/6OG6DgGoMRXlJcr98AmdOnVKdru9Rq5x/m9F3w8flF/jC99DVFXlZ8r0z16v1misNaXeDXMAAOCNGvK7OUgmAACwQEN+moPaPQAAMIXKBAAAFmjIlQmSCQAALNCQkwmGOQAAgClUJgAAsEBDrkyQTAAAYAFD5h7v9OZFn0gmAACwQEOuTDBnAgAAmEJlAgAACzTkygTJBAAAFmjIyQTDHAAAwBQqEwAAWKAhVyZIJgAAsIBh2GSYSAjM9K1rDHMAAABTqEwAAGABp2ymFq0y07eukUwAAGCBhjxngmEOAABgCpUJAAAs0JAnYJJMAABggYY8zEEyAQCABRpyZYI5EwAAwBQqEwAAWMAwOczhzZUJkgkAACxgSDIMc/29FcMcAADAFCoTAABYwCmbbKyACQAAqounOQAAgFeZNGmSbDab29amTRvX8ZKSEqWnpysyMlIhISEaMGCACgsL3c6Rn5+vPn36KDg4WNHR0Ro9erQqKio8joXKBAAAFnAaNtlqedGqX//611q1apXrc6NGP/1Zz8jI0NKlS/Xmm28qLCxMw4YNU//+/bVx40ZJUmVlpfr06aPY2Fht2rRJR48e1aBBg+Tn56cpU6Z4FAfJBAAAFjAMk09zVKNvo0aNFBsbe8H+U6dOad68eVq0aJF69OghScrOzlZSUpI2b96srl276sMPP9Tu3bu1atUqxcTEqEOHDpo8ebLGjh2rSZMmyd/fv8pxMMwBAEA9UlRU5LaVlpZesu3evXsVFxenli1bKjU1Vfn5+ZKk7du3q7y8XD179nS1bdOmjZo3b67c3FxJUm5urtq1a6eYmBhXm5SUFBUVFWnXrl0exUwyAQCABc5PwDSzSVJ8fLzCwsJcW1ZW1kWv16VLF82fP18rVqzQ7NmzdeDAAXXr1k2nT59WQUGB/P39FR4e7tYnJiZGBQUFkqSCggK3ROL88fPHPMEwBwAAFrDqaY7Dhw/Lbre79gcEBFy0/e233+76d/v27dWlSxclJCTojTfeUFBQULXjqA4qEwAAWOD8W0PNbJJkt9vdtkslEz8XHh6uq6++Wvv27VNsbKzKysp08uRJtzaFhYWuORaxsbEXPN1x/vPF5mFcDskEAAD/AYqLi7V//341bdpUnTp1kp+fn1avXu06npeXp/z8fDkcDkmSw+HQzp07dezYMVeblStXym63Kzk52aNrM8wBAIAFavtpjlGjRumuu+5SQkKCjhw5oieeeEK+vr66//77FRYWpiFDhmjkyJGKiIiQ3W7X8OHD5XA41LVrV0lSr169lJycrAceeEBTp05VQUGBxo8fr/T09CpXQ84jmQAAwALnkgkzcyY8a//NN9/o/vvv1w8//KCoqCjdeOON2rx5s6KioiRJ06dPl4+PjwYMGKDS0lKlpKToxRdfdPX39fVVTk6Ohg4dKofDocaNGystLU2ZmZkex04yAQCAF1q8ePFljwcGBmrWrFmaNWvWJdskJCRo2bJlpmMhmQAAwAIN+d0cJBMAAFjA+Ndmpr+34mkOAABgCpUJAAAswDAHAAAwpwGPc5BMAABgBZOVCXlxZYI5EwAAwBQqEwAAWKC2V8CsT0gmAACwQEOegMkwBwAAMIXKBAAAVjBs5iZRenFlgmQCAAALNOQ5EwxzAAAAU6hMAABgBRatAgAAZjTkpzmqlEy89957VT7h3XffXe1gAACA96lSMtGvX78qncxms6mystJMPAAAeC8vHqowo0rJhNPprOk4AADwag15mMPU0xwlJSVWxQEAgHczLNi8lMfJRGVlpSZPnqwrr7xSISEh+vrrryVJEyZM0Lx58ywPEAAA1G8eJxNPP/205s+fr6lTp8rf39+1v23btnrllVcsDQ4AAO9hs2DzTh4nEwsWLNDLL7+s1NRU+fr6uvZfc801+vLLLy0NDgAAr8EwR9V9++23atWq1QX7nU6nysvLLQkKAAB4D4+TieTkZK1fv/6C/W+99ZY6duxoSVAAAHidBlyZ8HgFzIkTJyotLU3ffvutnE6n3nnnHeXl5WnBggXKycmpiRgBAKj/GvBbQz2uTPTt21fvv/++Vq1apcaNG2vixInas2eP3n//fd122201ESMAAKjHqvVujm7dumnlypVWxwIAgNdqyK8gr/aLvrZt26Y9e/ZIOjePolOnTpYFBQCA1+GtoVX3zTff6P7779fGjRsVHh4uSTp58qSuv/56LV68WM2aNbM6RgAAUI95PGfioYceUnl5ufbs2aPjx4/r+PHj2rNnj5xOpx566KGaiBEAgPrv/ARMM5uX8rgysXbtWm3atEmtW7d27WvdurVeeOEFdevWzdLgAADwFjbj3Gamv7fyOJmIj4+/6OJUlZWViouLsyQoAAC8TgOeM+HxMMe0adM0fPhwbdu2zbVv27Zteuyxx/Tss89aGhwAAKj/qlSZaNKkiWy2n8Zyzpw5oy5duqhRo3PdKyoq1KhRIz344IPq169fjQQKAEC91oAXrapSMvH888/XcBgAAHi5BjzMUaVkIi0trabjAAAAXqrai1ZJUklJicrKytz22e12UwEBAOCVGnBlwuMJmGfOnNGwYcMUHR2txo0bq0mTJm4bAAANUgN+a6jHycSYMWP00Ucfafbs2QoICNArr7yiJ598UnFxcVqwYEFNxAgAAOoxj4c53n//fS1YsEDdu3fX73//e3Xr1k2tWrVSQkKCFi5cqNTU1JqIEwCA+q0BP83hcWXi+PHjatmypaRz8yOOHz8uSbrxxhu1bt06a6MDAMBLnF8B08zmrTxOJlq2bKkDBw5Iktq0aaM33nhD0rmKxfkXfwEAgIbD42Ti97//vT7//HNJ0uOPP65Zs2YpMDBQGRkZGj16tOUBAgDgFRrwBEyP50xkZGS4/t2zZ099+eWX2r59u1q1aqX27dtbGhwAAKj/PK5M/FxCQoL69+9PIgEAaNBsMjlnwuT1n3nmGdlsNo0YMcK1r6SkROnp6YqMjFRISIgGDBigwsJCt375+fnq06ePgoODFR0drdGjR6uiosKja1epMjFz5swqn/DRRx/1KAAAAGDO1q1b9dJLL13wxT4jI0NLly7Vm2++qbCwMA0bNkz9+/fXxo0bJZ1743efPn0UGxurTZs26ejRoxo0aJD8/Pw0ZcqUKl+/SsnE9OnTq3Qym832H5lM3HN1OzWy+dV1GECNKP2db12HANSYyvJa/Pm26NHQoqIit90BAQEKCAi4ZLfi4mKlpqZq7ty5euqpp1z7T506pXnz5mnRokXq0aOHJCk7O1tJSUnavHmzunbtqg8//FC7d+/WqlWrFBMTow4dOmjy5MkaO3asJk2aJH9//yqFXqVhjgMHDlRp+/rrr6t0UQAA/uNYNAEzPj5eYWFhri0rK+uyl01PT1efPn3Us2dPt/3bt29XeXm52/42bdqoefPmys3NlSTl5uaqXbt2iomJcbVJSUlRUVGRdu3aVeVbN/VuDgAAYK3Dhw+7vefqclWJxYsX69NPP9XWrVsvOFZQUCB/f/8Llm2IiYlRQUGBq82/JxLnj58/VlUkEwAAWMGiF33Z7fYqvTTz8OHDeuyxx7Ry5UoFBgaauLB5pp/mAAAAtb8C5vbt23Xs2DFde+21atSokRo1aqS1a9dq5syZatSokWJiYlRWVqaTJ0+69SssLFRsbKwkKTY29oKnO85/Pt+mKkgmAADwQrfeeqt27typHTt2uLbOnTsrNTXV9W8/Pz+tXr3a1ScvL0/5+flyOBySJIfDoZ07d+rYsWOuNitXrpTdbldycnKVY2GYAwAAK1g0zFFVoaGhatu2rdu+xo0bKzIy0rV/yJAhGjlypCIiImS32zV8+HA5HA517dpVktSrVy8lJyfrgQce0NSpU1VQUKDx48crPT39snM1fq5alYn169dr4MCBcjgc+vbbbyVJf//737Vhw4bqnA4AAO9XD5fTnj59uu68804NGDBAN910k2JjY/XOO++4jvv6+ionJ0e+vr5yOBwaOHCgBg0apMzMTI+u43Fl4u2339YDDzyg1NRUffbZZyotLZV07nnWKVOmaNmyZZ6eEgAAWGDNmjVunwMDAzVr1izNmjXrkn0SEhJM/+32uDLx1FNPac6cOZo7d678/H5ayOmGG27Qp59+aioYAAC8VUN+BbnHlYm8vDzddNNNF+wPCwu7YMYoAAANhkUrYHojjysTsbGx2rdv3wX7N2zYoJYtW1oSFAAAXqcezpmoLR4nEw8//LAee+wxbdmyRTabTUeOHNHChQs1atQoDR06tCZiBAAA9ZjHwxyPP/64nE6nbr31Vp09e1Y33XSTAgICNGrUKA0fPrwmYgQAoN4zO++hQc2ZsNls+utf/6rRo0dr3759Ki4uVnJyskJCQmoiPgAAvEMtrzNRn1R70Sp/f3+PVscCAAD/mTxOJm655RbZbJeecfrRRx+ZCggAAK9k9vHOhlSZ6NChg9vn8vJy7dixQ1988YXS0tKsigsAAO/CMEfVTZ8+/aL7J02apOLiYtMBAQAA72LZW0MHDhyoV1991arTAQDgXRrwOhOWvTU0NzdXgYGBVp0OAACvwqOhHujfv7/bZ8MwdPToUW3btk0TJkywLDAAAOAdPE4mwsLC3D77+PiodevWyszMVK9evSwLDAAAeAePkonKykr9/ve/V7t27dSkSZOaigkAAO/TgJ/m8GgCpq+vr3r16sXbQQEA+JmG/Apyj5/maNu2rb7++uuaiAUAAHghj5OJp556SqNGjVJOTo6OHj2qoqIitw0AgAarAT4WKnkwZyIzM1N//vOfdccdd0iS7r77brdltQ3DkM1mU2VlpfVRAgBQ3zXgORNVTiaefPJJ/fGPf9THH39ck/EAAAAvU+VkwjDOpUw333xzjQUDAIC3YtGqKrrc20IBAGjQGOaomquvvvoXE4rjx4+bCggAAHgXj5KJJ5988oIVMAEAAMMcVXbfffcpOjq6pmIBAMB7NeBhjiqvM8F8CQAAcDEeP80BAAAuogFXJqqcTDidzpqMAwAAr8acCQAAYE4Drkx4/G4OAACAf0dlAgAAKzTgygTJBAAAFmjIcyYY5gAAAKZQmQAAwAoMcwAAADMY5gAAAKgmKhMAAFiBYQ4AAGBKA04mGOYAAACmUJkAAMACtn9tZvp7K5IJAACs0ICHOUgmAACwAI+GAgAAVBPJBAAAVjAs2Dwwe/ZstW/fXna7XXa7XQ6HQ8uXL3cdLykpUXp6uiIjIxUSEqIBAwaosLDQ7Rz5+fnq06ePgoODFR0drdGjR6uiosLjWyeZAADAKrWUSEhSs2bN9Mwzz2j79u3atm2bevToob59+2rXrl2SpIyMDL3//vt68803tXbtWh05ckT9+/d39a+srFSfPn1UVlamTZs26bXXXtP8+fM1ceJEj2NhzgQAAF7orrvucvv89NNPa/bs2dq8ebOaNWumefPmadGiRerRo4ckKTs7W0lJSdq8ebO6du2qDz/8ULt379aqVasUExOjDh06aPLkyRo7dqwmTZokf3//KsdCZQIAAAucn4BpZpOkoqIit620tPQXr11ZWanFixfrzJkzcjgc2r59u8rLy9WzZ09XmzZt2qh58+bKzc2VJOXm5qpdu3aKiYlxtUlJSVFRUZGrulFVJBMAAFjBojkT8fHxCgsLc21ZWVmXvOTOnTsVEhKigIAA/fGPf9S7776r5ORkFRQUyN/fX+Hh4W7tY2JiVFBQIEkqKChwSyTOHz9/zBMMcwAAUI8cPnxYdrvd9TkgIOCSbVu3bq0dO3bo1KlTeuutt5SWlqa1a9fWRphuSCYAALCAVetMnH86oyr8/f3VqlUrSVKnTp20detWzZgxQ7/97W9VVlamkydPulUnCgsLFRsbK0mKjY3VJ5984na+8097nG9TVQxzAABghVp+NPRinE6nSktL1alTJ/n5+Wn16tWuY3l5ecrPz5fD4ZAkORwO7dy5U8eOHXO1Wblypex2u5KTkz26LpUJAAC80Lhx43T77berefPmOn36tBYtWqQ1a9bogw8+UFhYmIYMGaKRI0cqIiJCdrtdw4cPl8PhUNeuXSVJvXr1UnJysh544AFNnTpVBQUFGj9+vNLT0y87tHIxJBMAAFigtpfTPnbsmAYNGqSjR48qLCxM7du31wcffKDbbrtNkjR9+nT5+PhowIABKi0tVUpKil588UVXf19fX+Xk5Gjo0KFyOBxq3Lix0tLSlJmZ6XHsJBMAAFihll/0NW/evMseDwwM1KxZszRr1qxLtklISNCyZcs8u/BFkEwAAGCFBvzWUCZgAgAAU6hMAABggYb8CnKSCQAArMAwBwAAQPVQmQAAwAI2w5DNqH55wUzfukYyAQCAFRjmAAAAqB4qEwAAWICnOQAAgDkMcwAAAFQPlQkAACzAMAcAADCnAQ9zkEwAAGCBhlyZYM4EAAAwhcoEAABWYJgDAACY5c1DFWYwzAEAAEyhMgEAgBUM49xmpr+XIpkAAMACPM0BAABQTVQmAACwAk9zAAAAM2zOc5uZ/t6KYQ4AAGAKlQnUicjYcg356xFdd8tpBQQ5deRggJ7LiNfe/wuWJP15er56/faEW59tH4fqr6kt6yJc4JIG9fhMN7c7oISokyqt8NXOg7F6cWkX5X8X7taubUKB/nD7Vv26+TE5nTZ9dSRSGS/3UWnFuV/D9qASjbxno25MPiSnYdOa/0vU9H/eoB/L/OrgrlAtDHPUDcMw9Ic//EFvvfWWTpw4oc8++0wdOnS4ZPuDBw8qMTHxF9uhfgsJq9Df/rlX/7cpROMHttTJH3x1ZcsyFZ/ydWu39aNQPZcR7/pcXmar7VCBX9Sx5RG9vfHX2nM4Sr4+hv54xyd6/pGl+t20e1Xyr0SgbUKBpj+0XAs+6qC/vXuDKp0+uiruBzmNn36mJ6V+pMjQs3r05T5q5OPU+N+u0eP/tU5PLLq1rm4NHmrIT3PUaTKxYsUKzZ8/X2vWrFHLli11xRVX1GU4qCX3ph/T90f89VxGc9e+wsMBF7QrL7PpxHd8K0P9lvFKH7fPTy3uruVPLlCbZt9px9dxkqTH7s7Vmxva6u8fd3S1+/fKRUL0CTnaHNbvn++vL7+JkiT9bckNem7Icr2Q01XfFzWu+RuBeawzUTf279+vpk2b6vrrr6/LMFDLuvYq0vY1ofrrSwfV3nFG3xc0Us78K7R8UaRbu/aOYr3+f7t0+pSvPt8QovlTY3X6BCNzqN9CAsskSUVnAyVJTUJ+VNuEY/rg06v08rAlujKySIeOhWvO8uv0fwebSpLaJRSq6Ky/K5GQpK17m8lp2PTr5se09ovE2r8RwAN1NgFz8ODBGj58uPLz82Wz2dSiRQutWLFCN954o8LDwxUZGak777xT+/fvv+Q5Tpw4odTUVEVFRSkoKEhXXXWVsrOzXccPHz6se++9V+Hh4YqIiFDfvn118ODBS56vtLRURUVFbhus17R5me4c9IOOHAjQX36XqJzXrtDQyd+q52+Ou9psWxOqaY8119h7W2re003VzlGsp//xtXx8vDdzx38+m83QiL6b9PmBWH1dECFJios493vkoV7b9M8tbZQx9w7lfXuFXvhjjppdcUqSFBl6VieKg9zOVen0UdGPAYoIPVu7N4FqOz/MYWbzVnWWTMyYMUOZmZlq1qyZjh49qq1bt+rMmTMaOXKktm3bptWrV8vHx0f33HOPnM6LPy8zYcIE7d69W8uXL9eePXs0e/Zs11BJeXm5UlJSFBoaqvXr12vjxo0KCQlR7969VVZWdtHzZWVlKSwszLXFx8dftB3MsflI+74IUvYzTbX/i2AtXxip5Ysi1eeBH1xt1v6ziTZ/GKaDXwYpd0WYJg5KVOuOP6r99cV1GDlweaPu2aCWscc14R8/zXPw+ddfiCWbk7R0axt9deQKzXjveuUfC9dd131ZV6GiJhgWbF6qzmrGYWFhCg0Nla+vr2JjYyVJAwYMcGvz6quvKioqSrt371bbtm0vOEd+fr46duyozp07S5JatGjhOvb666/L6XTqlVdekc12bpJTdna2wsPDtWbNGvXq1euC840bN04jR450fS4qKiKhqAHHjzXSoa8C3fYd3hugG+84eck+BfkBOvmDr+JalGnHhhoOEKiGP9+zQTckH9LQF+/Wd6dCXPu/P33uCaUDhU3c2h88Fq6YJueS4x9OB6tJyI9ux319nLIHler4v/oD9Vm9Wmdi7969uv/++9WyZUvZ7XZXcpCfn3/R9kOHDtXixYvVoUMHjRkzRps2bXId+/zzz7Vv3z6FhoYqJCREISEhioiIUElJySWHTgICAmS32902WG/31saK/1Wp274rW5bq2Lf+l+xzRdMy2ZtU6vgx5kygvjH053s26Oa2BzRszl06etz998bR46H67lSwEqJOue1vHnVKBSfOJR07D8XIHlym1ld+5zreqdW38rEZ2pUfXfO3AEs05GGOevWb+a677lJCQoLmzp2ruLg4OZ1OtW3b9pLDErfffrsOHTqkZcuWaeXKlbr11luVnp6uZ599VsXFxerUqZMWLlx4Qb+oqKiLnA215Z2XozT9vb26b3ih1r0frtYdz+qOgcf1/OhmkqTA4EoN/HOhNiwN04ljfmraolQPjT+qIwf8tX1NaB1HD7gb1X+DenXcp7HZKTpb6uea43DmR/9/rSFh08I11+ihXtu192ik9n4bqTs6f6WE6JP6y4LbJEmHjjVR7pfxGvebdZr6djc18nXqz/ds1KodrXiSw5vwNEfd++GHH5SXl6e5c+eqW7dukqQNG365nh0VFaW0tDSlpaWpW7duGj16tJ599llde+21ev311xUdHU2FoZ756vNgZQ5J1O/HHVVqRqEKDvtrzsQ4ffzuuTKw02lTYtKPuu03J9TYXqkfChvp07Whem1qrMrL6lUxDdCA63dLkl780/tu+ycv7q5l21pLkl5f317+jSr12N2bZA8u1b4jkXr0pT769ocwV/tJC3voz/ds1Mw/5MgwbFqzM1F/W3JD7d0IYEK9SSaaNGmiyMhIvfzyy2ratKny8/P1+OOPX7bPxIkT1alTJ/36179WaWmpcnJylJSUJElKTU3VtGnT1LdvX9dEz0OHDumdd97RmDFj1KxZs9q4LVzCllV2bVl18SSvrMRHf/3dr2o5IqB6HKP+UKV2f/+4o9s6Ez9X9GMgC1R5uYa8aFW9+Zrn4+OjxYsXa/v27Wrbtq0yMjI0bdq0y/bx9/fXuHHj1L59e910003y9fXV4sWLJUnBwcFat26dmjdvrv79+yspKUlDhgxRSUkJlQoAgPUa8NMcNsPw4kGaGlZUVKSwsDB1V181srESI/4zFf2ua12HANSYyvISbX9jvE6dOlVjXyTP/61w9M5UI7/AX+5wCRXlJcpdMbFGY60p9WaYAwAAb9aQhzlIJgAAsILTOLeZ6e+lSCYAALBCA34Feb2ZgAkAALwTlQkAACxgk8k5E5ZFUvtIJgAAsEIDXgGTYQ4AAGAKyQQAABao7Rd9ZWVl6brrrlNoaKiio6PVr18/5eXlubUpKSlRenq6IiMjFRISogEDBqiwsNCtTX5+vvr06aPg4GBFR0dr9OjRqqio8CgWkgkAAKxQyytgrl27Vunp6dq8ebNWrlyp8vJy9erVS2fOnHG1ycjI0Pvvv68333xTa9eu1ZEjR9S/f3/X8crKSvXp00dlZWXatGmTXnvtNc2fP18TJ070KBbmTAAA4IVWrFjh9nn+/PmKjo7W9u3bddNNN+nUqVOaN2+eFi1apB49ekiSsrOzlZSUpM2bN6tr16768MMPtXv3bq1atUoxMTHq0KGDJk+erLFjx2rSpEny9/evUixUJgAAsIDNMExv0rnluf99Ky0trdL1T506JUmKiIiQJG3fvl3l5eXq2bOnq02bNm3UvHlz5ebmSpJyc3PVrl07xcTEuNqkpKSoqKhIu3btqvK9k0wAAGAFpwWbpPj4eIWFhbm2rKysX76006kRI0bohhtuUNu2bSVJBQUF8vf3V3h4uFvbmJgYFRQUuNr8eyJx/vj5Y1XFMAcAAPXI4cOH3V70FRAQ8It90tPT9cUXX2jDhg01GdolkUwAAGCBfx+qqG5/SbLb7R69NXTYsGHKycnRunXr1KxZM9f+2NhYlZWV6eTJk27VicLCQsXGxrrafPLJJ27nO/+0x/k2VcEwBwAAVqjlpzkMw9CwYcP07rvv6qOPPlJiYqLb8U6dOsnPz0+rV6927cvLy1N+fr4cDockyeFwaOfOnTp27JirzcqVK2W325WcnFzlWKhMAABghVpeATM9PV2LFi3SP//5T4WGhrrmOISFhSkoKEhhYWEaMmSIRo4cqYiICNntdg0fPlwOh0Ndu3aVJPXq1UvJycl64IEHNHXqVBUUFGj8+PFKT0+v0vDKeSQTAAB4odmzZ0uSunfv7rY/OztbgwcPliRNnz5dPj4+GjBggEpLS5WSkqIXX3zR1dbX11c5OTkaOnSoHA6HGjdurLS0NGVmZnoUC8kEAAAWqM4qlj/v7wmjCpWMwMBAzZo1S7Nmzbpkm4SEBC1btsyzi/8MyQQAAFbgRV8AAADVQ2UCAAAL2JznNjP9vRXJBAAAVmCYAwAAoHqoTAAAYIVqLDx1QX8vRTIBAIAFrFpO2xsxzAEAAEyhMgEAgBUa8ARMkgkAAKxgSDLzeKf35hIkEwAAWIE5EwAAANVEZQIAACsYMjlnwrJIah3JBAAAVmjAEzAZ5gAAAKZQmQAAwApOSTaT/b0UyQQAABbgaQ4AAIBqojIBAIAVGvAETJIJAACs0ICTCYY5AACAKVQmAACwQgOuTJBMAABgBR4NBQAAZvBoKAAAQDVRmQAAwArMmQAAAKY4DclmIiFwem8ywTAHAAAwhcoEAABWYJgDAACYYzKZkPcmEwxzAAAAU6hMAABgBYY5AACAKU5DpoYqeJoDAAA0VFQmAACwguE8t5np76VIJgAAsAJzJgAAgCnMmQAAAKgeKhMAAFiBYQ4AAGCKIZPJhGWR1DqGOQAAgClUJgAAsALDHAAAwBSnU5KJtSKc3rvOBMMcAADAFJIJAACscH6Yw8zmoXXr1umuu+5SXFycbDablixZ8rOQDE2cOFFNmzZVUFCQevbsqb1797q1OX78uFJTU2W32xUeHq4hQ4aouLjYozhIJgAAsEIdJBNnzpzRNddco1mzZl30+NSpUzVz5kzNmTNHW7ZsUePGjZWSkqKSkhJXm9TUVO3atUsrV65UTk6O1q1bp0ceecSjOJgzAQCAl7r99tt1++23X/SYYRh6/vnnNX78ePXt21eStGDBAsXExGjJkiW67777tGfPHq1YsUJbt25V586dJUkvvPCC7rjjDj377LOKi4urUhxUJgAAsILTML9JKioqcttKS0urFc6BAwdUUFCgnj17uvaFhYWpS5cuys3NlSTl5uYqPDzclUhIUs+ePeXj46MtW7ZU+VokEwAAWMAwnKY3SYqPj1dYWJhry8rKqlY8BQUFkqSYmBi3/TExMa5jBQUFio6OdjveqFEjRUREuNpUBcMcAABYwTDMvazrX3MmDh8+LLvd7todEBBgNrIaR2UCAIB6xG63u23VTSZiY2MlSYWFhW77CwsLXcdiY2N17Ngxt+MVFRU6fvy4q01VkEwAAGCFOnia43ISExMVGxur1atXu/YVFRVpy5YtcjgckiSHw6GTJ09q+/btrjYfffSRnE6nunTpUuVrMcwBAIAVnE7JZmIVS8PzvsXFxdq3b5/r84EDB7Rjxw5FRESoefPmGjFihJ566ildddVVSkxM1IQJExQXF6d+/fpJkpKSktS7d289/PDDmjNnjsrLyzVs2DDdd999VX6SQyKZAADAa23btk233HKL6/PIkSMlSWlpaZo/f77GjBmjM2fO6JFHHtHJkyd14403asWKFQoMDHT1WbhwoYYNG6Zbb71VPj4+GjBggGbOnOlRHCQTAABYwTBk6j3i1Rjm6N69u4zL9LPZbMrMzFRmZuYl20RERGjRokUeX/vfkUwAAGABw+mUYWKYw6jGMEd9wQRMAABgCpUJAACsUAfDHPUFyQQAAFZwGpKtYSYTDHMAAABTqEwAAGAFw5BkZp0J761MkEwAAGABw2nIMDHMcblHPOs7kgkAAKxgOGWuMsGjoQAAoIGiMgEAgAUY5gAAAOY04GEOkonLOJ8lVqjc1DokQH1WWV5S1yEANeb8z3dtfOs3+7eiQuXWBVPLbIY311Vq2DfffKP4+Pi6DgMAYNLhw4fVrFmzGjl3SUmJEhMTVVBQYPpcsbGxOnDggNtbPb0BycRlOJ1OHTlyRKGhobLZbHUdToNQVFSk+Ph4HT58WHa7va7DASzHz3jtMgxDp0+fVlxcnHx8au6Zg5KSEpWVlZk+j7+/v9clEhLDHJfl4+NTY5ksLs9ut/OLFv/R+BmvPWFhYTV+jcDAQK9MAqzCo6EAAMAUkgkAAGAKyQTqlYCAAD3xxBMKCAio61CAGsHPOP4TMQETAACYQmUCAACYQjIBAABMIZkAAACmkEwAgIcMw9AjjzyiiIgI2Ww27dix47LtDx48WKV2gLcimUCN6t69u0aMGFHXYQCWWrFihebPn6+cnBwdPXpUbdu2reuQgDrFCpioU4ZhqLKyUo0a8aMI77F//341bdpU119/fV2HAtQLVCZQYwYPHqy1a9dqxowZstlsstlsmj9/vmw2m5YvX65OnTopICBAGzZs0ODBg9WvXz+3/iNGjFD37t1dn51Op7KyspSYmKigoCBdc801euutt2r3ptDgDR48WMOHD1d+fr5sNptatGihFStW6MYbb1R4eLgiIyN15513av/+/Zc8x4kTJ5SamqqoqCgFBQXpqquuUnZ2tuv44cOHde+99yo8PFwRERHq27evDh48WAt3B1QPyQRqzIwZM+RwOPTwww/r6NGjOnr0qOstrI8//rieeeYZ7dmzR+3bt6/S+bKysrRgwQLNmTNHu3btUkZGhgYOHKi1a9fW5G0AbmbMmKHMzEw1a9ZMR48e1datW3XmzBmNHDlS27Zt0+rVq+Xj46N77rlHTqfzoueYMGGCdu/ereXLl2vPnj2aPXu2rrjiCklSeXm5UlJSFBoaqvXr12vjxo0KCQlR7969LXmRFFATqC2jxoSFhcnf31/BwcGKjY2VJH355ZeSpMzMTN12221VPldpaammTJmiVatWyeFwSJJatmypDRs26KWXXtLNN99s/Q0AFxEWFqbQ0FD5+vq6fq4HDBjg1ubVV19VVFSUdu/efdH5FPn5+erYsaM6d+4sSWrRooXr2Ouvvy6n06lXXnnF9bbi7OxshYeHa82aNerVq1cN3RlQfSQTqBPnf4lW1b59+3T27NkLEpCysjJ17NjRytAAj+3du1cTJ07Uli1b9P3337sqEvn5+RdNJoYOHaoBAwbo008/Va9evdSvXz/X/IvPP/9c+/btU2hoqFufkpKSyw6dAHWJZAJ1onHjxm6ffXx89POV3cvLy13/Li4uliQtXbpUV155pVs73nGAunbXXXcpISFBc+fOVVxcnJxOp9q2bXvJYYnbb79dhw4d0rJly7Ry5UrdeuutSk9P17PPPqvi4mJ16tRJCxcuvKBfVFRUTd8KUC0kE6hR/v7+qqys/MV2UVFR+uKLL9z27dixQ35+fpKk5ORkBQQEKD8/nyEN1Cs//PCD8vLyNHfuXHXr1k2StGHDhl/sFxUVpbS0NKWlpalbt24aPXq0nn32WV177bV6/fXXFR0dLbvdXtPhA5ZgAiZqVIsWLbRlyxYdPHjQrfz7cz169NC2bdu0YMEC7d27V0888YRbchEaGqpRo0YpIyNDr732mvbv369PP/1UL7zwgl577bXauh3gAk2aNFFkZKRefvll7du3Tx999JFGjhx52T4TJ07UP//5T+3bt0+7du1STk6OkpKSJEmpqam64oor1LdvX61fv14HDhzQmjVr9Oijj+qbb76pjVsCPEYygRo1atQo+fr6Kjk5WVFRUcrPz79ou5SUFE2YMEFjxozRddddp9OnT2vQoEFubSZPnqwJEyYoKytLSUlJ6t27t5YuXarExMTauBXgonx8fLR48WJt375dbdu2VUZGhqZNm3bZPv7+/ho3bpzat2+vm266Sb6+vlq8eLEkKTg4WOvWrVPz5s3Vv39/JSUlaciQISopKaFSgXqLV5ADAABTqEwAAABTSCYAAIApJBMAAMAUkgkAAGAKyQQAADCFZAIAAJhCMgEAAEwhmQAAAKaQTAD13ODBg9WvXz/X5+7du2vEiBG1HseaNWtks9l08uTJS7ax2WxasmRJlc85adIkdejQwVRcBw8elM1m044dO0ydB0D1kUwA1TB48GDZbDbZbDb5+/urVatWyszMVEVFRY1f+5133tHkyZOr1LYqCQAAmMVbQ4Fq6t27t7Kzs1VaWqply5YpPT1dfn5+Gjdu3AVty8rK5O/vb8l1IyIiLDkPAFiFygRQTQEBAYqNjVVCQoKGDh2qnj176r333pP009DE008/rbi4OLVu3VqSdPjwYd17770KDw9XRESE+vbtq4MHD7rOWVlZqZEjRyo8PFyRkZEaM2aMfv76nJ8Pc5SWlmrs2LGKj49XQECAWrVqpXnz5ungwYO65ZZbJJ17s6XNZtPgwYMlSU6nU1lZWUpMTFRQUJCuueYavfXWW27XWbZsma6++moFBQXplltucYuzqsaOHaurr75awcHBatmypSZMmKDy8vIL2r300kuKj49XcHCw7r33Xp06dcrt+CuvvKKkpCQFBgaqTZs2evHFFz2OBUDNIZkALBIUFKSysjLX59WrVysvL08rV65UTk6OysvLlZKSotDQUK1fv14bN25USEiIevfu7er33HPPaf78+Xr11Ve1YcMGHT9+XO++++5lrzto0CD97//+r2bOnKk9e/bopZdeUkhIiOLj4/X2229LkvLy8nT06FHNmDFDkpSVlaUFCxZozpw52rVrlzIyMjRw4ECtXbtW0rmkp3///rrrrru0Y8cOPfTQQ3r88cc9/t8kNDRU8+fP1+7duzVjxgzNnTtX06dPd2uzb98+vfHGG3r//fe1YsUKffbZZ/rTn/7kOr5w4UJNnDhRTz/9tPbs2aMpU6ZowoQJvHoeqE8MAB5LS0sz+vbtaxiGYTidTmPlypVGQECAMWrUKNfxmJgYo7S01NXn73//u9G6dWvD6XS69pWWlhpBQUHGBx98YBiGYTRt2tSYOnWq63h5ebnRrFkz17UMwzBuvvlm47HHHjMMwzDy8vIMScbKlSsvGufHH39sSDJOnDjh2ldSUmIEBwcbmzZtcms7ZMgQ4/777zcMwzDGjRtnJCcnux0fO3bsBef6OUnGu+++e8nj06ZNMzp16uT6/MQTTxi+vr7GN99849q3fPlyw8fHxzh69KhhGIbxq1/9yli0aJHbeSZPnmw4HA7DMAzjwIEDhiTjs88+u+R1AdQs5kwA1ZSTk6OQkBCVl5fL6XTqd7/7nSZNmuQ63q5dO7d5Ep9//rn27dun0NBQt/OUlJRo//79OnXqlI4ePaouXbq4jjVq1EidO3e+YKjjvB07dsjX11c333xzlePet2+fzp49q9tuu81tf1lZmTp27ChJ2rNnj1sckuRwOKp8jfNef/11zZw5U/v371dxcbEqKipkt9vd2jRv3lxXXnml23WcTqfy8vIUGhqq/fv3a8iQIXr44YddbSoqKhQWFuZxPABqBskEUE233HKLZs+eLX9/f8XFxalRI/f/nBo3buz2ubi4WJ06ddLChQsvOFdUVFS1YggKCvK4T3FxsSRp6dKlbn/EpXPzQKySm5ur1NRUPfnkk0pJSVFYWJgWL16s5557zuNY586de0Fy4+vra1msAMwhmQCqqXHjxmrVqlWV21977bV6/fXXFR0dfcG38/OaNm2qLVu26KabbpJ07hv49u3bde211160fbt27eR0OrV27Vr17NnzguPnKyOVlZWufcnJyQoICFB+fv4lKxpJSUmuyaTnbd68+Zdv8t9s2rRJCQkJ+utf/+rad+jQoQva5efn68iRI4qLi3Ndx8fHR61bt1ZMTIzi4uL09ddfKzU11aPrA6g9TMAEaklqaqquuOIK9e3bV+vXr9eBAwe0Zs0aPfroo/rmm28kSY899pieeeYZLVmyRF9++aX+9Kc/XXaNiBYtWigtLU0PPviglixZ4jrnG2+8IUlKSEiQzWZTTk6OvvvuOxUXFys0NFSjRo1SRkaGXnvtNe3fv1+ffvqpXnjhBdekxj/+8Y/au3evRo8erby8PC1atEjz58/36H6vuuoq5efna/Hixdq/f79mzpx50cmkgYGBSktL0+eff67169fr0Ucf1b333qvY2FhJ0pNPPqmsrCzNnDlTX331lXbu3Kns7Gz97W9/8ygeADWHZAKoJcHBwVq3bp2aN2+u/v37KykpSUOGDFFJSYmrUvHnP/9ZDzzwgNLS0uRwOBQaGqp77rnnsuedPXu2/uu//kt/+tOf1KZNGz388MM6c+aMJOnKK6/Uk08+qccff1wxMTEaNmyYJGny5MmaMGGCsrKylJSUpN69e2vp0qVKTEyUdG4ew9tvv60lS5bommuu0Zw5czRlyhSP7vfuu+9WRkaGhg0bpg4dOmjTpk2aMGHCBe1atWql/v3764477lCvXr3Uvn17t0c/H3roIb3yyivKzs5Wu3btdPPNN2v+/PmuWAHUPZtxqZldAAAAVUBlAgAAmEIyAQAATCGZAAAAppBMAAAAU0gmAACAKSQTAADAFJIJAABgCskEAAAwhWQCAACYQjIBAABMIZkAAACm/H/z7wVnvt5nBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1491/1491 [00:10<00:00, 147.59it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:07<00:00, 110.73it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pheme_results_4 = get_results_multi(\"pheme\", 0.0, 100, pheme, [[twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]], model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((77.82, 74.22), (78.91, 76.14)),\n",
       " ('twitter15', (51.11, 44.57), (50.84, 45.41)),\n",
       " ('twitter16', (57.04, 50.55), (58.51, 53.16))]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_results_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/trial, best loss: 0.6071428571428572]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4821428571428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5138888888888888]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/trial, best loss: 0.5694444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.6111111111111112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.5972222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.6891891891891893]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.3918918918918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5302013422818792]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.43624161073825507]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.5302013422818792]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.5771812080536913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.5302013422818792]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/trial, best loss: 0.5161290322580645]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/trial, best loss: 0.4838709677419355]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/trial, best loss: 0.47096774193548385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.5225806451612903]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.37209302325581395]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.4418604651162791]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.32558139534883723]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.4651162790697675]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.17647058823529416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.125]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.4545454545454546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.4545454545454546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.4545454545454546]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.30000000000000004]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.5384615384615384]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5384615384615384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.3076923076923077]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:09<00:00, 137.06it/s]\n",
      "100%|██████████| 2308/2308 [00:12<00:00, 184.01it/s]\n",
      " 50%|█████     | 1/2 [02:35<02:35, 155.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.4655172413793104]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.22413793103448276]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.12068965517241381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.12068965517241381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.6027397260273972]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.34246575342465757]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.3972602739726028]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.36986301369863017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.273972602739726]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.4657534246575342]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.23287671232876717]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/trial, best loss: 0.273972602739726]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.3972602739726028]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.2191780821917808]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.2465753424657534]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.34931506849315064]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.273972602739726]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.74s/trial, best loss=?]\n",
      "Error training Adaboost in category News, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.1333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.39610389610389607]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.33766233766233766]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.3246753246753247]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.38636363636363635]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/trial, best loss: 0.4545454545454546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2727272727272727]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.7647058823529411]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.47058823529411764]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.625]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.8888888888888888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.4444444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.0714285714285714]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:03<00:00, 139.19it/s]\n",
      "100%|██████████| 6425/6425 [00:53<00:00, 119.28it/s]\n",
      "100%|██████████| 2/2 [06:08<00:00, 184.31s/it]\n"
     ]
    }
   ],
   "source": [
    "test_results = run_tests_multi(tests2, 0.2, 50, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_models(tests, confidence_threshold, size_threshold, model_list):\n",
    "    trained_models = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        trained_models.append((train[2], train_models(train[1], confidence_threshold, size_threshold, train[0], model_list)))\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.676056338028169]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.46478873239436624]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.5915492957746479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5604395604395604]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.48351648351648346]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/trial, best loss: 0.5164835164835164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/trial, best loss: 0.5164835164835164]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.6263736263736264]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/trial, best loss: 0.5274725274725275]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/trial, best loss: 0.5824175824175823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/trial, best loss: 0.4619565217391305]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.5869565217391304]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.5434782608695652]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/trial, best loss: 0.482051282051282]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.19s/trial, best loss=?]\n",
      "Error training Adaboost in category Sensitive Subjects, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.4717948717948718]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/trial, best loss: 0.3928571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5357142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.4821428571428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (242) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (242) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.09999999999999998]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5333333333333333]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.38888888888888884]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.38888888888888884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:41<05:22, 161.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.32499999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.35]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.44999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.32307692307692304]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.36923076923076925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.339622641509434]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.80s/trial, best loss=?]\n",
      "Error training Adaboost in category Law & Government, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.25225225225225223]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/trial, best loss: 0.25225225225225223]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/trial, best loss: 0.3063063063063063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.3063063063063063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/trial, best loss: 0.2702702702702703]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (151) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (151) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15384615384615385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.3257575757575758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/trial, best loss: 0.18939393939393945]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.29729729729729726]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.29729729729729726]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.32432432432432434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.18918918918918914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.2702702702702703]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.5333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5555555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:07<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.28125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.21875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.17948717948717952]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.10256410256410253]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.40s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.1282051282051282]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.45945945945945943]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.22972972972972971]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.09459459459459463]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.31081081081081086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.1216216216216216]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.3492063492063492]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.2063492063492064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.3492063492063492]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.42105263157894735]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5789473684210527]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.368421052631579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.368421052631579]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:56<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Shopping, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 10\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:57<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Shopping, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [06:59<02:32, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Shopping, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:12<00:00, 144.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_1 = train_many_models(tests, 0.2, 50, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.7575757575757576]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.5757575757575757]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5454545454545454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4516129032258065]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.6129032258064516]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.4193548387096774]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/trial, best loss: 0.4516129032258065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4193548387096774]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.6111111111111112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6415094339622642]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.49056603773584906]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3584905660377359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.679245283018868]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.07692307692307687]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.07692307692307687]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3076923076923077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.5344827586206897]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5258620689655172]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.5258620689655172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/trial, best loss: 0.5258620689655172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.5172413793103448]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4444444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3846153846153846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:07<04:14, 127.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.7272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (162) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (162) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.42500000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.21250000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.23750000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.2222222222222222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:58<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.5555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2777777777777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.038461538461538436]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.11538461538461542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "\n",
      " 67%|██████▋   | 2/3 [04:55<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.5]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 13\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:13<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:19<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [05:23<01:57, 117.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:26<00:00, 108.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_2 = train_many_models(tests, 0.5, 20, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.6901408450704225]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.295774647887324]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.6338028169014085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5774647887323944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.5824175824175823]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.4725274725274725]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.5384615384615384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5494505494505495]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.6263736263736264]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.6153846153846154]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.6153846153846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.45108695652173914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5434782608695652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5597826086956521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.4836956521739131]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.3897435897435897]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4871794871794872]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/trial, best loss: 0.5384615384615384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5487179487179488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.5487179487179488]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5178571428571428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:04<02:08, 64.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.27692307692307694]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/trial, best loss: 0.2153846153846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2615384615384615]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.37735849056603776]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.30188679245283023]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.339622641509434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5045045045045045]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.23423423423423428]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.18018018018018023]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1742424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25757575757575757]\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.59s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3513513513513513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2432432432432432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/trial, best loss: 0.32432432432432434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3513513513513513]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:18<01:45, 105.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.1875]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.1875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.28125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15384615384615385]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1923076923076923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.20512820512820518]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.1282051282051282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/trial, best loss: 0.17948717948717952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.2564102564102564]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.16216216216216217]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.09459459459459463]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.16216216216216217]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.31081081081081086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.45945945945945943]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3492063492063492]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3492063492063492]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.2698412698412699]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3157894736842105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.4736842105263158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.368421052631579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:17<00:00, 85.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_3 = train_many_models(tests, 0.2, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5315315315315315]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4054054054054054]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/trial, best loss: 0.4414414414414415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/trial, best loss: 0.6126126126126126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.45945945945945943]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.484472049689441]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.36645962732919257]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5652173913043479]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/trial, best loss: 0.5962732919254659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.515527950310559]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.5629629629629629]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6222222222222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.4740740740740741]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5799256505576208]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.43494423791821557]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.5315985130111525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/trial, best loss: 0.6022304832713754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/trial, best loss: 0.5390334572490707]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.4545454545454546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.4439461883408071]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/trial, best loss: 0.4887892376681614]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.5112107623318385]\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.87s/trial, best loss: 0.5156950672645739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.452914798206278]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41414141414141414]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41414141414141414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.48484848484848486]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.27586206896551724]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.4482758620689655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.1724137931034483]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.47619047619047616]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.38095238095238093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5238095238095238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:58<05:56, 178.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.19117647058823528]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.27941176470588236]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.17431192660550454]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.29357798165137616]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.21100917431192656]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33944954128440363]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/trial, best loss: 0.24770642201834858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.30379746835443033]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25316455696202533]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5063291139240507]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.21518987341772156]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.24390243902439024]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.24390243902439024]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.323170731707317]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.43292682926829273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.25609756097560976]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.18791946308724827]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2818791946308725]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.22818791946308725]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.52s/trial, best loss: 0.3422818791946308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.18120805369127513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.32835820895522383]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.20895522388059706]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.25373134328358204]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.25373134328358204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4626865671641791]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.3157894736842105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.10526315789473684]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.6428571428571428]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0714285714285714]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.0714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:05<02:28, 148.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.18604651162790697]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.86s/trial, best loss: 0.13953488372093026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4423076923076923]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.28846153846153844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.3846153846153846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5192307692307692]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.4821428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4821428571428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.38095238095238093]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.2571428571428571]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.16190476190476188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.3648648648648649]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.1351351351351351]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.20270270270270274]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.3918918918918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.2727272727272727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/trial, best loss: 0.36363636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.21212121212121215]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:28<00:00, 149.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_4 = train_many_models(tests, 0, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.18634656 -0.03676989  0.15031008 -0.03959699 -0.12490043 -0.07037755\n -0.09134111 -0.04458665  0.1352139  -0.16476609 -0.05009278  0.09190992\n -0.34166586  0.08114699  0.23261669 -0.17008431  0.26703    -0.16768888\n -0.06202133 -0.05942278  0.1092316  -0.02862591  0.05251266 -0.11338406\n -0.05869795  0.33533546 -0.03953567 -0.19303656  0.01340386  0.14430277\n  0.12718946 -0.02238544  0.04988867  0.00456388  0.02524789 -0.15779145\n -0.02987773  0.10196378  0.28181955  0.05118968 -0.02515618 -0.03099566\n -0.0779213   0.11291613  0.01456078 -0.17366055  0.015126   -0.2848044\n  0.24427599  0.19280988 -0.24432033 -0.08670945  0.14834113 -0.127662\n  0.03236877 -0.05287711  0.19145322  0.07521589 -0.19245347 -0.09138723\n -0.07555477  0.27363858 -0.05572034  0.04520389  0.05240389  0.18196422\n -0.18374667  0.18832822  0.18250655 -0.19465455 -0.10638002  0.05715333\n  0.2827231   0.084935    0.02958411 -0.09023823  0.21262322  0.03100055\n  0.16618191  0.19083691  0.18848822 -0.18259932  0.106947   -0.01263633\n -0.15905377 -0.13997145 -0.05745578 -0.02598044 -0.16546914 -0.22051655\n  0.13094386  0.17497684 -0.08850133  0.052844    0.005095    0.15047556\n  0.05498667  0.06692345 -0.10702322 -0.14551237 -0.11534366  0.26609001\n -0.20847064 -0.26204512 -0.26585776 -0.2789644   0.07561325  0.1621031\n  0.06365511  0.13850023  0.17936866 -0.03577911 -0.04874377  0.16383789\n -0.0411925  -0.02017578 -0.15831366 -0.13642257 -0.05869178  0.08106789\n  0.02017177  0.03341779  0.06465533  0.026192   -0.14571334 -0.10601302\n -0.08588845 -0.10384832 -0.32165346  0.43277434  0.22263125 -0.04443278\n  0.13772123 -0.02116974 -0.07342443  0.08155388 -0.01546111  0.03273155\n -0.2512722  -0.02160933  0.05281444 -0.16476355  0.01053255  0.18035859\n -0.3449012   0.023987    0.32511413  0.13935401 -0.12777989  0.081007\n  0.15717798  0.07340612 -2.21698451 -0.11545645  0.05947145  0.17918311\n -0.10580367  0.17822446  0.02427446 -0.013803    0.13548744  0.10256466\n -0.24156009  0.13866609 -0.01050414 -0.04511344  0.11788198  0.04844212\n  0.09757856  0.08501974 -0.24932776  0.13573311  0.11360656  0.02161834\n -0.08702457 -0.11466544 -0.033427    0.01223289 -0.04737334 -0.10691623\n -0.09661411  0.28688347 -0.05942756  0.01578281  0.06951     0.07973965\n  0.08174323 -0.18866701 -0.16314334  0.02758878  0.19159548 -0.03379688\n -0.1073091   0.06545316 -0.08683923 -0.040576    0.00380845 -0.19891965\n  0.08870278  0.08446962].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willc\\Documents\\wills ensemble\\categorized_voters.ipynb Cell 25\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([text \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m pheme[\u001b[39m'\u001b[39m\u001b[39me_text\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, pheme[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m clf\u001b[39m.\u001b[39;49mpredict(twitter[\u001b[39m'\u001b[39;49m\u001b[39me_text\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:369\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# 'hard' voting\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n\u001b[0;32m    370\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\n\u001b[0;32m    371\u001b[0m         \u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39mbincount(x, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_not_none)),\n\u001b[0;32m    372\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    373\u001b[0m         arr\u001b[39m=\u001b[39mpredictions,\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    376\u001b[0m maj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39minverse_transform(maj)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:68\u001b[0m, in \u001b[0;36m_BaseVoting._predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:68\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([est\u001b[39m.\u001b[39;49mpredict(X) \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    816\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    817\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \n\u001b[0;32m    418\u001b[0m \u001b[39m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[0;32m    432\u001b[0m     predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[0;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\svm\\_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[1;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    612\u001b[0m         X,\n\u001b[0;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    615\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    617\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[0;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.18634656 -0.03676989  0.15031008 -0.03959699 -0.12490043 -0.07037755\n -0.09134111 -0.04458665  0.1352139  -0.16476609 -0.05009278  0.09190992\n -0.34166586  0.08114699  0.23261669 -0.17008431  0.26703    -0.16768888\n -0.06202133 -0.05942278  0.1092316  -0.02862591  0.05251266 -0.11338406\n -0.05869795  0.33533546 -0.03953567 -0.19303656  0.01340386  0.14430277\n  0.12718946 -0.02238544  0.04988867  0.00456388  0.02524789 -0.15779145\n -0.02987773  0.10196378  0.28181955  0.05118968 -0.02515618 -0.03099566\n -0.0779213   0.11291613  0.01456078 -0.17366055  0.015126   -0.2848044\n  0.24427599  0.19280988 -0.24432033 -0.08670945  0.14834113 -0.127662\n  0.03236877 -0.05287711  0.19145322  0.07521589 -0.19245347 -0.09138723\n -0.07555477  0.27363858 -0.05572034  0.04520389  0.05240389  0.18196422\n -0.18374667  0.18832822  0.18250655 -0.19465455 -0.10638002  0.05715333\n  0.2827231   0.084935    0.02958411 -0.09023823  0.21262322  0.03100055\n  0.16618191  0.19083691  0.18848822 -0.18259932  0.106947   -0.01263633\n -0.15905377 -0.13997145 -0.05745578 -0.02598044 -0.16546914 -0.22051655\n  0.13094386  0.17497684 -0.08850133  0.052844    0.005095    0.15047556\n  0.05498667  0.06692345 -0.10702322 -0.14551237 -0.11534366  0.26609001\n -0.20847064 -0.26204512 -0.26585776 -0.2789644   0.07561325  0.1621031\n  0.06365511  0.13850023  0.17936866 -0.03577911 -0.04874377  0.16383789\n -0.0411925  -0.02017578 -0.15831366 -0.13642257 -0.05869178  0.08106789\n  0.02017177  0.03341779  0.06465533  0.026192   -0.14571334 -0.10601302\n -0.08588845 -0.10384832 -0.32165346  0.43277434  0.22263125 -0.04443278\n  0.13772123 -0.02116974 -0.07342443  0.08155388 -0.01546111  0.03273155\n -0.2512722  -0.02160933  0.05281444 -0.16476355  0.01053255  0.18035859\n -0.3449012   0.023987    0.32511413  0.13935401 -0.12777989  0.081007\n  0.15717798  0.07340612 -2.21698451 -0.11545645  0.05947145  0.17918311\n -0.10580367  0.17822446  0.02427446 -0.013803    0.13548744  0.10256466\n -0.24156009  0.13866609 -0.01050414 -0.04511344  0.11788198  0.04844212\n  0.09757856  0.08501974 -0.24932776  0.13573311  0.11360656  0.02161834\n -0.08702457 -0.11466544 -0.033427    0.01223289 -0.04737334 -0.10691623\n -0.09661411  0.28688347 -0.05942756  0.01578281  0.06951     0.07973965\n  0.08174323 -0.18866701 -0.16314334  0.02758878  0.19159548 -0.03379688\n -0.1073091   0.06545316 -0.08683923 -0.040576    0.00380845 -0.19891965\n  0.08870278  0.08446962].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "ensemble = []\n",
    "for model in models_1[0][1]['People & Society'].keys():\n",
    "    set = models_1[0][1]['People & Society']\n",
    "    ensemble.append((model, set[model]))\n",
    "clf = VotingClassifier(ensemble, voting=\"hard\")\n",
    "X_train = np.array([text for text in pheme['e_text']])\n",
    "clf.fit(X_train, pheme['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array(twitter['e_text'][0]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo = get_dataset(\"weibo\")\n",
    "weibo = weibo.drop([1933, 3564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4662/4662 [00:27<00:00, 171.96it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_hard, predictions_soft = predict_points_mutiple_models(models_1[0][1], \"weibo_categories.json\", weibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "X_train = np.array([text for text in ph['e_text']])\n",
    "svm.fit(X_train, twitter['target'])\n",
    "X_test = np.array([text for text in weibo['e_text']])\n",
    "pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.26, 33.71)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.26, 33.75)\n"
     ]
    }
   ],
   "source": [
    "print(check_score(weibo['target'], predictions_hard))\n",
    "print(check_score(weibo['target'], predictions_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51.57, 47.94)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51.57, 47.92)\n"
     ]
    }
   ],
   "source": [
    "print(check_score(weibo[\"target\"], predictions_soft))\n",
    "print(check_score(weibo[\"target\"], predictions_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/trial, best loss: 0.506426735218509]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.37s/trial, best loss: 0.33676092544987146]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.46s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.26s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.71s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.81s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.55s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.52s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.22s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.61s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.55s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.29s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.21s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.19s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.16s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.17s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.20s/trial, best loss: 0.33419023136246784]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.44s/trial, best loss: 0.3316195372750642]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.46s/trial, best loss: 0.3316195372750642]\n",
      "{'learner': SVC(C=1.27806368437018, coef0=0.48726712591817056, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006615201746896151), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/trial, best loss: 0.49382716049382713]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.67s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.38s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.40s/trial, best loss: 0.4320987654320988]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.40s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.39s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.49s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.27s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.71s/trial, best loss: 0.4296296296296296]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.47s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.70s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.42s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.45s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.52s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.50s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.60s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.74s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.78s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.26s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.34s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.23s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.46s/trial, best loss: 0.4246913580246914]\n",
      "100%|██████████| 25/25 [00:05<00:00,  5.37s/trial, best loss: 0.4246913580246914]\n",
      "{'learner': SVC(C=0.9657655830484548, coef0=0.6786722363807116,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=1.4737120975701307e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.3443396226415094]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.96s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.88s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.94s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.3113207547169812]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.97s/trial, best loss: 0.3113207547169812]\n",
      "{'learner': SVC(C=1.174510237626359, coef0=0.02669401762935497,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.009299695485933401), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.78s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.53s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.70s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.60s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.78s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.71s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.44s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.59s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.63s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.53s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.27s/trial, best loss: 0.4130434782608695]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 16/16 [00:05<00:00,  5.49s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.29s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.62s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 19/19 [00:04<00:00,  4.79s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.59s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.84s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.32s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.78s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.63s/trial, best loss: 0.40821256038647347]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.44s/trial, best loss: 0.40821256038647347]\n",
      "{'learner': SVC(C=0.9227940526363324, coef0=0.7927791220638721, degree=1, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0047687362414503606), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.42690058479532167]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.10s/trial, best loss: 0.4093567251461988]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.85s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.3801169590643275]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.3801169590643275]\n",
      "{'learner': SVC(C=1.1079814075167367, coef0=0.8245707521169836,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=2.799872522153208e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.34693877551020413]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.86s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.84s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.80s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.83s/trial, best loss: 0.33163265306122447]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.81s/trial, best loss: 0.33163265306122447]\n",
      "{'learner': SVC(C=0.9257408490290698, coef0=0.41311745281537826,\n",
      "    decision_function_shape='ovo', kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=0.006917915910103056), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.90s/trial, best loss: 0.0980392156862745]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.0980392156862745]\n",
      "{'learner': SVC(C=0.8398322802689391, coef0=0.9227589466765949,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=3.358917433194155e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.4360189573459715]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.00s/trial, best loss: 0.37914691943127965]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.85s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.99s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.92s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.91s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.92s/trial, best loss: 0.30805687203791465]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.30805687203791465]\n",
      "{'learner': SVC(C=0.7540885291669677, coef0=0.7528619691414311,\n",
      "    decision_function_shape='ovo', degree=1, gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, tol=1.0681087675420041e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.022346368715083775]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.83s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.88s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.86s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.88s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.005586592178770999]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.005586592178770999]\n",
      "{'learner': SVC(C=0.6079746578511527, coef0=0.11574484436091592,\n",
      "    decision_function_shape='ovo', degree=5, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.0003660128763222489), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "{'learner': SVC(C=0.770276256541704, coef0=0.8734355361758418, degree=1, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42,\n",
      "    tol=0.0034900441487901706), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.057376398293643, coef0=0.4632876803061109,\n",
      "    decision_function_shape='ovo', degree=5, kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=1.3789159332712913e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.4]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.4]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.4]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.4]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.37142857142857144]\n",
      "{'learner': SVC(C=1.0831080076863404, coef0=0.316185484275032, kernel='poly',\n",
      "    probability=True, random_state=42, tol=9.764195804613026e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0180836682609906, coef0=0.20588792776765352, degree=4, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42,\n",
      "    tol=0.0011333977367915522), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.48]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.42000000000000004]\n",
      "{'learner': SVC(C=1.3174914317906543, coef0=0.7010254690005955, degree=1, probability=True,\n",
      "    random_state=42, tol=0.0006737435001820457), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8863991547664496, coef0=0.4762849565334496, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006657527193216036), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 5375.09it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5347.30it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4563.92it/s]\n",
      " 33%|███▎      | 1/3 [12:29<24:58, 749.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.15625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.15625]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.15625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.15625]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.15625]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.1945646294220587, coef0=0.7884022933921573, degree=1, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0005025238209911815), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.33999999999999997]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.26]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.26]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.26]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.26]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.26]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.24]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.96s/trial, best loss: 0.24]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.03s/trial, best loss: 0.24]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.24]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.95s/trial, best loss: 0.24]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.24]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.24]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.24]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.24]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.24]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.24]\n",
      "{'learner': SVC(C=0.6492912940993498, coef0=0.5441071721230211,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    shrinking=False, tol=6.834361122169257e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.26190476190476186]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.23809523809523814]\n",
      "{'learner': SVC(C=0.8382306246268949, coef0=0.1803690144099015, degree=4, probability=True,\n",
      "    random_state=42, tol=0.0006357388371780233), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.4943820224719101]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.4943820224719101]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2134831460674157]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.1910112359550562]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.78s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.1685393258426966]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.1685393258426966]\n",
      "{'learner': SVC(C=0.9357870759949558, coef0=0.8812821811553421, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.000697527292063522), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0550309647234999, coef0=0.12586013483651415,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.4616474472242081e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0029349581026352, coef0=0.8341480110132776,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    tol=6.702387659796514e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.38]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.14]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.14]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.14]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.14]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.14]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.14]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.14]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.14]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.14]\n",
      "{'learner': SVC(C=1.0620389180277778, coef0=0.029225219203634967, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=6.105606229249174e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.19444444444444442]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.19444444444444442]\n",
      "{'learner': SVC(C=0.5739737166730667, coef0=0.2585621879762716, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0006013771814293189), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.75s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.2962962962962963]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.2962962962962963]\n",
      "{'learner': SVC(C=1.2705136171970062, coef0=0.5400803587482712, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.465830903553389e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.9453032431574453, coef0=0.6007505212540446,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=2.1979249406020847e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.92s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.08s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.92s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=0.8022419371773636, coef0=0.3728577272853363,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0007225168975079846), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=0.8345218023385902, coef0=0.8612891003431599,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, tol=7.146656516836443e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.8933232117455074, coef0=0.5719852675043511,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=0.00015489737340369154), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8452513408234731, coef0=0.9510009361774524, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.007109605847214362), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.0244418566405622, coef0=0.7524552152977808,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.008671256105803455), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Shopping\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=0.9027490213784626, coef0=0.9009048690863479,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.002082398998649251), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 5571.19it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6213.67it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5065.41it/s]\n",
      " 67%|██████▋   | 2/3 [24:06<11:58, 718.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.75s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "{'learner': SVC(C=1.0739993031808703, coef0=0.416689057344241,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0007512366343107693), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "{'learner': SVC(C=1.0106129084990836, coef0=0.9259986948470166, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=2.6061167280872727e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.1724137931034483]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.10344827586206895]\n",
      "{'learner': SVC(C=1.1349840539747738, coef0=0.22540388279634171,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=8.469028406795745e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.82s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.1454545454545455]\n",
      "{'learner': SVC(C=1.3450905167851424, coef0=0.706298652560372, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0005204310494716461), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=1.3600985998300588, coef0=0.9577397780001515,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0003397762686307047), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.24]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.24]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.07999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.040000000000000036]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.040000000000000036]\n",
      "{'learner': SVC(C=1.0549129681233322, coef0=0.23988649512904547, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0010371211656674854), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.07s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.9380684153137936, coef0=0.40053045674426, degree=5, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0007584402160608023), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.96s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.94s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.86s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.84s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.87s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.98s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.05555555555555558]\n",
      "{'learner': SVC(C=1.2609631231136633, coef0=0.33740777295663926, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0010461527328453723), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.5625]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.4375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.4375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.375]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "{'learner': SVC(C=1.0315806400436711, coef0=0.3308717648341267,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.007034405498861934), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.97s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.20s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.91s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.1102772816703703, coef0=0.45848872977822486, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=2.1697960991976383e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.89s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.94s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.120562506943213, coef0=0.2177396686039209, degree=5, probability=True,\n",
      "    random_state=42, tol=0.00026489988551958623), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.1825275975727285, coef0=0.9761729518584825, degree=5, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42,\n",
      "    tol=0.009792736878295684), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.150038096349518, coef0=0.6282824018315654, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0047396390412245875), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.800544497151287, coef0=0.13263043902140748, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.009867581817724826), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.076808603204328, coef0=0.965096967170564, degree=2, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00027473265677620127), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 5466.15it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6541.73it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 6223.86it/s]\n",
      "100%|██████████| 3/3 [35:05<00:00, 701.76s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/trial, best loss: 0.5136363636363637]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.90s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.79s/trial, best loss: 0.4772727272727273]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.87s/trial, best loss: 0.4772727272727273]\n",
      "{'learner': SVC(C=0.9902408249812638, coef0=0.12156199270367096,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00045155910532401663), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.08771929824561409]\n",
      "{'learner': SVC(C=0.7136085040433904, coef0=0.48747808619366395,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', probability=True,\n",
      "    random_state=42, tol=0.00011788274422353139), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.55]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.55]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.55]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.525]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.525]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.525]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.525]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.525]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.57s/trial, best loss: 0.525]\n",
      "{'learner': SVC(C=1.3766200869982947, coef0=0.5372880079150215, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0009084885622898456), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.3798882681564246]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.2849162011173184]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.2793296089385475]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.67s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.78s/trial, best loss: 0.2737430167597765]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.2737430167597765]\n",
      "{'learner': SVC(C=0.966099473809587, coef0=0.2398600586262697, degree=1, kernel='sigmoid',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=2.41754101616871e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.58s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.4482758620689655]\n",
      "{'learner': SVC(C=0.7596674069226144, coef0=0.7374776518119935,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, tol=0.0009731534599314168), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=1.181596039796485, coef0=0.9000207945440192, degree=4, probability=True,\n",
      "    random_state=42, tol=0.001272526113055135), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.3163904172390262, coef0=0.5599152283031321,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.002164113892036766), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4838709677419355]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.467741935483871]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.98s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.00s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.99s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.85s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.93s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.88s/trial, best loss: 0.33870967741935487]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.33870967741935487]\n",
      "{'learner': SVC(C=1.2213920692095193, coef0=0.5746683577070564,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.6855032004828986e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8184558750129268, coef0=0.538820867119558, degree=5, probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.4176057809663056e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.9818181818181818]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.4363636363636364]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2909090909090909]\n",
      "{'learner': SVC(C=0.8610172308299733, coef0=0.22278476975059336,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0013140751222849442), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0925644179222571, coef0=0.4653535477535402, probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0005872685422652758), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.2222222222222222]\n",
      "{'learner': SVC(C=0.7276426586657265, coef0=0.9809266667602178,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00010439865792361638), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.7142857142857143]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.7142857142857143]\n",
      "{'learner': SVC(C=1.0811806468537133, coef0=0.7411559984150862,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.00011456860847060542), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 6042.76it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5872.48it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4765.43it/s]\n",
      " 33%|███▎      | 1/3 [09:21<18:42, 561.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.3846153846153846]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.70s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "{'learner': SVC(C=1.0973347350416882, coef0=0.8146959543122512, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00020866131622642725), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.95s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.97s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.05s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.85s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.73s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.08s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "{'learner': SVC(C=0.8309466980369555, coef0=0.7462564439354765,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.002540178954143434), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=0.9918299805919085, coef0=0.028751298823087357,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0001641799004124282), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "{'learner': SVC(C=0.6845698620823486, coef0=0.5829835206007147,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0007016193070621238), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.025075498683294, coef0=0.3604506564046419,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, tol=4.375838053860454e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.46153846153846156]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.42307692307692313]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.90s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.99s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.85s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.97s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.1923076923076923]\n",
      "{'learner': SVC(C=1.0913418353305946, coef0=0.5584001473576362,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.009749224234551556), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.96s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0003502521229837, coef0=0.8018539595879638, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, tol=1.655617446329184e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.95s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.73s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.86s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.15000000000000002]\n",
      "{'learner': SVC(C=0.7360887983885595, coef0=0.30755783313415963, degree=1, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0034674311163742384), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=0.8694698610777177, coef0=0.18959463421163147,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.268070022219199e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Sensitive Subjects/Other due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.91s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.12s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.94s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.1946223693358395, coef0=0.6411910581138591,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00043559422548918785), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.16s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8463355617960903, coef0=0.8375194175259746, degree=1, probability=True,\n",
      "    random_state=42, tol=0.00012253195457966962), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Pets & Animals\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.5]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.5]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "{'learner': SVC(C=1.143654831462878, coef0=0.6128369207843704,\n",
      "    decision_function_shape='ovo', degree=2, kernel='sigmoid', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.0022901877843015373), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=0.6568428862910083, coef0=0.42494678991564283,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00024138419907427888), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2699371173196583, coef0=0.020408215422609288,\n",
      "    decision_function_shape='ovo', kernel='sigmoid', probability=True,\n",
      "    random_state=42, tol=0.002266874195033649), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Shopping\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.09s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.80s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.0467746599276628, coef0=0.1608792540108338,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.0004193260884928869), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 6089.65it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6755.00it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5710.00it/s]\n",
      " 67%|██████▋   | 2/3 [20:28<10:23, 623.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.95s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.88s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.01s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.10s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.01s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.93s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=0.7026417007342285, coef0=0.7345482881735375, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.00875741934024043), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.89s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.00s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.92s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.1717656596961255, coef0=0.5731214871814254, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0006639095964708486), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.07s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.88s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8644753527772016, coef0=0.25395865614792945,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00817403429570748), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.92s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.83s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.95s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.77s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.86s/trial, best loss: 0.050000000000000044]\n",
      "{'learner': SVC(C=1.0778675653060408, coef0=0.296421671266788, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.905793243720779e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.821195441662391, coef0=0.9583351928177092,\n",
      "    decision_function_shape='ovo', degree=1, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0003837521871284174), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.01s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.96s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.1333333333333333]\n",
      "{'learner': SVC(C=1.2659932834237202, coef0=0.444864129767393, probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.4148634983954097e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.8333333333333334]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=1.0414631976494435, coef0=0.6508710734520677,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0006283629427111075), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.7945079944947862, coef0=0.2949425551562904,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.004813427310731593), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.0339729934507316, coef0=0.6514424963305195,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0005460029755411147), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Sensitive Subjects/Other due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8690534124790918, coef0=0.4762509472326891, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0023841900823015913), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 1.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.94s/trial, best loss: 1.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 1.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 1.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  2.00s/trial, best loss: 1.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 1.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.13s/trial, best loss: 1.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 1.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 1.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 1.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.85s/trial, best loss: 1.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.87s/trial, best loss: 1.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 1.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 1.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 1.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.90s/trial, best loss: 1.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.95s/trial, best loss: 1.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 1.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 1.0]\n",
      "{'learner': SVC(C=0.7837025169471417, coef0=0.07992371875603121, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=5.421404725167397e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2380696262460873, coef0=0.9468190026744151,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', probability=True,\n",
      "    random_state=42, tol=0.00019134297199107587), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [29:39<10:23, 623.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "error training Sports svm, skipping\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4885.76it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6141.91it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5726.74it/s]\n",
      "100%|██████████| 3/3 [29:40<00:00, 593.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.63s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.52s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.79s/trial, best loss: 0.43846153846153846]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.16s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.41s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.28s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.82s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.34s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.32820512820512826]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.61s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.42s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.28s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.62s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.67s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.54s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.45s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.47s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.21s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.17s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.78s/trial, best loss: 0.3256410256410256]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.54s/trial, best loss: 0.3256410256410256]\n",
      "{'learner': SVC(C=1.4850977719052936, coef0=0.7213847427709724,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0003521601209020623), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.61s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.4669926650366748]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.59s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.58s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.72s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.64s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.93s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.86s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.70s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.42s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.71s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.78s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.51s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.87s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.89s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.57s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.54s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.49s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.31s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.47s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.53s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.32s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.60s/trial, best loss: 0.4156479217603912]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.50s/trial, best loss: 0.4156479217603912]\n",
      "{'learner': SVC(C=1.1200050163118433, coef0=0.994496830106449, degree=5, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0010135904438530305), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.96s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.07s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.10s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  2.00s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.00s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.19s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.01s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.17s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.73s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.00s/trial, best loss: 0.32407407407407407]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.12s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.09s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.99s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.19s/trial, best loss: 0.27314814814814814]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.39s/trial, best loss: 0.27314814814814814]\n",
      "{'learner': SVC(C=1.1708437379896266, coef0=0.485690543308848, gamma='auto',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00011814792103229369), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/trial, best loss: 0.4326923076923077]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.89s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.01s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.74s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.63s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.79s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.88s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.51s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.56s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.64s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.59s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.64s/trial, best loss: 0.40384615384615385]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.36s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.98s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.73s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.56s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 18/18 [00:05<00:00,  5.70s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.60s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.51s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.40s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.62s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.70s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.49s/trial, best loss: 0.38221153846153844]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.83s/trial, best loss: 0.38221153846153844]\n",
      "{'learner': SVC(C=1.1626704608976373, coef0=0.9482855293141186,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.006293009855243045), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.4819277108433735]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.87s/trial, best loss: 0.43975903614457834]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.93s/trial, best loss: 0.4337349397590361]\n",
      "100%|██████████| 18/18 [00:01<00:00,  2.00s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.03s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.05s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.11s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.86s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.88s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.02s/trial, best loss: 0.40963855421686746]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.90s/trial, best loss: 0.40963855421686746]\n",
      "{'learner': SVC(C=1.1447870773999322, coef0=0.9663254573708002,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0010246783232766106), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.2864321608040201]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.2864321608040201]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.11s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.17s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.94s/trial, best loss: 0.2814070351758794]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.97s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.93s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.06s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.10s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.11s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.96s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.92s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.03s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.18s/trial, best loss: 0.27638190954773867]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.06s/trial, best loss: 0.27638190954773867]\n",
      "{'learner': SVC(C=1.2469151352914385, coef0=0.811105799135416, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0029710726635458827), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.82s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.77s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.81s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.11875000000000002]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.11875000000000002]\n",
      "{'learner': SVC(C=1.044399647885405, coef0=0.8816520053654071,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    tol=5.868767919848203e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.11s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.10s/trial, best loss: 0.4112149532710281]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.92s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.02s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.80s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.02s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.89s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.96s/trial, best loss: 0.28971962616822433]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.28971962616822433]\n",
      "{'learner': SVC(C=0.9989572336743652, coef0=0.5557713973821182,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=1.2870730925494057e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.83s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.72s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.005464480874316946]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.73s/trial, best loss: 0.005464480874316946]\n",
      "{'learner': SVC(C=1.2157804241037837, coef0=0.567975708674522, degree=5, gamma='auto',\n",
      "    kernel='poly', probability=True, random_state=42,\n",
      "    tol=0.0003333890435284616), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.8529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.8529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.36764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "{'learner': SVC(C=0.9605745182657707, coef0=0.5116331451080922, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00173690406830319), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.574468085106383]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.5531914893617021]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.70s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.5319148936170213]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.5319148936170213]\n",
      "{'learner': SVC(C=1.500782150948154, coef0=0.45076475389230797, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0026451540449486787), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 5813.43it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5744.23it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5186.27it/s]\n",
      " 33%|███▎      | 1/3 [09:39<19:19, 579.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.6060606060606061]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6060606060606061]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.97s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.12121212121212122]\n",
      "{'learner': SVC(C=1.053170110418928, coef0=0.5772521344971144, degree=4, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0015240630301997062), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4423076923076923]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.34615384615384615]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.34615384615384615]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.28846153846153844]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.28846153846153844]\n",
      "{'learner': SVC(C=1.5143011307215515, coef0=0.9028860174159863,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.003082161441447713), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "{'learner': SVC(C=1.076290480716731, coef0=0.8842217989495117,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=6.965222376786167e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2808988764044944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.2696629213483146]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.2696629213483146]\n",
      "{'learner': SVC(C=1.2162138325340206, coef0=0.31943164255526724,\n",
      "    decision_function_shape='ovo', degree=4, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.00624942702293549), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.14583333333333337]\n",
      "{'learner': SVC(C=1.0124889109973583, coef0=0.2460990112526118,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0012734169930438024), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.26530612244897955]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.22448979591836737]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.16326530612244894]\n",
      "{'learner': SVC(C=0.8465270774716437, coef0=0.15490731392475865,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00010705665030995827), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=1.1661134391877166, coef0=0.7018332444398482, degree=5, probability=True,\n",
      "    random_state=42, tol=0.00012759062964340633), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.24137931034482762]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.24137931034482762]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2068965517241379]\n",
      "{'learner': SVC(C=1.0425441228670578, coef0=0.20241183270764618,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=1.0288910412901804e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "{'learner': SVC(C=1.0004399631515826, coef0=0.7164300669839695, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0020279902697426166), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Sensitive Subjects/Accidents & Disasters due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 7118.84it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6722.07it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5813.04it/s]\n",
      " 67%|██████▋   | 2/3 [15:57<07:40, 460.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.16000000000000003]\n",
      "{'learner': SVC(C=1.0150034429945505, coef0=0.4277436151638021, degree=4, probability=True,\n",
      "    random_state=42, tol=5.697602835540444e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.69s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.2272727272727273]\n",
      "{'learner': SVC(C=0.6883588002316052, coef0=0.530058644489191,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=3.202134316824303e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.68s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.09677419354838712]\n",
      "{'learner': SVC(C=1.3086733391297063, coef0=0.1611692395882237,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.00011394522825153981), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=1.2769912811259527, coef0=0.5310038091788527, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0003779463696752834), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.62s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.11538461538461542]\n",
      "{'learner': SVC(C=0.973308512783995, coef0=0.06846108792505667,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.008319688927469907), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.7184767166405854, coef0=0.5650723805451646,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    shrinking=False, tol=0.00015847292027060725), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.66s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.09999999999999998]\n",
      "{'learner': SVC(C=1.0229598964397024, coef0=0.4884428253572495,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=1.2766100390547977e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.65s/trial, best loss: 0.0625]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.63s/trial, best loss: 0.0625]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.0625]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.0625]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.0625]\n",
      "{'learner': SVC(C=1.1029499511798162, coef0=0.21644250264917964, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=4.810775526142717e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.2938025999061962, coef0=0.7770288266113425, degree=5, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.0005497771214803883), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Sensitive Subjects/Accidents & Disasters due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4555.55it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6818.52it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 7002.14it/s]\n",
      "100%|██████████| 3/3 [22:13<00:00, 444.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/trial, best loss: 0.4619771863117871]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.58s/trial, best loss: 0.3136882129277566]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.95s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.56s/trial, best loss: 0.28326996197718635]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.68s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.82s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.34s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.42s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.73s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.45s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.36s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.51s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.86s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.32s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.47s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.96s/trial, best loss: 0.2775665399239544]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.33s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.64s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.68s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.34s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 23/23 [00:05<00:00,  5.57s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.61s/trial, best loss: 0.26615969581749055]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.44s/trial, best loss: 0.26615969581749055]\n",
      "{'learner': SVC(C=1.0354579939043367, coef0=0.6343214579891316, degree=1, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.005462888691007148), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.02s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.50s/trial, best loss: 0.5045317220543807]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.23s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.15s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.71s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.99s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.98s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 9/9 [00:10<00:00, 10.30s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.06s/trial, best loss: 0.44712990936555896]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.91s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.97s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.27s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.09s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.33s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.87s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 18/18 [00:03<00:00,  3.97s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.86s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.10s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.50s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 22/22 [00:03<00:00,  3.67s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.75s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 24/24 [00:03<00:00,  3.77s/trial, best loss: 0.43202416918429]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.26s/trial, best loss: 0.43202416918429]\n",
      "{'learner': SVC(C=0.8188298309947025, coef0=0.9174219843469561, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.668548470353182e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.10s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.04s/trial, best loss: 0.4076923076923077]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.10s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.14s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.45s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 16/16 [00:03<00:00,  3.58s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.61s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.69s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.76s/trial, best loss: 0.40512820512820513]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.37s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.56s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.47s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.52s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.52s/trial, best loss: 0.36923076923076925]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.39s/trial, best loss: 0.36923076923076925]\n",
      "{'learner': SVC(C=0.6413929204561002, coef0=0.14483087242897996, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0021260473311007105), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/trial, best loss: 0.5223300970873787]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.18s/trial, best loss: 0.5223300970873787]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.93s/trial, best loss: 0.4563106796116505]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.92s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.67s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.17s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.22s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.69s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.20s/trial, best loss: 0.45242718446601937]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.42s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.70s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.65s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.63s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.16s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.88s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.88s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.72s/trial, best loss: 0.44466019417475733]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.44s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.83s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.74s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 21/21 [00:03<00:00,  3.23s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.70s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 23/23 [00:03<00:00,  3.20s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 24/24 [00:03<00:00,  3.64s/trial, best loss: 0.43495145631067966]\n",
      "100%|██████████| 25/25 [00:03<00:00,  3.12s/trial, best loss: 0.43495145631067966]\n",
      "{'learner': SVC(C=0.8642653945638715, coef0=0.5839810885286911,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.003363392176623931), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.43190661478599224]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.39688715953307396]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.3891050583657587]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 13/13 [00:01<00:00,  2.00s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.96s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.91s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.91s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.99s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.89s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.86s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.98s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.03s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.39s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.93s/trial, best loss: 0.3463035019455253]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.31s/trial, best loss: 0.3463035019455253]\n",
      "{'learner': SVC(C=1.3432699639883203, coef0=0.1521625047465014,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0008482677684109368), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.01s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.02s/trial, best loss: 0.4568245125348189]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.00s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.98s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.12s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.01s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.16s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.09s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.37604456824512533]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.09s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.95s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.01s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.94s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.98s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.12s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.02s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.08s/trial, best loss: 0.3704735376044568]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.94s/trial, best loss: 0.36768802228412256]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.92s/trial, best loss: 0.36768802228412256]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.03s/trial, best loss: 0.36768802228412256]\n",
      "{'learner': SVC(C=0.6755970533119107, coef0=0.594016954483138, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.005345841940323481), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.2329749103942652]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.09s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.31s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.81s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.87s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.09s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.92s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.91s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.89s/trial, best loss: 0.2114695340501792]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.89s/trial, best loss: 0.2114695340501792]\n",
      "{'learner': SVC(C=1.2523483472146713, coef0=0.9298410184908785, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00016579205394151881), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.16s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.35526315789473684]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.98s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.31s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.96s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.10s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.42s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.13s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.23s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.32s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.02s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.17s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.19s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.15s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.97s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.03s/trial, best loss: 0.3519736842105263]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.23s/trial, best loss: 0.3519736842105263]\n",
      "{'learner': SVC(C=1.024399663052638, coef0=0.9942689934608099,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='sigmoid',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005087492312337215), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.91s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.99s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.93s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.92s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.95s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.96s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.90s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.85s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.89s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.85s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.97s/trial, best loss: 0.13183279742765275]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.13s/trial, best loss: 0.13183279742765275]\n",
      "{'learner': SVC(C=1.235825619240749, coef0=0.9238401177323995,\n",
      "    decision_function_shape='ovo', degree=1, probability=True, random_state=42,\n",
      "    tol=0.0014237686718697505), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.4571428571428572]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.4571428571428572]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.37142857142857144]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=0.7834479179614491, coef0=0.9977348431453368, degree=4, gamma='auto',\n",
      "    kernel='sigmoid', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.005666066907806563), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Reference\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.06s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.84s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.78s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.80s/trial, best loss: 0.30000000000000004]\n",
      "{'learner': SVC(C=1.0201874371566448, coef0=0.11023114461785166, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00014900666244169306), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Firearms & Weapons\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.7325581395348837]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.4767441860465116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4767441860465116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.81s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.79s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.38372093023255816]\n",
      "{'learner': SVC(C=0.7404738303826865, coef0=0.6267263365455618,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=5.047620044484848e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.84s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.00s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.92s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.87s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.82s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.77s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.74s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.26315789473684215]\n",
      "{'learner': SVC(C=1.498549077659054, coef0=0.18066536792136256,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=3.39840649940919e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.9444444444444444]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.9444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.7222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.78s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.73s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.73s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.6111111111111112]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.6111111111111112]\n",
      "{'learner': SVC(C=0.9423971911934294, coef0=0.5537580311095094,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=7.160568694467945e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.7777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.7777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.87s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.27s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.80s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.4722222222222222]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.83s/trial, best loss: 0.4722222222222222]\n",
      "{'learner': SVC(C=0.8946049155899276, coef0=0.5854157388769318,\n",
      "    decision_function_shape='ovo', kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0014967607096380174), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Travel & Transportation\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:00<00:00, 4747.06it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5246.96it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 4695.59it/s]\n",
      " 33%|███▎      | 1/3 [13:41<27:23, 821.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.73s/trial, best loss: 0.1964285714285714]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.74s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.79s/trial, best loss: 0.1785714285714286]\n",
      "{'learner': SVC(C=0.9689573367316257, coef0=0.4308797345901485,\n",
      "    decision_function_shape='ovo', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=2.3634845999761477e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.3294117647058824]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.2588235294117647]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.81s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.79s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.23529411764705888]\n",
      "{'learner': SVC(C=0.708658334469585, coef0=0.4802867330432232,\n",
      "    decision_function_shape='ovo', degree=4, probability=True, random_state=42,\n",
      "    shrinking=False, tol=2.3984789710312818e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.5538461538461539]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.24615384615384617]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.13s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.79s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.75s/trial, best loss: 0.19999999999999996]\n",
      "{'learner': SVC(C=1.1842439006344645, coef0=0.9222532817907875,\n",
      "    decision_function_shape='ovo', degree=4, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.003994644487376946), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.22556390977443608]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.22556390977443608]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.87s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.85s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.81s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.83s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.20300751879699253]\n",
      "{'learner': SVC(C=0.8256828805648174, coef0=0.8111818877100204,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00011321533743303551), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.77s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.84s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.02s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.76s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.67s/trial, best loss: 0.09090909090909094]\n",
      "{'learner': SVC(C=1.2647949300574346, coef0=0.9134434356454106,\n",
      "    decision_function_shape='ovo', kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.004065886583365643), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.24561403508771928]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.76s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.79s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.14035087719298245]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.71s/trial, best loss: 0.14035087719298245]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.72s/trial, best loss: 0.14035087719298245]\n",
      "{'learner': SVC(C=1.00882083848888, coef0=0.7233970841400361, decision_function_shape='ovo',\n",
      "    degree=4, kernel='poly', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.003071829161006276), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.22666666666666668]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.39s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.98s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.75s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.18s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.11s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.93s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.01s/trial, best loss: 0.21333333333333337]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.82s/trial, best loss: 0.21333333333333337]\n",
      "{'learner': SVC(C=0.8412115704503753, coef0=0.35886401942974866,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', probability=True,\n",
      "    random_state=42, tol=0.0008515015488483201), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5306122448979591]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.92s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.94s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.83s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.71s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.74s/trial, best loss: 0.20408163265306123]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.76s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.81s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.78s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.16326530612244894]\n",
      "100%|██████████| 25/25 [00:02<00:00,  2.09s/trial, best loss: 0.16326530612244894]\n",
      "{'learner': SVC(C=1.1595357821726857, coef0=0.6677138581574943, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42,\n",
      "    tol=0.0019438975552523775), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.62s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.71s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.64s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.21818181818181814]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.59s/trial, best loss: 0.21818181818181814]\n",
      "{'learner': SVC(C=1.3053593755817927, coef0=0.9907790248511561,\n",
      "    decision_function_shape='ovo', degree=5, probability=True, random_state=42,\n",
      "    tol=0.006738077748238987), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.32432432432432434]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.32432432432432434]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.2702702702702703]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2702702702702703]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.84s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.96s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.18918918918918914]\n",
      "{'learner': SVC(C=0.8585777920702677, coef0=0.699468624580953,\n",
      "    decision_function_shape='ovo', degree=2, probability=True, random_state=42,\n",
      "    tol=3.9518201312698455e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.1875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.1875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.1875]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.1875]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.1875]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.1875]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.1875]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.72s/trial, best loss: 0.1875]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.66s/trial, best loss: 0.1875]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "{'learner': SVC(C=0.7797889050649219, coef0=0.5163508240164248, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00017318010063429505), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.2316406332920518, coef0=0.43105338630321455, degree=1, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0022489487222173304), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.81s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.66s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.74s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.82s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.68s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.58s/trial, best loss: 0.23529411764705888]\n",
      "{'learner': SVC(C=0.4830395270814024, coef0=0.9273971994519238,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=2.6794411463268183e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=1.1273292544503029, coef0=0.9677116074578805,\n",
      "    decision_function_shape='ovo', degree=5, gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.002380793477486848), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:00<00:00, 5691.64it/s]\n",
      "100%|██████████| 6425/6425 [00:00<00:00, 6645.95it/s]\n",
      "100%|██████████| 817/817 [00:00<00:00, 5427.88it/s]\n",
      " 67%|██████▋   | 2/3 [23:59<11:41, 701.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.65s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.59s/trial, best loss: 0.18918918918918914]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.18918918918918914]\n",
      "{'learner': SVC(C=1.1854487404071743, coef0=0.4616991803791799, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.006744868923094926), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: People & Society\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.65s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.62s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.66s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.18604651162790697]\n",
      "{'learner': SVC(C=0.8238837122820875, coef0=0.29430990881146823, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.00015236716068676753), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Arts & Entertainment\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.11363636363636365]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.65s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.84s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.83s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.97s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.99s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.72s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.09090909090909094]\n",
      "{'learner': SVC(C=1.0288633092207546, coef0=0.6241710851772245,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=1.7548258743746086e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Law & Government\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.3975903614457831]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.19277108433734935]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.19277108433734935]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.69s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.68s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.67s/trial, best loss: 0.12048192771084343]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.69s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.68s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.67s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.69s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.68s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.10843373493975905]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.70s/trial, best loss: 0.10843373493975905]\n",
      "{'learner': SVC(C=1.0389121698412023, coef0=0.3918118822663198,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, shrinking=False, tol=6.76107455772695e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: News\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.6714638142626838, coef0=0.36920014751766206, degree=2, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005610573081463986), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Food & Drink\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.75s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.63s/trial, best loss: 0.06666666666666665]\n",
      "{'learner': SVC(C=1.2880514976184676, coef0=0.8955765202855243,\n",
      "    decision_function_shape='ovo', degree=5, kernel='linear', probability=True,\n",
      "    random_state=42, shrinking=False, tol=0.005725730917700241), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Violence & Abuse\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.14814814814814814]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.14814814814814814]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.07407407407407407]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.57s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.59s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.60s/trial, best loss: 0.03703703703703709]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.66s/trial, best loss: 0.03703703703703709]\n",
      "{'learner': SVC(C=1.3364383335792416, coef0=0.7789939037627189, degree=4, gamma='auto',\n",
      "    kernel='linear', probability=True, random_state=42, shrinking=False,\n",
      "    tol=0.0005010131440851913), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Death & Tragedy\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.60s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.59s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.58s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.61s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.67s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.91s/trial, best loss: 0.1071428571428571]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.74s/trial, best loss: 0.1071428571428571]\n",
      "{'learner': SVC(C=1.0766816669103876, coef0=0.12850224576898261, degree=2, probability=True,\n",
      "    random_state=42, tol=0.00041467392482562803), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/War & Conflict\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.81s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.85s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.94s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.59s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.65s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.69s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.81s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.60s/trial, best loss: 0.2692307692307693]\n",
      "{'learner': SVC(C=1.3527952358595319, coef0=0.5489386173857607,\n",
      "    decision_function_shape='ovo', degree=4, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.0023905782633924493), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Online Communities\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "{'learner': SVC(C=1.3669075550514596, coef0=0.12701541259495197, degree=2, probability=True,\n",
      "    random_state=42, tol=0.0009512504785812856), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Other\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.77s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.72s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.64s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "{'learner': SVC(C=1.2681833218104106, coef0=0.9590096510934277,\n",
      "    decision_function_shape='ovo', degree=2, kernel='poly', probability=True,\n",
      "    random_state=42, tol=0.00047027757948644045), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Health\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.02s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.76s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.87s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "{'learner': SVC(C=1.099635698549255, coef0=0.17566072294139579, degree=4, kernel='linear',\n",
      "    probability=True, random_state=42, tol=0.00047434981375646124), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Business & Industrial\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "{'learner': SVC(C=0.8940054835764077, coef0=0.07461559453754929, degree=2, kernel='linear',\n",
      "    probability=True, random_state=42, tol=1.8183007404132265e-05), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sensitive Subjects/Accidents & Disasters\n",
      "Skipped category: Sensitive Subjects/Self-Harm due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.15s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "{'learner': SVC(C=0.6771598742435734, coef0=0.5687710609329284, degree=4, probability=True,\n",
      "    random_state=42, tol=0.00018750571204383915), 'preprocs': (), 'ex_preprocs': ()}\n",
      "Created SVM trained in category: Sports\n",
      "Skipped category: Sensitive Subjects/Firearms & Weapons due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Sensitive Subjects/Recreational Drugs due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4370.79it/s]\n",
      "100%|██████████| 6425/6425 [00:01<00:00, 6322.05it/s]\n",
      "100%|██████████| 1491/1491 [00:00<00:00, 5702.27it/s]\n",
      "100%|██████████| 3/3 [33:56<00:00, 678.73s/it]\n"
     ]
    }
   ],
   "source": [
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"]]\n",
    "results1 = run_tests(tests, 0.2, 50)\n",
    "results2 = run_tests(tests, 0.5, 20)\n",
    "results3 = run_tests(tests, 0.2, 200)\n",
    "results4 = run_tests(tests, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.7017543859649122]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.6491228070175439]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.4736842105263158]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.7543859649122807]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5915492957746479]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5352112676056338]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.6338028169014085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.6621621621621622]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.5675675675675675]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.472972972972973]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.5405405405405406]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.48611111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.5069444444444444]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.33s/trial, best loss: 0.5694444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.5138888888888888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4375]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3924050632911392]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.4493670886075949]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.4810126582278481]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.5759493670886076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.4810126582278481]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.3555555555555555]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.4222222222222223]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.5555555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.6]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.5111111111111111]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.33333333333333337]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.4]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.75]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.375]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.5833333333333333]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.5833333333333333]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4444444444444444]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.33333333333333337]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4444444444444444]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.3076923076923077]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3076923076923077]\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23076923076923073]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:09<00:00, 131.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(pheme.drop(\"target\", axis=1), pheme[\"target\"], train_size=0.8, stratify=pheme[\"target\"]) \n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "models = train_models(\"pheme\", 0.2, 50, train_set, model_list)\n",
    "a = predict_points_mutiple_models(models, \"pheme_categories.json\", X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.5166666666666666]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Adaboost in category People & Society, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.55]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5945945945945945]\n"
     ]
    }
   ],
   "source": [
    "multi_result1 = get_tests_multi(tests, 0.2, 50, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.64]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.64]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.64]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.64]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.36]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.36]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.64]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.36]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.36]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.36]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.36]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.36]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.36]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.38s/trial, best loss: 0.36]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.36]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.36]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.36]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.56]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.56]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.56]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.56]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.52]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.52]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.52]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.52]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.52]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.52]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.52]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.52]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.5416666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.45833333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.21s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.15s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.78s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.10s/trial, best loss: 0.29166666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.20833333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.20833333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.45833333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.39534883720930236]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.6046511627906976]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.12s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 12/12 [00:05<00:00,  5.01s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.41860465116279066]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.41860465116279066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.6744186046511628]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.6511627906976745]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.94s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.627906976744186]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.6046511627906976]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  2.00s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.72s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.4565217391304348]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.44565217391304346]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.48913043478260865]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.85s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:15<00:00, 15.50s/trial, best loss: 0.4782608695652174]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.00s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.19s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.95s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.18s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.38s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.34782608695652173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.5217391304347826]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.5217391304347826]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.10s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (307) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (307) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.75]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.6]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.30000000000000004]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:11<00:00, 113.14it/s]\n",
      "100%|██████████| 1491/1491 [00:09<00:00, 156.81it/s]\n",
      "100%|██████████| 817/817 [00:04<00:00, 173.10it/s]\n",
      " 33%|███▎      | 1/3 [26:10<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.41s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.41666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.38888888888888884]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.2777777777777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2222222222222222]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.95s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.37s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.07s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.99s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.28s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.18s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.07s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.35s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.07s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.41s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.03s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.01s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.05s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.18s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/trial, best loss: 0.31818181818181823]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.16s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.47s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.64s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.13636363636363635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.13636363636363635]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.43s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.28125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.28125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.28125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.234375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.234375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.234375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.234375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.234375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.234375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.234375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.484375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.28125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.28125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.28125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.265625]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.265625]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.265625]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.81s/trial, best loss: 0.265625]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.265625]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.265625]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.265625]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.265625]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.39s/trial, best loss: 0.265625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.265625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.265625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/trial, best loss: 0.234375]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.12s/trial, best loss: 0.234375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.234375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.234375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.234375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.234375]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.234375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.234375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.234375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.234375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.234375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.234375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.234375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.234375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.08s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 12, n_neighbors = 14\n",
      "\n",
      " 33%|███▎      | 1/3 [40:13<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.41s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.49s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.51s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.20s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.26s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.98s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.84s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.98s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 8, n_neighbors = 11\n",
      "\n",
      " 33%|███▎      | 1/3 [46:42<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 12, n_neighbors = 14\n",
      "\n",
      " 33%|███▎      | 1/3 [48:39<52:21, 1570.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Shopping, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.99s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.93s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.03s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.90s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.04s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.15s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.99s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.31s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:01<00:00, 210.82it/s]\n",
      "100%|██████████| 6425/6425 [00:25<00:00, 256.47it/s]\n",
      "100%|██████████| 817/817 [00:04<00:00, 168.20it/s]\n",
      " 67%|██████▋   | 2/3 [52:44<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.98s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.3571428571428571]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.01s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.85s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.95s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.2142857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.11s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.97s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.12s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.14s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.30s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.32s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.09s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.43s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.18s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.25s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.97s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 6/6 [00:01<00:00,  2.00s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 13/13 [00:01<00:00,  2.00s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.052631578947368474]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.06s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.88s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.82s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.87s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.86s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.07s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.01s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.99s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.17s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.89s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.49s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.01s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.10526315789473684]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.10526315789473684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.89s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.13s/trial, best loss: 0.1578947368421053]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.12s/trial, best loss: 0.1578947368421053]\n",
      "Skipped category: Food & Drink due to class issues\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.08s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.08s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.06s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.95s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.15s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.01s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.06s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.96s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.00s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.85s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.76s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.83s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.2068965517241379]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.23s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.95s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 10/10 [00:05<00:00,  5.22s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.64s/trial, best loss: 0.03448275862068961]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.08s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.93s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.94s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.88s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.04s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.03s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 14/14 [00:01<00:00,  2.00s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.03448275862068961]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/trial, best loss: 1.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 1.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 1.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.18s/trial, best loss: 1.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.06s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:05:03<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Online Communities, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.02s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.17s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.10s/trial, best loss: 0.0]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  2.00s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 8\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:07:01<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Health, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.12s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.31s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "Skipped category: Pets & Animals due to class issues\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 9\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:08:52<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training KNN in category Business & Industrial, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.13s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.99s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.14s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.95s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.82s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.00s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.01s/trial, best loss: 0.0]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to class issues\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:10:18<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?trial/s, best loss=?]\n",
      "Error training SVC in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.09s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.00s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False\n",
      "\n",
      " 67%|██████▋   | 2/3 [1:10:49<26:24, 1584.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "Error training Logistic Regression in category Sports, skipping\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.95s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.25]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:01<00:00, 129.98it/s]\n",
      "100%|██████████| 6425/6425 [01:23<00:00, 76.74it/s]\n",
      "100%|██████████| 1491/1491 [00:13<00:00, 113.39it/s]\n",
      "100%|██████████| 3/3 [1:13:21<00:00, 1467.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((64.9, 47.49), (64.82, 47.44)),\n",
       "   ('twitter15', (52.05, 39.26), (51.78, 38.83)),\n",
       "   ('twitter16', (50.8, 36.75), (51.04, 37.25))]),\n",
       " ('twitter15',\n",
       "  [((62.88, 61.21), (63.55, 61.79)),\n",
       "   ('PHEME', (61.4, 51.65), (61.37, 51.53)),\n",
       "   ('twitter16', (53.0, 46.59), (53.0, 46.38))]),\n",
       " ('twitter16',\n",
       "  [((69.51, 67.58), (69.51, 67.58)),\n",
       "   ('PHEME', (62.05, 60.04), (61.68, 59.74)),\n",
       "   ('twitter15', (51.37, 46.11), (51.31, 46.21))])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result2 = run_tests_multi(tests, 0.5, 20, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.08s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.92s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.90s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.15s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.79s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.38596491228070173]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.55s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.82s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.97s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.04s/trial, best loss: 0.2807017543859649]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85s/trial, best loss: 0.6140350877192983]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.05s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.98s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.04s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.07s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.24s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.88s/trial, best loss: 0.543859649122807]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/trial, best loss: 0.6842105263157895]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.4736842105263158]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.18s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.80s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.55s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 15/15 [00:07<00:00,  7.32s/trial, best loss: 0.45614035087719296]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.92s/trial, best loss: 0.5614035087719298]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.97s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.13s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.12s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.45614035087719296]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.95s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.86s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.4864864864864865]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.472972972972973]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.09s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.85s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.44594594594594594]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.97s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.86s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.14s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.06s/trial, best loss: 0.527027027027027]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.5]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.5]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.5]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.5]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.5]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.18s/trial, best loss: 0.5]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.82s/trial, best loss: 0.5]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.72s/trial, best loss: 0.6756756756756757]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.12s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.02s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.45s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.78s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 6/6 [00:09<00:00,  9.54s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.19s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 8/8 [00:05<00:00,  5.77s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 9/9 [00:14<00:00, 14.98s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.15s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.75s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.37s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.93s/trial, best loss: 0.3918918918918919]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.3918918918918919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/trial, best loss: 0.6081081081081081]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.6081081081081081]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.5945945945945945]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.03s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.5540540540540541]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.03s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.5405405405405406]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.6056338028169015]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.6056338028169015]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.5774647887323944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.05s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.78s/trial, best loss: 0.5633802816901409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.92s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.89s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.86s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.80s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.05s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.93s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.26s/trial, best loss: 0.47887323943661975]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.04s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.10s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.5070422535211268]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.98s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 11/11 [00:07<00:00,  7.36s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.28s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.45070422535211263]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.45070422535211263]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.619718309859155]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.80s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.85s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.98s/trial, best loss: 0.5492957746478873]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.88s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.11s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.91s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.87s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.98s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.5034013605442177]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.4217687074829932]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.34s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.4013605442176871]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.3945578231292517]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.36s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.50s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.63s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.84s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.50s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.77s/trial, best loss: 0.3877551020408163]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.69s/trial, best loss: 0.47619047619047616]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.47619047619047616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/trial, best loss: 0.6190476190476191]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.92s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 3/3 [01:11<00:00, 71.26s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 4/4 [00:08<00:00,  8.79s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.6054421768707483]\n",
      "100%|██████████| 6/6 [00:20<00:00, 20.57s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.76s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.40s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.45s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.13s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.77s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.71s/trial, best loss: 0.5714285714285714]\n",
      "100%|██████████| 15/15 [00:08<00:00,  8.50s/trial, best loss: 0.5714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.5850340136054422]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.5782312925170068]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.94s/trial, best loss: 0.5170068027210885]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.5170068027210885]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.93s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.92s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.5102040816326531]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.88s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.90s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.4897959183673469]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.44897959183673475]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.44897959183673475]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.44897959183673475]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.4144736842105263]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.91s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.73s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.20s/trial, best loss: 0.45394736842105265]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.4473684210526315]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.493421052631579]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.04s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.10s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.94s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.10s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.83s/trial, best loss: 0.48026315789473684]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.89s/trial, best loss: 0.48026315789473684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.64s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78s/trial, best loss: 0.4671052631578947]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.87s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.89s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.23s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.87s/trial, best loss: 0.4078947368421053]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.4078947368421053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.5263157894736843]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.44s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.18s/trial, best loss: 0.48684210526315785]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.20s/trial, best loss: 0.48684210526315785]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.37s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.06s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.90s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.54s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.07s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.56s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.5681818181818181]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.43181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.43181818181818177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.5454545454545454]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.19s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.93s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.40s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.54s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.32s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.34090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.34090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.00s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.10s/trial, best loss: 0.4545454545454546]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.86s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.86s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.96s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.96s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.88s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.95s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.36363636363636365]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:07<00:00, 164.61it/s]\n",
      "100%|██████████| 1491/1491 [00:08<00:00, 177.57it/s]\n",
      "100%|██████████| 817/817 [00:05<00:00, 154.05it/s]\n",
      " 33%|███▎      | 1/3 [18:31<37:03, 1111.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.5151515151515151]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.21212121212121215]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.4242424242424242]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.96s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.93s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.26s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.15s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.89s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.98s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/trial, best loss: 0.303030303030303]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.303030303030303]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.94s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.87s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 11/11 [00:05<00:00,  5.31s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.24242424242424243]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.92s/trial, best loss: 0.24242424242424243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.95s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.96s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.35s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.1515151515151515]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.03s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.92s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.12121212121212122]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.78s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.80s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.84s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.02s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.91s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.88s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2075471698113207]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.37735849056603776]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.3207547169811321]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.28301886792452835]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.43s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.77s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.80s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.79s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.26415094339622647]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.89s/trial, best loss: 0.26415094339622647]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.339622641509434]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.24528301886792447]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.76s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.06s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.94s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.2264150943396226]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.90s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.99s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.18867924528301883]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.78s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.76s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.09s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.79s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.82s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.05s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.36s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.32s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.39s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.66s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.59s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.85s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.29s/trial, best loss: 0.2558139534883721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.06s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.98s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.80s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.68s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.17s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.97s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.02s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.04s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.2790697674418605]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.5227272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.84s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.86s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.12s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.34s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.82s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.91s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.38s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.27s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.43s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.37s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.04s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.20454545454545459]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.26136363636363635]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.07s/trial, best loss: 0.26136363636363635]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.09s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.91s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.20s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.2272727272727273]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.4204545454545454]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.40909090909090906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.03s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.3522727272727273]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.15s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.00s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.65s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.77s/trial, best loss: 0.23863636363636365]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.97s/trial, best loss: 0.23863636363636365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.48s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.50s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.48s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.14s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.09s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.96s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.29s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.00s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.03s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.21590909090909094]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.11s/trial, best loss: 0.20454545454545459]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.91s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.07s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.14s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.02s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.05s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.89s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.87s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.84s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.80s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.91s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.47s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.19s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.92s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.00s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.20s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.61s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.81s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.82s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.69s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.01s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.43s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.70s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.54s/trial, best loss: 0.19047619047619047]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.79s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.44s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.11s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.37s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.66s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.83s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.40s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.19s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.83s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.18s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 12/12 [00:06<00:00,  6.61s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.06s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.14s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.21904761904761905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.3142857142857143]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.56s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.85s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.27s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.31s/trial, best loss: 0.2761904761904762]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.08s/trial, best loss: 0.2571428571428571]\n",
      "100%|██████████| 10/10 [00:06<00:00,  6.24s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.49s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.18s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 13/13 [00:25<00:00, 25.34s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 14/14 [00:15<00:00, 15.21s/trial, best loss: 0.23809523809523814]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.38s/trial, best loss: 0.23809523809523814]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.51s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.38s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.69s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.51s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.03s/trial, best loss: 0.22857142857142854]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.86s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.51s/trial, best loss: 0.21904761904761905]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.89s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.65s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.23s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.43s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.56s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.42s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.49s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.48s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.92s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.53s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.51s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.41s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.59s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.3548387096774194]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.39s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.50s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.52s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.56s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.64s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.32258064516129037]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.37s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.39s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.41s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.32s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.29s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.40s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.89s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.63s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.22s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.19354838709677424]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.45s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.56s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.34s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.40s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.44s/trial, best loss: 0.22580645161290325]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.85s/trial, best loss: 0.22580645161290325]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:08<00:00, 35.70it/s]\n",
      "100%|██████████| 6425/6425 [03:53<00:00, 27.55it/s]\n",
      "100%|██████████| 817/817 [00:18<00:00, 43.72it/s]\n",
      " 67%|██████▋   | 2/3 [40:26<20:31, 1231.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/trial, best loss: 0.6538461538461539]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.24s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.21s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.32s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.38s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.38s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.36s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.46s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.50s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.47s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.42s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.11538461538461542]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.25s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.24s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.35s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.32s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.23s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.30s/trial, best loss: 0.23076923076923073]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.25s/trial, best loss: 0.23076923076923073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.3076923076923077]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.35s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.29s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.21s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.24s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.21s/trial, best loss: 0.1923076923076923]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.36s/trial, best loss: 0.1923076923076923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.6538461538461539]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.44s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.35s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.18s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.21s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.33s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.40s/trial, best loss: 0.2692307692307693]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.22s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.34s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.17s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.36s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.49s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.24s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.33s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.43s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.26s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.22s/trial, best loss: 0.09999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.68s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.05s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.41s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.19s/trial, best loss: 0.050000000000000044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.28s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.25s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.38s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.22s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.31s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.25s/trial, best loss: 0.09999999999999998]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.6]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.6]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.25s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.29s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.23s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.17s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.18s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.15s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.30s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.16s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.40s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.42s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.42s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.40s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.48s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.25s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.36s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.32s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.3666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.45s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.22s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.16s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.37s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.54s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.87s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.55s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.53s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.28s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.52s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.49s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.56s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.27s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.75s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.17s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.44s/trial, best loss: 0.4482758620689655]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.28s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.29s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.33s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.93s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.26s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.38s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.19s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.39s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.30s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.19s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.39s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.27s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.33s/trial, best loss: 0.06896551724137934]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.20s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.51s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.29s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.35s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.2931034482758621]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.2931034482758621]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.85s/trial, best loss: 0.15517241379310343]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.58s/trial, best loss: 0.15517241379310343]\n",
      "100%|██████████| 5/5 [00:14<00:00, 14.79s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.77s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.65s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.28s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.08s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.12068965517241381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.13793103448275867]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.69s/trial, best loss: 0.12068965517241381]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.36s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.10344827586206895]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.54s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.36s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.22s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.51s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.32s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.48s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.31s/trial, best loss: 0.08620689655172409]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.17s/trial, best loss: 0.051724137931034475]\n",
      "Skipped category: Food & Drink due to low numbers\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.18s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.20s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.3137254901960784]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.25s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.10s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.34s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.15s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.25s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.27s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.26s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.46s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.34s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.196078431372549]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.22s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.17s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.30s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.42s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.48s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.42s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.40s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.13s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.24s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.16s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.22s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.17s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.14s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.19s/trial, best loss: 0.27450980392156865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.33s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.48s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.47s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.42s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.02s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.46s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.57s/trial, best loss: 0.27450980392156865]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.32s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.70s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.30s/trial, best loss: 0.2549019607843137]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.58s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.32s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.78s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.56s/trial, best loss: 0.21568627450980393]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.14s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.13s/trial, best loss: 0.4666666666666667]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.14s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.21s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.22s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.15s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.20s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.20s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.51s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.18s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.19s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.34s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.16s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.21s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.11s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.15s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.08s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.13s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.23s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.14s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.08s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.06s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.15s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.14s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.11s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.38s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.16s/trial, best loss: 0.2666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.6666666666666667]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.4]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.4]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.17s/trial, best loss: 0.4]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.4]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.80s/trial, best loss: 0.4]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.13s/trial, best loss: 0.4]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.18s/trial, best loss: 0.4]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.24s/trial, best loss: 0.4]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.20s/trial, best loss: 0.4]\n",
      "100%|██████████| 12/12 [00:05<00:00,  5.55s/trial, best loss: 0.4]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.14s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.37s/trial, best loss: 0.2666666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.22s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.31s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.16s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.26s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.15s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.51s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.35s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.40s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.21s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.20s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.06666666666666665]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "Skipped category: Health due to low numbers\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "Skipped category: Business & Industrial due to low numbers\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "Skipped category: Sports due to low numbers\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 33.11it/s]\n",
      "100%|██████████| 6425/6425 [01:25<00:00, 75.43it/s] \n",
      "100%|██████████| 1491/1491 [00:25<00:00, 57.63it/s]\n",
      "100%|██████████| 3/3 [1:00:53<00:00, 1217.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((66.93, 56.46), (66.69, 56.28)),\n",
       "   ('twitter15', (51.51, 41.61), (51.17, 41.16)),\n",
       "   ('twitter16', (52.26, 41.46), (52.51, 41.91))]),\n",
       " ('twitter15',\n",
       "  [((63.88, 61.02), (63.88, 60.86)),\n",
       "   ('PHEME', (61.56, 52.93), (61.67, 52.94)),\n",
       "   ('twitter16', (56.18, 49.09), (56.06, 48.89))]),\n",
       " ('twitter16',\n",
       "  [((71.34, 69.8), (71.34, 69.8)),\n",
       "   ('PHEME', (61.54, 60.14), (61.51, 60.11)),\n",
       "   ('twitter15', (52.78, 48.61), (53.12, 48.78))])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result3 = run_tests_multi(tests, 0.2, 200, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.25s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.22s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.26s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.30s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.24s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.27s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.28s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.5393258426966292]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/trial, best loss: 0.3932584269662921]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.50s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.19s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.24s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.54s/trial, best loss: 0.3820224719101124]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.40s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.45s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.3707865168539326]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.18s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.27s/trial, best loss: 0.3595505617977528]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/trial, best loss: 0.5955056179775281]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.35s/trial, best loss: 0.5955056179775281]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.5842696629213483]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.36s/trial, best loss: 0.5842696629213483]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.73s/trial, best loss: 0.5730337078651686]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.67s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.27s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.17s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.35s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.72s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.5168539325842696]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.5168539325842696]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.65s/trial, best loss: 0.6292134831460674]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.56s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.59s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.81s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 6/6 [00:33<00:00, 33.29s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 8/8 [00:03<00:00,  3.51s/trial, best loss: 0.6067415730337078]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.13s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.72s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.32s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.29s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 13/13 [00:14<00:00, 14.56s/trial, best loss: 0.550561797752809]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.14s/trial, best loss: 0.5056179775280899]\n",
      "100%|██████████| 15/15 [00:14<00:00, 14.02s/trial, best loss: 0.5056179775280899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.36s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.33s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.30s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.32s/trial, best loss: 0.4831460674157303]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.45s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.46s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.62s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.65s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.37s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.52s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.48s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.49s/trial, best loss: 0.449438202247191]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.21s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.31s/trial, best loss: 0.49606299212598426]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.44s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.33s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.25s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.28s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.24s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.23s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.23s/trial, best loss: 0.3228346456692913]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.3464566929133859]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.26s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.35s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.42s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.46s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.20s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.31s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.69s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.37s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.20s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.34s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.08s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.43s/trial, best loss: 0.31496062992125984]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.53s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.37s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.3858267716535433]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.59s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.17s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.3779527559055118]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.54s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.26s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.13s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.73s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.36s/trial, best loss: 0.3700787401574803]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.17s/trial, best loss: 0.3700787401574803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/trial, best loss: 0.5511811023622047]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.01s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.07s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.22s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.25s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.28s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.46s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.49s/trial, best loss: 0.5039370078740157]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.84s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 11/11 [00:17<00:00, 17.39s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.68s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.93s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 14/14 [00:11<00:00, 11.14s/trial, best loss: 0.4803149606299213]\n",
      "100%|██████████| 15/15 [00:13<00:00, 13.68s/trial, best loss: 0.4803149606299213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/trial, best loss: 0.4173228346456693]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.63s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.08s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.38s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.83s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.70s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.54s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.36s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.51s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.34s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.70s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.37s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.38s/trial, best loss: 0.3307086614173228]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.5660377358490566]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.24s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.20s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.17s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.17s/trial, best loss: 0.4716981132075472]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.19s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.29s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.17s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.16s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.20s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.27s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.17s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.24s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.28s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.31s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.32s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.27s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.33s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.58s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.23s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.50s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.33s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.30s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.45s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.65s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/trial, best loss: 0.5471698113207547]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.23s/trial, best loss: 0.5]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.5]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29s/trial, best loss: 0.5]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.62s/trial, best loss: 0.5]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.40s/trial, best loss: 0.5]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.28s/trial, best loss: 0.5]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.63s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.25s/trial, best loss: 0.42452830188679247]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.55s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.74s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.29s/trial, best loss: 0.41509433962264153]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.96s/trial, best loss: 0.41509433962264153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.31s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.39s/trial, best loss: 0.5754716981132075]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.39s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.33s/trial, best loss: 0.5377358490566038]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.22s/trial, best loss: 0.5283018867924528]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.20s/trial, best loss: 0.46226415094339623]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.19s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.29s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.21s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.22s/trial, best loss: 0.4528301886792453]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.18s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.17s/trial, best loss: 0.4339622641509434]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.24s/trial, best loss: 0.4339622641509434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.96s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.34s/trial, best loss: 0.4056603773584906]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.69s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.53s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.19s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.49s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.63s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.55s/trial, best loss: 0.39622641509433965]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.59s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.44s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.41s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.35s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.88s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.03s/trial, best loss: 0.3584905660377359]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.92s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.36s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.32s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.54s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.35s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.31s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.34s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.38s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.31s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.44s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.34s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.23s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.48s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.21s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.81s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.62s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.28s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.35s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.41s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.38s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.36s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.49s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.20s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.26s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.37s/trial, best loss: 0.40476190476190477]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.16s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.24s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.89s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.36s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.46s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.70s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.28s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.61s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.50s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.74s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.48s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.54s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.46s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 2/2 [00:07<00:00,  7.41s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 3/3 [00:03<00:00,  3.22s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.58s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.11s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 6/6 [00:16<00:00, 16.68s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.60s/trial, best loss: 0.5285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.74s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.19s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 11/11 [00:11<00:00, 11.98s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.57s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.29s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.64s/trial, best loss: 0.519047619047619]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.30s/trial, best loss: 0.519047619047619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/trial, best loss: 0.5761904761904761]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.59s/trial, best loss: 0.5571428571428572]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.12s/trial, best loss: 0.5238095238095238]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.73s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.68s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.97s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.57s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.80s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.45s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.19s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.15s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.45s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.15s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.53s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.5294117647058824]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.79s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.81s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.03s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.16s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.73s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.04s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.83s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.37s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.2941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.5028571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.48571428571428577]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.41714285714285715]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.15s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.35s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.33s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.01s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.25s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.79s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.4285714285714286]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.4285714285714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:30<00:00, 30.40s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.57s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 3/3 [00:13<00:00, 13.65s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.98s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 5/5 [01:34<00:00, 94.45s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.09s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 7/7 [00:10<00:00, 10.20s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.26s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.04s/trial, best loss: 0.4971428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.83s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 12/12 [00:22<00:00, 22.71s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 13/13 [00:11<00:00, 11.67s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 14/14 [00:04<00:00,  4.46s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.30s/trial, best loss: 0.43999999999999995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.70s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.94s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.15s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.06s/trial, best loss: 0.43999999999999995]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.83s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.06s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.40s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.84s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.4342857142857143]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.26582278481012656]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75s/trial, best loss: 0.40506329113924056]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.3291139240506329]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.72s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.2784810126582279]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.80s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.91s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.80s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.22784810126582278]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.22784810126582278]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.89s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 5/5 [00:10<00:00, 10.81s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 6/6 [00:03<00:00,  3.50s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.379746835443038]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.31645569620253167]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.31645569620253167]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.4177215189873418]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.85s/trial, best loss: 0.240506329113924]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.74s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.83s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.76s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.86s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.189873417721519]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.189873417721519]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4347826086956522]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.77s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.78s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.73s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.30434782608695654]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.26086956521739135]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.21739130434782605]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.62s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17391304347826086]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.17391304347826086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.34782608695652173]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.08695652173913049]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.08695652173913049]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.65s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.66s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.80s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.11764705882352944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.73s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.67s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.2941176470588235]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.74s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.3529411764705882]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.17647058823529416]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.4117647058823529]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:09<00:00, 135.68it/s]\n",
      "100%|██████████| 1491/1491 [00:15<00:00, 96.94it/s]\n",
      "100%|██████████| 817/817 [00:07<00:00, 111.46it/s]\n",
      " 33%|███▎      | 1/3 [32:18<1:04:36, 1938.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.4642857142857143]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.73s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.1428571428571429]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.1428571428571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.51s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.2678571428571429]\n",
      "100%|██████████| 12/12 [00:04<00:00,  4.93s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.2321428571428571]\n",
      "100%|██████████| 15/15 [00:04<00:00,  4.73s/trial, best loss: 0.2142857142857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.79s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.03s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.80s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.1785714285714286]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.1607142857142857]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.1607142857142857]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.73s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.74s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.34883720930232553]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.17441860465116277]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16279069767441856]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.75s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.71s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.70s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2441860465116279]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.86s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.76s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.36046511627906974]\n",
      "100%|██████████| 2/2 [00:14<00:00, 14.92s/trial, best loss: 0.34883720930232553]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.29s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.23s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.17s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.47s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.22093023255813948]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.22093023255813948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.90s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.84s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.30s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.83s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.74s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.53s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.96s/trial, best loss: 0.19767441860465118]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.16129032258064513]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.3709677419354839]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.3709677419354839]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.29032258064516125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.79s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.25806451612903225]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.24193548387096775]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.19354838709677424]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.17741935483870963]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.97s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.30645161290322576]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.09s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.01s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.63s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.77s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.02s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.27419354838709675]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.27419354838709675]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/trial, best loss: 0.20967741935483875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.76s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 13/13 [00:02<00:00,  2.01s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.85s/trial, best loss: 0.17741935483870963]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.66s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.2706766917293233]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.68s/trial, best loss: 0.26315789473684215]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.24060150375939848]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.04s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.03s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.21052631578947367]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.91s/trial, best loss: 0.2857142857142857]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.89s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.09s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.85s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.2556390977443609]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.18s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.21s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.43s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.78s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 11/11 [00:04<00:00,  4.38s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.03s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.3007518796992481]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.3007518796992481]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/trial, best loss: 0.29323308270676696]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.97s/trial, best loss: 0.27819548872180455]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.82s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.12s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.94s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.09s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.28s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.92s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.77s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.89s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.80s/trial, best loss: 0.18045112781954886]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.67s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.77s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.34745762711864403]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.3389830508474576]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.3389830508474576]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.90s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.68s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.89s/trial, best loss: 0.2627118644067796]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.65s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.2966101694915254]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.22033898305084743]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.22033898305084743]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.87s/trial, best loss: 0.211864406779661]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.30508474576271183]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.30508474576271183]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.03s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.2796610169491526]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.79s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.84s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.98s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.79s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.73s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.99s/trial, best loss: 0.27118644067796616]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/trial, best loss: 0.34745762711864403]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.31355932203389836]\n",
      "100%|██████████| 10/10 [00:25<00:00, 25.23s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 14/14 [00:10<00:00, 10.75s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2542372881355932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/trial, best loss: 0.288135593220339]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.78s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 5/5 [00:03<00:00,  3.09s/trial, best loss: 0.2542372881355932]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.2457627118644068]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.88s/trial, best loss: 0.23728813559322037]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.99s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.06s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.49s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.78s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.88s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.83s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.02s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.22881355932203384]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.82s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.75s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.77s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.84s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.85s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.68s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.2545454545454545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/trial, best loss: 0.4181818181818182]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.3090909090909091]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.47s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.76s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:04<00:00,  4.37s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.22s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.90s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.53s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.85s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.05s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.25s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.72s/trial, best loss: 0.2545454545454545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.34545454545454546]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2909090909090909]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.72s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.80s/trial, best loss: 0.2545454545454545]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.69s/trial, best loss: 0.23636363636363633]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.77s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.80s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.88s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.40s/trial, best loss: 0.18181818181818177]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.56s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.57s/trial, best loss: 0.3125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.3125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.3125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.3125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0625]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0625]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0625]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.3125]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.1875]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.1875]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.1875]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.1875]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.1875]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.125]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.125]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.125]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.125]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.70s/trial, best loss: 0.125]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.125]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.125]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.125]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.68s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.72s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.74s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.08333333333333337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.66s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.08333333333333337]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.08333333333333337]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/trial, best loss: 0.2727272727272727]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.18181818181818177]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.99s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.36363636363636365]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.69s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.09090909090909094]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.81s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (276) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (276) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:08<00:00, 35.77it/s]\n",
      "100%|██████████| 6425/6425 [03:16<00:00, 32.69it/s]\n",
      "100%|██████████| 817/817 [00:27<00:00, 29.37it/s]\n",
      " 67%|██████▋   | 2/3 [1:00:25<29:50, 1790.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.5588235294117647]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.20588235294117652]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.65s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.74s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.47058823529411764]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.32352941176470584]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.54s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.45s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 7/7 [00:09<00:00,  9.37s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.52s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.00s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.23529411764705888]\n",
      "100%|██████████| 15/15 [00:06<00:00,  6.85s/trial, best loss: 0.23529411764705888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.78s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.78s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.2647058823529411]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.4883720930232558]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.4418604651162791]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.62s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.73s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.18604651162790697]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.74s/trial, best loss: 0.3023255813953488]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.69s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.88s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.85s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.44s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.31s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.2093023255813954]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.91s/trial, best loss: 0.2093023255813954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.2558139534883721]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.66s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.94s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.70s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.91s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.72s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.05s/trial, best loss: 0.2325581395348837]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.1333333333333333]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0888888888888889]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.68s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.57s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.15555555555555556]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.72s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0444444444444444]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.76s/trial, best loss: 0.0444444444444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/trial, best loss: 0.1777777777777778]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.88s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 6/6 [00:06<00:00,  6.85s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.71s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 9/9 [00:03<00:00,  3.73s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.64s/trial, best loss: 0.11111111111111116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.76s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.74s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.75s/trial, best loss: 0.06666666666666665]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.14117647058823535]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.86s/trial, best loss: 0.21176470588235297]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.71s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.15294117647058825]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.94s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.68s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.65s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.71s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.67s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.91s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.81s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.81s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.12941176470588234]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/trial, best loss: 0.3176470588235294]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.2941176470588235]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.10s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:10<00:00, 10.45s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:14<00:00, 14.25s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.27s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.64s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16470588235294115]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16470588235294115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.81s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.79s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.75s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.73s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.72s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.77s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.25s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.11764705882352944]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.10588235294117643]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.03s/trial, best loss: 0.10588235294117643]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.31666666666666665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.31666666666666665]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.2833333333333333]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.70s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.68s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.70s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.67s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.77s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.79s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.68s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.15000000000000002]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.79s/trial, best loss: 0.2666666666666667]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.72s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.73s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.74s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.63s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.61s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.68s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.64s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.75s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.68s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.21666666666666667]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.53s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.90s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.67s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.56s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.23333333333333328]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.95s/trial, best loss: 0.23333333333333328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/trial, best loss: 0.30000000000000004]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.81s/trial, best loss: 0.25]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.77s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.78s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.64s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.83s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.92s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.09s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.76s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.94s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.83s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.31999999999999995]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.28]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.28]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.28]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.28]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.56]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.70s/trial, best loss: 0.52]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71s/trial, best loss: 0.52]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.48]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.71s/trial, best loss: 0.48]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.71s/trial, best loss: 0.48]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.72s/trial, best loss: 0.48]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.72s/trial, best loss: 0.48]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.48]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.48]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.4]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.4]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/trial, best loss: 0.4]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.58s/trial, best loss: 0.36]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70s/trial, best loss: 0.36]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.36]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.36]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.28]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.62s/trial, best loss: 0.28]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.56s/trial, best loss: 0.28]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.28]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.65s/trial, best loss: 0.28]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.28]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.28]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.28]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.63s/trial, best loss: 0.28]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.77s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 7/7 [00:03<00:00,  3.01s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.63s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.61s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16000000000000003]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.16000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.67s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.63s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.81s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.74s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.95s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.66s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.62s/trial, best loss: 0.19999999999999996]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.65s/trial, best loss: 0.19999999999999996]\n",
      "Skipped category: Internet & Telecom due to low numbers\n",
      "Skipped category: Computers & Electronics due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.70s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.73s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.71s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.72s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.5]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.93s/trial, best loss: 0.25]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.25]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.48s/trial, best loss: 0.25]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.25]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.25]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/trial, best loss: 0.375]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.61s/trial, best loss: 0.375]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.60s/trial, best loss: 0.375]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.375]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.65s/trial, best loss: 0.375]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.375]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.67s/trial, best loss: 0.375]\n",
      "Skipped category: Pets & Animals due to low numbers\n",
      "Skipped category: Reference due to low numbers\n",
      "Skipped category: Adult due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.65s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.84s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.68s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.73s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.56s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.61s/trial, best loss: 0.0]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.58s/trial, best loss: 0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.62s/trial, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.57s/trial, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.33333333333333337]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.65s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.66s/trial, best loss: 0.16666666666666663]\n",
      "Skipped category: Books & Literature due to low numbers\n",
      "Skipped category: Jobs & Education due to low numbers\n",
      "Skipped category: Shopping due to low numbers\n",
      "Skipped category: Beauty & Fitness due to low numbers\n",
      "Skipped category: Autos & Vehicles due to low numbers\n",
      "Skipped category: Science due to low numbers\n",
      "Skipped category: Finance due to low numbers\n",
      "Skipped category: Travel & Transportation due to low numbers\n",
      "Skipped category: Hobbies & Leisure due to low numbers\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.57s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.69s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.72s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/trial, best loss: 0.5]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.62s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.59s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.60s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.67s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.58s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.70s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.64s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.63s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.61s/trial, best loss: 0.16666666666666663]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.71s/trial, best loss: 0.16666666666666663]\n",
      "Skipped category: Games due to low numbers\n",
      "Skipped category: Home & Garden due to low numbers\n",
      "Skipped category: Real Estate due to low numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 56.63it/s]\n",
      "100%|██████████| 6425/6425 [01:20<00:00, 79.99it/s] \n",
      "100%|██████████| 1491/1491 [00:19<00:00, 75.06it/s]\n",
      "100%|██████████| 3/3 [1:24:28<00:00, 1689.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((67.47, 60.83), (67.63, 61.02)),\n",
       "   ('twitter15', (51.17, 43.71), (51.64, 44.4)),\n",
       "   ('twitter16', (54.71, 47.38), (55.08, 47.75))]),\n",
       " ('twitter15',\n",
       "  [((66.89, 64.47), (66.89, 64.47)),\n",
       "   ('PHEME', (61.56, 52.72), (61.46, 52.56)),\n",
       "   ('twitter16', (55.45, 49.17), (55.69, 49.45))]),\n",
       " ('twitter16',\n",
       "  [((68.9, 67.23), (68.9, 67.23)),\n",
       "   ('PHEME', (60.23, 58.71), (60.3, 58.82)),\n",
       "   ('twitter15', (53.79, 50.01), (53.52, 49.6))])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_result4 = run_tests_multi(tests, 0, 100, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_result1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willc\\Documents\\wills ensemble\\categorized_voters.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willc/Documents/wills%20ensemble/categorized_voters.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m multi_result1\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_result1' is not defined"
     ]
    }
   ],
   "source": [
    "multi_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1285 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:36<00:00, 34.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80.54, 77.7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = predict_points_mutiple_models(models, \"pheme_categories.json\", X_val)\n",
    "check_score(a, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [[pheme, \"pheme\", \"PHEME\"], [twitter15, \"twitter\", \"twitter15\"], [twitter16, \"twitter\", \"twitter16\"], [weibo, \"weibo\", \"weibo\"]]\n",
    "#r = get_results_multi(\"pheme\", 0.2, 50, pheme, tests, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.58s/trial, best loss: 0.3317120622568094]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/trial, best loss: 0.20622568093385218]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.63s/trial, best loss: 0.21400778210116733]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/trial, best loss: 0.24708171206225682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.96s/trial, best loss: 0.21108949416342415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 1/4 [01:11<03:33, 71.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/trial, best loss: 0.41841004184100417]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.2468619246861925]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/trial, best loss: 0.38912133891213385]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/trial, best loss: 0.3138075313807531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/trial, best loss: 0.20920502092050208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 2/4 [01:32<01:24, 42.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/trial, best loss: 0.3129770992366412]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/trial, best loss: 0.25190839694656486]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.19083969465648853]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/trial, best loss: 0.2137404580152672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/trial, best loss: 0.2137404580152672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 3/4 [02:12<00:40, 40.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/trial, best loss: 0.3793565683646113]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/trial, best loss: 0.36863270777479895]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/trial, best loss: 0.3672922252010724]\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.19s/trial, best loss: 0.37131367292225204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.69s/trial, best loss: 0.3552278820375335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\willc\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [04:56<00:00, 74.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# Multi baseline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc_mod*100)), float(\"{0:.2f}\".format(f1_mod*100))\n",
    "\n",
    "\n",
    "def run_baseline_tests(tests, model_list):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_baseline_results(train[0], tests, model_list)))\n",
    "    return test_results\n",
    "\n",
    "def get_baseline_results(train, tests, model_list): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_val_text = np.array([text for text in X_val['e_text']])\n",
    "    models = []\n",
    "    for model_name, model in model_list:\n",
    "        baseline_model = optimize_model(model, X_train_text, y_train)\n",
    "        sk_model = baseline_model.best_model()[\"learner\"].fit(X_train_text, y_train)\n",
    "        models.append((model_name, sk_model))\n",
    "\n",
    "    vc_hard = VotingClassifier(estimators=models, voting=\"hard\")\n",
    "    vc_hard = vc_hard.fit(X_train_text, y_train)\n",
    "    vc_soft = VotingClassifier(estimators=models, voting=\"soft\")\n",
    "    vc_soft.fit(X_train_text, y_train)\n",
    "\n",
    "    results = []\n",
    "    results.append((evaluate_baseline(vc_hard, X_val_text, y_val), evaluate_baseline(vc_soft, X_val_text, y_val)))\n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_data_text = np.array([text for text in test_data['e_text']])\n",
    "        test_target = test_set[\"target\"]\n",
    "        results.append((test_name, evaluate_baseline(vc_hard, test_data_text, test_target), evaluate_baseline(vc_soft, test_data_text, test_target),))\n",
    "    return results\n",
    "\n",
    "multi_baseline_results = run_baseline_tests(tests, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [((77.74, 74.39), (79.61, 77.6)),\n",
       "   ('PHEME', (85.45, 83.52), (93.29, 92.75)),\n",
       "   ('twitter15', (52.11, 46.02), (50.44, 46.21)),\n",
       "   ('twitter16', (61.44, 57.53), (63.4, 60.97)),\n",
       "   ('weibo', (50.47, 33.66), (50.77, 34.62))]),\n",
       " ('twitter15',\n",
       "  [((80.27, 80.25), (79.26, 79.26)),\n",
       "   ('PHEME', (60.09, 53.85), (58.26, 53.35)),\n",
       "   ('twitter15', (91.55, 91.54), (95.84, 95.84)),\n",
       "   ('twitter16', (58.26, 54.93), (60.47, 58.1)),\n",
       "   ('weibo', (45.71, 44.75), (46.59, 45.74))]),\n",
       " ('twitter16',\n",
       "  [((74.39, 74.29), (76.22, 76.15)),\n",
       "   ('PHEME', (54.27, 54.19), (53.32, 53.22)),\n",
       "   ('twitter15', (57.14, 57.03), (59.29, 59.1)),\n",
       "   ('twitter16', (91.06, 91.05), (94.61, 94.61)),\n",
       "   ('weibo', (49.44, 35.64), (46.83, 44.05))]),\n",
       " ('weibo',\n",
       "  [((65.27, 65.27), (63.24, 62.92)),\n",
       "   ('PHEME', (59.84, 43.72), (60.81, 41.54)),\n",
       "   ('twitter15', (49.56, 38.81), (49.36, 36.26)),\n",
       "   ('twitter16', (48.84, 38.2), (47.98, 34.56)),\n",
       "   ('weibo', (68.38, 68.38), (71.69, 71.51))])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.70s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 2/2 [00:08<00:00,  8.81s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 3/3 [00:05<00:00,  5.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 4/4 [00:06<00:00,  6.88s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 5/5 [00:06<00:00,  6.16s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 6/6 [00:08<00:00,  8.19s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 7/7 [00:12<00:00, 12.87s/trial, best loss: 0.1857976653696498]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.87s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 9/9 [00:08<00:00,  8.20s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.07s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 11/11 [00:06<00:00,  6.78s/trial, best loss: 0.18287937743190663]\n",
      "100%|██████████| 12/12 [00:07<00:00,  7.38s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 13/13 [00:05<00:00,  5.86s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 14/14 [00:08<00:00,  8.95s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 15/15 [00:06<00:00,  6.18s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 16/16 [00:06<00:00,  6.59s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 17/17 [00:06<00:00,  6.06s/trial, best loss: 0.17996108949416345]\n",
      "100%|██████████| 18/18 [00:06<00:00,  6.33s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 19/19 [00:06<00:00,  6.89s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 20/20 [00:06<00:00,  6.45s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 21/21 [00:06<00:00,  6.42s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 22/22 [00:06<00:00,  6.80s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 23/23 [00:05<00:00,  5.52s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 24/24 [00:06<00:00,  6.02s/trial, best loss: 0.15369649805447472]\n",
      "100%|██████████| 25/25 [00:06<00:00,  6.66s/trial, best loss: 0.15369649805447472]\n",
      "{'learner': SVC(C=1.2007340688965829, coef0=0.41195154588714744, degree=5, kernel='poly',\n",
      "    probability=True, random_state=42, tol=0.0021174726338347707), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:05<06:11, 185.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 4/4 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.19s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 10/10 [00:02<00:00,  2.14s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 11/11 [00:02<00:00,  2.07s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 12/12 [00:02<00:00,  2.21s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 14/14 [00:02<00:00,  2.16s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 15/15 [00:02<00:00,  2.06s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 16/16 [00:02<00:00,  2.03s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 17/17 [00:02<00:00,  2.02s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 18/18 [00:02<00:00,  2.20s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 19/19 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 20/20 [00:02<00:00,  2.12s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.15s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 22/22 [00:02<00:00,  2.09s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 23/23 [00:02<00:00,  2.04s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 24/24 [00:02<00:00,  2.13s/trial, best loss: 0.20502092050209209]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.97s/trial, best loss: 0.20502092050209209]\n",
      "{'learner': SVC(C=0.5853585639125682, coef0=0.9129795392049047,\n",
      "    decision_function_shape='ovo', degree=5, kernel='poly', probability=True,\n",
      "    random_state=42, tol=2.2560165272510383e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [03:59<01:48, 108.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.87s/trial, best loss: 0.33587786259541985]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.81s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.87s/trial, best loss: 0.2137404580152672]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 9/9 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 11/11 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.89s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.86s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 16/16 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 17/17 [00:01<00:00,  1.79s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 18/18 [00:01<00:00,  1.80s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 19/19 [00:01<00:00,  1.83s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 21/21 [00:01<00:00,  1.90s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 22/22 [00:01<00:00,  1.78s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.84s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 24/24 [00:01<00:00,  1.82s/trial, best loss: 0.1984732824427481]\n",
      "100%|██████████| 25/25 [00:01<00:00,  1.88s/trial, best loss: 0.1984732824427481]\n",
      "{'learner': SVC(C=0.9906379338992914, coef0=0.5764761568576748, degree=2, kernel='poly',\n",
      "    probability=True, random_state=42, shrinking=False,\n",
      "    tol=8.617804258277811e-05), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:46<00:00, 95.48s/it] \n"
     ]
    }
   ],
   "source": [
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    pred_y = model.predict(X_test)\n",
    "    acc_mod = accuracy_score(y_test, pred_y)\n",
    "    f1_mod = f1_score(y_test, pred_y, average=\"macro\")\n",
    "    return float(\"{0:.2f}\".format(acc_mod*100)), float(\"{0:.2f}\".format(f1_mod*100))\n",
    "\n",
    "\n",
    "def run_baseline_tests(tests):\n",
    "    test_results = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        t = tests.copy()\n",
    "        train = t.pop(i)\n",
    "        test_results.append((train[2], get_baseline_results(train[0], tests)))\n",
    "    return test_results\n",
    "\n",
    "def get_baseline_results(train, tests): \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train.drop(\"target\", axis=1), train[\"target\"], train_size=0.8, stratify=train[\"target\"]) \n",
    "    X_train_text = np.array([text for text in X_train['e_text']])\n",
    "    X_val_text = np.array([text for text in X_val['e_text']])\n",
    "    baseline = optimize_model(\"svm\", X_train_text, y_train)\n",
    "    results = []\n",
    "    results.append(evaluate_baseline(baseline, X_val_text, y_val))\n",
    "    for test_set, test_cat, test_name in tests:\n",
    "        test_data = test_set.drop(\"target\", axis=1)\n",
    "        test_data_text = np.array([text for text in test_data['e_text']])\n",
    "        test_target = test_set[\"target\"]\n",
    "        results.append((test_name, evaluate_baseline(baseline, test_data_text, test_target)))\n",
    "    return results\n",
    "\n",
    "baseline_results = run_baseline_tests(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHEME',\n",
       "  [(83.5, 82.24),\n",
       "   ('PHEME', (94.09, 93.64)),\n",
       "   ('twitter15', (50.17, 47.63)),\n",
       "   ('twitter16', (61.69, 59.78))]),\n",
       " ('twitter15',\n",
       "  [(81.61, 81.6),\n",
       "   ('PHEME', (55.7, 51.97)),\n",
       "   ('twitter15', (95.91, 95.91)),\n",
       "   ('twitter16', (62.3, 60.07))]),\n",
       " ('twitter16',\n",
       "  [(74.39, 74.39),\n",
       "   ('PHEME', (61.29, 60.87)),\n",
       "   ('twitter15', (56.2, 55.43)),\n",
       "   ('twitter16', (87.52, 87.52))])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v2\n",
    "\n",
    "def split_labels(categories):\n",
    "    \"\"\"The category labels are of the form \"/a/b/c\" up to three levels,\n",
    "    for example \"/Computers & Electronics/Software\", and these labels\n",
    "    are used as keys in the categories dictionary, whose values are\n",
    "    confidence scores.\n",
    "\n",
    "    The split_labels function splits the keys into individual levels\n",
    "    while duplicating the confidence score, which allows a natural\n",
    "    boost in how we calculate similarity when more levels are in common.\n",
    "\n",
    "    Example:\n",
    "    If we have\n",
    "\n",
    "    x = {\"/a/b/c\": 0.5}\n",
    "    y = {\"/a/b\": 0.5}\n",
    "    z = {\"/a\": 0.5}\n",
    "\n",
    "    Then x and y are considered more similar than y and z.\n",
    "    \"\"\"\n",
    "    _categories = {}\n",
    "    for name, confidence in categories.items():\n",
    "        labels = [label for label in name.split(\"/\") if label]\n",
    "        for label in labels:\n",
    "            _categories[label] = confidence\n",
    "\n",
    "    return _categories\n",
    "\n",
    "def similarity(categories1, categories2):\n",
    "    \"\"\"Cosine similarity of the categories treated as sparse vectors.\"\"\"\n",
    "    categories1 = split_labels(categories1)\n",
    "    categories2 = split_labels(categories2)\n",
    "\n",
    "    norm1 = np.linalg.norm(list(categories1.values()))\n",
    "    norm2 = np.linalg.norm(list(categories2.values()))\n",
    "\n",
    "    # Return the smallest possible similarity if either categories is empty.\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute the cosine similarity.\n",
    "    dot = 0.0\n",
    "    for label, confidence in categories1.items():\n",
    "        dot += confidence * categories2.get(label, 0.0)\n",
    "\n",
    "    return dot / (norm1 * norm2)\n",
    "\n",
    "def query_category(index_file, category_string, n_top=3):\n",
    "    \"\"\"Find the indexed files that are the most similar to\n",
    "    the query label.\n",
    "\n",
    "    The list of all available labels:\n",
    "    https://cloud.google.com/natural-language/docs/categories\n",
    "    \"\"\"\n",
    "\n",
    "    with open(index_file) as f:\n",
    "        index = json.load(f)\n",
    "\n",
    "    # Make the category_string into a dictionary so that it is\n",
    "    # of the same format as what we get by calling classify.\n",
    "    query_categories = {category_string: 1.0}\n",
    "\n",
    "    similarities = []\n",
    "    for filename, categories in index.items():\n",
    "        similarities.append((filename, similarity(query_categories, categories)))\n",
    "\n",
    "    similarities = sorted(similarities, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"Query: {category_string}\\n\")\n",
    "    print(f\"\\nMost similar {n_top} indexed texts:\")\n",
    "    for filename, sim in similarities[:n_top]:\n",
    "        print(f\"\\tFilename: {filename}\")\n",
    "        print(f\"\\tSimilarity: {sim}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Query: /Sensitive Subjects/War & Conflict\n",
      "\n",
      "\n",
      "Most similar 3 indexed texts:\n",
      "\tFilename: 1237\n",
      "\tSimilarity: 1.0\n",
      "\n",
      "\n",
      "\tFilename: 1488\n",
      "\tSimilarity: 1.0\n",
      "\n",
      "\n",
      "\tFilename: 1903\n",
      "\tSimilarity: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1237', 1.0),\n",
       " ('1488', 1.0),\n",
       " ('1903', 1.0),\n",
       " ('5264', 1.0),\n",
       " ('5987', 1.0),\n",
       " ('6088', 1.0),\n",
       " ('6090', 1.0),\n",
       " ('6225', 1.0),\n",
       " ('6229', 1.0),\n",
       " ('756', 0.9999999999999999),\n",
       " ('822', 0.9999999999999999),\n",
       " ('1555', 0.9999999999999999),\n",
       " ('5807', 0.9999999999999999),\n",
       " ('6035', 0.9999999999999999),\n",
       " ('6278', 0.9999999999999999),\n",
       " ('6387', 0.9999999999999999),\n",
       " ('2958', 0.9999999999999998),\n",
       " ('6354', 0.9999999999999998),\n",
       " ('2011', 0.9925923625058777),\n",
       " ('1032', 0.9888405779372219),\n",
       " ('673', 0.9877442987416001),\n",
       " ('1052', 0.9864248730334662),\n",
       " ('637', 0.9861404034204636),\n",
       " ('393', 0.9847656506068245),\n",
       " ('1105', 0.982740365017687),\n",
       " ('358', 0.9818058933951872),\n",
       " ('1061', 0.9810378341043879),\n",
       " ('1606', 0.9801032698929284),\n",
       " ('5233', 0.9794738480193588),\n",
       " ('2748', 0.9789070644290978),\n",
       " ('242', 0.9781137327105758),\n",
       " ('1430', 0.9778237680583077),\n",
       " ('5354', 0.9760385139052788),\n",
       " ('2008', 0.975973967626339),\n",
       " ('215', 0.975553502588769),\n",
       " ('2063', 0.9752697579970404),\n",
       " ('136', 0.9746139831189184),\n",
       " ('143', 0.9737571469431453),\n",
       " ('1114', 0.9737567177595979),\n",
       " ('1343', 0.9735997435148678),\n",
       " ('1676', 0.9717418124253712),\n",
       " ('265', 0.971246839319809),\n",
       " ('5783', 0.9712069539431799),\n",
       " ('461', 0.9701447133543584),\n",
       " ('1020', 0.9696658816277435),\n",
       " ('5612', 0.969416593976783),\n",
       " ('827', 0.9691900096968813),\n",
       " ('6307', 0.9687094411317057),\n",
       " ('6029', 0.9681751390620402),\n",
       " ('1570', 0.967340121117833),\n",
       " ('665', 0.9669041225895524),\n",
       " ('1576', 0.9661289877332105),\n",
       " ('729', 0.965987578785266),\n",
       " ('1268', 0.965428931911503),\n",
       " ('5753', 0.9646312776468479),\n",
       " ('5982', 0.9644528647146251),\n",
       " ('123', 0.9623744611545951),\n",
       " ('613', 0.9619538499374506),\n",
       " ('1954', 0.9617325681677692),\n",
       " ('508', 0.9615700851656065),\n",
       " ('1924', 0.9615677012371663),\n",
       " ('500', 0.9613636069801833),\n",
       " ('944', 0.9604543259940479),\n",
       " ('2000', 0.9601610871007309),\n",
       " ('1406', 0.960148006846078),\n",
       " ('2047', 0.9600683102339251),\n",
       " ('1934', 0.9563412300785417),\n",
       " ('6344', 0.955670577390817),\n",
       " ('911', 0.9555937097008104),\n",
       " ('513', 0.9554504243116294),\n",
       " ('853', 0.955381244865006),\n",
       " ('1377', 0.9548758466368752),\n",
       " ('941', 0.954828776516568),\n",
       " ('5327', 0.9540714826950525),\n",
       " ('1279', 0.9539201651943473),\n",
       " ('758', 0.9536016161049516),\n",
       " ('623', 0.9526900077144833),\n",
       " ('519', 0.9526601848226108),\n",
       " ('6162', 0.9519998934056993),\n",
       " ('792', 0.9508753383403538),\n",
       " ('5286', 0.950328013803754),\n",
       " ('518', 0.9500380527469777),\n",
       " ('1792', 0.9499436629495333),\n",
       " ('724', 0.9490754520444399),\n",
       " ('1948', 0.9488788780763225),\n",
       " ('5225', 0.9487829663990753),\n",
       " ('1159', 0.9485474317938125),\n",
       " ('63', 0.9484985919171791),\n",
       " ('1483', 0.9484969674494469),\n",
       " ('5576', 0.9483012671354456),\n",
       " ('1383', 0.9471276546649918),\n",
       " ('511', 0.9467780800304963),\n",
       " ('563', 0.946462261716836),\n",
       " ('5940', 0.9459229313255292),\n",
       " ('2020', 0.9457524993833094),\n",
       " ('2378', 0.9455338747397934),\n",
       " ('1057', 0.9451301072470929),\n",
       " ('1330', 0.9445531214463413),\n",
       " ('6308', 0.9432995534937085),\n",
       " ('197', 0.9432248168596906),\n",
       " ('547', 0.9427425682917202),\n",
       " ('27', 0.942678853808983),\n",
       " ('1297', 0.9424782269083261),\n",
       " ('4100', 0.9401891337497278),\n",
       " ('1758', 0.9401093224182382),\n",
       " ('142', 0.9400777323745807),\n",
       " ('2885', 0.9390131994932885),\n",
       " ('1361', 0.9383265375949866),\n",
       " ('1691', 0.9365122777860022),\n",
       " ('1902', 0.9359692444260888),\n",
       " ('6005', 0.9359198555420374),\n",
       " ('1045', 0.935776021116983),\n",
       " ('1062', 0.9345975718068555),\n",
       " ('1193', 0.9345668695455387),\n",
       " ('1673', 0.9343792465962903),\n",
       " ('834', 0.9342241214490534),\n",
       " ('1895', 0.9339988752601098),\n",
       " ('2485', 0.9338218826643995),\n",
       " ('746', 0.933788163713771),\n",
       " ('790', 0.9331781172015929),\n",
       " ('1056', 0.9328493024400725),\n",
       " ('1426', 0.9327237673381089),\n",
       " ('1795', 0.932435590637432),\n",
       " ('5984', 0.9322143319197349),\n",
       " ('776', 0.9318868865690987),\n",
       " ('512', 0.9313948102362074),\n",
       " ('1978', 0.9305891978333015),\n",
       " ('1946', 0.927653931211267),\n",
       " ('6282', 0.9266221341924913),\n",
       " ('893', 0.9263914920476805),\n",
       " ('1652', 0.9262251128779756),\n",
       " ('1743', 0.9260524264138449),\n",
       " ('127', 0.9259283360528329),\n",
       " ('6182', 0.9257983719151455),\n",
       " ('735', 0.9257031290637138),\n",
       " ('1844', 0.9235503522437304),\n",
       " ('5407', 0.9234254905696102),\n",
       " ('1471', 0.9218439280570584),\n",
       " ('506', 0.9208001600676021),\n",
       " ('6318', 0.9206686794707656),\n",
       " ('538', 0.9202751296191187),\n",
       " ('2043', 0.9195899645180663),\n",
       " ('1021', 0.9192688857209352),\n",
       " ('5206', 0.9190057349661769),\n",
       " ('5235', 0.9189339607769719),\n",
       " ('5938', 0.9187129667998812),\n",
       " ('1306', 0.9182488761508344),\n",
       " ('6007', 0.9181980678036956),\n",
       " ('824', 0.9169318806989402),\n",
       " ('1450', 0.9163104337828311),\n",
       " ('522', 0.9161134211019486),\n",
       " ('619', 0.9154690546063192),\n",
       " ('2266', 0.9145145620861148),\n",
       " ('5735', 0.9142150841720351),\n",
       " ('1123', 0.9140854463729352),\n",
       " ('1874', 0.9132896571504253),\n",
       " ('5403', 0.9116617121457425),\n",
       " ('1384', 0.9110931659380123),\n",
       " ('2797', 0.9106068387349461),\n",
       " ('858', 0.9105724454262633),\n",
       " ('655', 0.9100874724437706),\n",
       " ('6235', 0.9098422497773759),\n",
       " ('1194', 0.909712277908178),\n",
       " ('66', 0.9087358664286943),\n",
       " ('593', 0.9082361288624589),\n",
       " ('964', 0.9058739182642551),\n",
       " ('6096', 0.9051096895851591),\n",
       " ('2016', 0.9045338535209357),\n",
       " ('1726', 0.9045318242053481),\n",
       " ('1672', 0.9022561706455736),\n",
       " ('1047', 0.9011660136722484),\n",
       " ('1455', 0.9000801665762818),\n",
       " ('2071', 0.8985091699885008),\n",
       " ('974', 0.8984215472134423),\n",
       " ('6107', 0.8973620250899279),\n",
       " ('5920', 0.8972213821268544),\n",
       " ('1438', 0.8961972946911105),\n",
       " ('550', 0.8961780390669426),\n",
       " ('1178', 0.8958183751694596),\n",
       " ('1512', 0.8913446458876175),\n",
       " ('1682', 0.8907863059877885),\n",
       " ('584', 0.8906334941127552),\n",
       " ('478', 0.8899470191595742),\n",
       " ('805', 0.888828879693493),\n",
       " ('175', 0.8873930429445354),\n",
       " ('1283', 0.8873773630653651),\n",
       " ('2269', 0.8857782222015739),\n",
       " ('1859', 0.884578646122855),\n",
       " ('6124', 0.8812735165774441),\n",
       " ('1364', 0.8792809820121574),\n",
       " ('779', 0.8776961114418165),\n",
       " ('259', 0.8774874765004805),\n",
       " ('556', 0.8754712554792539),\n",
       " ('470', 0.8743411397464617),\n",
       " ('936', 0.8740764170537008),\n",
       " ('4141', 0.8740593886096449),\n",
       " ('774', 0.8738075053176994),\n",
       " ('238', 0.873360180857282),\n",
       " ('731', 0.8733024757313123),\n",
       " ('2928', 0.8719000831311681),\n",
       " ('1892', 0.871666816399487),\n",
       " ('472', 0.8713968005061014),\n",
       " ('4131', 0.871216304473834),\n",
       " ('640', 0.8700554658592734),\n",
       " ('1629', 0.8694615616613698),\n",
       " ('499', 0.8692413026724484),\n",
       " ('1253', 0.869151145689536),\n",
       " ('1546', 0.8690504524838691),\n",
       " ('97', 0.868279383442789),\n",
       " ('491', 0.8657080523893731),\n",
       " ('144', 0.8645911253344041),\n",
       " ('2962', 0.8639965852159344),\n",
       " ('1498', 0.8637626204684369),\n",
       " ('510', 0.8628421872187498),\n",
       " ('6', 0.8627736186143559),\n",
       " ('1587', 0.8605603528275302),\n",
       " ('2019', 0.8592858486766194),\n",
       " ('5898', 0.8587306362561092),\n",
       " ('1432', 0.8579054990615822),\n",
       " ('1790', 0.8567102809624323),\n",
       " ('5319', 0.8543297159753632),\n",
       " ('6202', 0.8538987340930428),\n",
       " ('5554', 0.8520827699343649),\n",
       " ('6298', 0.8515421212117763),\n",
       " ('1036', 0.8502367362441158),\n",
       " ('90', 0.8488823285101067),\n",
       " ('435', 0.8478901914487097),\n",
       " ('165', 0.8476063606075633),\n",
       " ('1842', 0.8458872257555544),\n",
       " ('5891', 0.8455485357860187),\n",
       " ('748', 0.8413605667810634),\n",
       " ('767', 0.8406586144771065),\n",
       " ('1214', 0.8402079800017829),\n",
       " ('1977', 0.8391217313519616),\n",
       " ('5305', 0.838374633624804),\n",
       " ('902', 0.8381435958800356),\n",
       " ('208', 0.836546480562728),\n",
       " ('630', 0.835805251327365),\n",
       " ('1411', 0.8357469093193657),\n",
       " ('1373', 0.8352992933371802),\n",
       " ('6263', 0.834864242265426),\n",
       " ('1286', 0.8337514828989553),\n",
       " ('5299', 0.832196928067605),\n",
       " ('1385', 0.831853297251264),\n",
       " ('784', 0.8315349822547263),\n",
       " ('976', 0.8306322189718718),\n",
       " ('838', 0.8305479528534193),\n",
       " ('6121', 0.8304262749048784),\n",
       " ('479', 0.8290041951731639),\n",
       " ('467', 0.8287803539508708),\n",
       " ('685', 0.828780332156461),\n",
       " ('749', 0.8285256835903685),\n",
       " ('5928', 0.82764145747093),\n",
       " ('5221', 0.8270319116944481),\n",
       " ('5257', 0.8248363919252056),\n",
       " ('5437', 0.8240007404100252),\n",
       " ('4278', 0.8233242507975053),\n",
       " ('4264', 0.8233064761428127),\n",
       " ('5882', 0.8230825379818962),\n",
       " ('1836', 0.8227902282569994),\n",
       " ('635', 0.8213534181014769),\n",
       " ('1337', 0.8208868650204005),\n",
       " ('5550', 0.8205883982562017),\n",
       " ('6192', 0.8197247652006567),\n",
       " ('2012', 0.8195620442992165),\n",
       " ('29', 0.8195116707936342),\n",
       " ('5272', 0.8188015557753894),\n",
       " ('2458', 0.8181046750137086),\n",
       " ('6087', 0.8174464742071335),\n",
       " ('2025', 0.8174081798963975),\n",
       " ('403', 0.817389501143294),\n",
       " ('1100', 0.8164836443852163),\n",
       " ('1998', 0.8149477186233817),\n",
       " ('1136', 0.8143013170886584),\n",
       " ('451', 0.8140775762202973),\n",
       " ('1702', 0.814075001104839),\n",
       " ('366', 0.8140336353372901),\n",
       " ('40', 0.8138618495140518),\n",
       " ('5215', 0.8136944674174336),\n",
       " ('618', 0.8136799860580559),\n",
       " ('400', 0.8132278812934843),\n",
       " ('2006', 0.8132005768202099),\n",
       " ('1144', 0.812956897290334),\n",
       " ('406', 0.8125020133373864),\n",
       " ('1923', 0.8124893296817238),\n",
       " ('1110', 0.8118494432223444),\n",
       " ('5208', 0.8113945976873008),\n",
       " ('240', 0.8110776771098694),\n",
       " ('5966', 0.811043921554066),\n",
       " ('436', 0.8109309654089555),\n",
       " ('442', 0.8109309654089555),\n",
       " ('450', 0.8109309654089555),\n",
       " ('1942', 0.8108922395375359),\n",
       " ('1656', 0.8107496957541132),\n",
       " ('1523', 0.81004539830911),\n",
       " ('402', 0.8098295309846782),\n",
       " ('272', 0.8091085483157898),\n",
       " ('5238', 0.808641206240398),\n",
       " ('5992', 0.8085559472736119),\n",
       " ('1558', 0.8080792411917521),\n",
       " ('1828', 0.8077129587835449),\n",
       " ('405', 0.8069909350504877),\n",
       " ('1415', 0.8065875212018258),\n",
       " ('1761', 0.8064637161949906),\n",
       " ('5559', 0.8061513274719659),\n",
       " ('1801', 0.8059187185181743),\n",
       " ('5821', 0.8057695575340443),\n",
       " ('349', 0.8055383118402747),\n",
       " ('1223', 0.804665502679487),\n",
       " ('2013', 0.8042808072875004),\n",
       " ('30', 0.803911130160162),\n",
       " ('650', 0.8032321477562505),\n",
       " ('690', 0.8028340938600748),\n",
       " ('1886', 0.8027764935450525),\n",
       " ('380', 0.8003404677143598),\n",
       " ('244', 0.8003401556417015),\n",
       " ('979', 0.8002153036010637),\n",
       " ('1420', 0.7998891262806744),\n",
       " ('1608', 0.7997964629371382),\n",
       " ('1965', 0.7997964629371382),\n",
       " ('233', 0.7994162462135515),\n",
       " ('6114', 0.7990864867470528),\n",
       " ('1244', 0.7990570178809554),\n",
       " ('1474', 0.7990570178809554),\n",
       " ('5480', 0.7990040267753994),\n",
       " ('5304', 0.7988096196881426),\n",
       " ('1564', 0.7986398831498503),\n",
       " ('1962', 0.7983035261690564),\n",
       " ('1563', 0.7980833153356058),\n",
       " ('852', 0.797981278208734),\n",
       " ('681', 0.7978990678947699),\n",
       " ('537', 0.7973344664248255),\n",
       " ('2457', 0.7973048527446011),\n",
       " ('5439', 0.7965459558820999),\n",
       " ('2072', 0.7962521886551881),\n",
       " ('270', 0.7961825525825588),\n",
       " ('1065', 0.7961480510149511),\n",
       " ('733', 0.7956701560284387),\n",
       " ('1034', 0.7955988965613104),\n",
       " ('374', 0.7954952638293824),\n",
       " ('1945', 0.7952700999827936),\n",
       " ('5513', 0.7951661564119635),\n",
       " ('228', 0.7951403653462421),\n",
       " ('1989', 0.7949804150374592),\n",
       " ('5361', 0.7948134197465417),\n",
       " ('288', 0.794652583118703),\n",
       " ('6376', 0.7943870529604834),\n",
       " ('159', 0.7940027761792249),\n",
       " ('2017', 0.7936559155793498),\n",
       " ('1727', 0.7927973734237969),\n",
       " ('224', 0.7927552679286346),\n",
       " ('2015', 0.790836801996754),\n",
       " ('5957', 0.7908365197435712),\n",
       " ('2262', 0.7902329080160116),\n",
       " ('1817', 0.7900610162380001),\n",
       " ('5432', 0.7896113621878191),\n",
       " ('191', 0.7896088600048391),\n",
       " ('1990', 0.7896049530740287),\n",
       " ('5764', 0.7893956205739856),\n",
       " ('1027', 0.7891424323642771),\n",
       " ('1585', 0.7884945455102956),\n",
       " ('306', 0.7883753317769249),\n",
       " ('689', 0.7875433715045247),\n",
       " ('601', 0.787336856669266),\n",
       " ('5521', 0.787147996592149),\n",
       " ('5565', 0.7869329462233232),\n",
       " ('516', 0.7869048886016682),\n",
       " ('5687', 0.7868750241199177),\n",
       " ('5531', 0.7868159828418665),\n",
       " ('4511', 0.7863209739656873),\n",
       " ('1645', 0.7860270679513126),\n",
       " ('212', 0.7858476965873792),\n",
       " ('1818', 0.7856309848287493),\n",
       " ('2029', 0.7855781542241606),\n",
       " ('1855', 0.7850482441646052),\n",
       " ('77', 0.7850328998480111),\n",
       " ('2004', 0.7849952469259507),\n",
       " ('1940', 0.784965637721727),\n",
       " ('1129', 0.7845887687061284),\n",
       " ('1971', 0.784548214730426),\n",
       " ('61', 0.784474219463586),\n",
       " ('1216', 0.78346956913634),\n",
       " ('6031', 0.7833997408803628),\n",
       " ('5588', 0.7831622419386012),\n",
       " ('1156', 0.7830374841834427),\n",
       " ('1332', 0.7828062156132796),\n",
       " ('5563', 0.7826907578325573),\n",
       " ('1534', 0.7826181292724056),\n",
       " ('5291', 0.7821951483400623),\n",
       " ('6334', 0.7821436987592503),\n",
       " ('764', 0.7821027233510773),\n",
       " ('5240', 0.781922390953591),\n",
       " ('5250', 0.7818835691657693),\n",
       " ('1425', 0.7814473513727135),\n",
       " ('23', 0.7811234859348587),\n",
       " ('263', 0.7808537508793731),\n",
       " ('1641', 0.7800640036037166),\n",
       " ('495', 0.7790869461988114),\n",
       " ('5382', 0.7790382659589578),\n",
       " ('5399', 0.7785893017596335),\n",
       " ('1697', 0.7785750022257532),\n",
       " ('1919', 0.7782075371862938),\n",
       " ('382', 0.7779711009763113),\n",
       " ('1938', 0.7779251620985083),\n",
       " ('1263', 0.7778792947739029),\n",
       " ('188', 0.7778792942121096),\n",
       " ('797', 0.777845660163189),\n",
       " ('1974', 0.7773542028332646),\n",
       " ('138', 0.7766492254755846),\n",
       " ('1985', 0.776227342128666),\n",
       " ('1500', 0.7758181085337141),\n",
       " ('906', 0.7755793330523839),\n",
       " ('2014', 0.7754559000538759),\n",
       " ('1221', 0.7752757550919123),\n",
       " ('275', 0.7752249809214398),\n",
       " ('1076', 0.7752136603654184),\n",
       " ('1901', 0.7751971005887865),\n",
       " ('1004', 0.7749307782515636),\n",
       " ('6386', 0.7747740660117445),\n",
       " ('2022', 0.7738973250544934),\n",
       " ('6395', 0.7735669874347497),\n",
       " ('5894', 0.7735628171971123),\n",
       " ('5689', 0.7733319869422978),\n",
       " ('611', 0.773035785677082),\n",
       " ('819', 0.7718568212887846),\n",
       " ('1935', 0.7718405680235509),\n",
       " ('5269', 0.7716990445075365),\n",
       " ('256', 0.771652311312842),\n",
       " ('1089', 0.7715081129913318),\n",
       " ('5690', 0.7710242017016001),\n",
       " ('6295', 0.7709345127725723),\n",
       " ('177', 0.7708590107297457),\n",
       " ('821', 0.7708590107297457),\n",
       " ('1320', 0.7704840871836758),\n",
       " ('157', 0.7702936573346769),\n",
       " ('180', 0.7702936542737301),\n",
       " ('5222', 0.7702894738641536),\n",
       " ('531', 0.7702178861767759),\n",
       " ('857', 0.7701087564865532),\n",
       " ('348', 0.7700674664440108),\n",
       " ('1305', 0.7698913548854008),\n",
       " ('1997', 0.7693931353725652),\n",
       " ('1890', 0.7692795585456333),\n",
       " ('984', 0.7692168255817526),\n",
       " ('1307', 0.7690881279179248),\n",
       " ('5227', 0.769016904654251),\n",
       " ('1832', 0.768984196335027),\n",
       " ('763', 0.7689828706300917),\n",
       " ('444', 0.7689171366470766),\n",
       " ('5877', 0.7687353142723722),\n",
       " ('6317', 0.7679654049863339),\n",
       " ('420', 0.7679618501407862),\n",
       " ('1054', 0.767776203197662),\n",
       " ('5398', 0.7677365553067376),\n",
       " ('6335', 0.7676444195625398),\n",
       " ('2050', 0.7675236534770554),\n",
       " ('26', 0.7672772102878865),\n",
       " ('41', 0.7670929877209284),\n",
       " ('1693', 0.76690434982752),\n",
       " ('1525', 0.7668395420844704),\n",
       " ('110', 0.7668257155907426),\n",
       " ('5625', 0.7665534042666052),\n",
       " ('59', 0.7663372893708548),\n",
       " ('670', 0.7659994156363351),\n",
       " ('1580', 0.765720124483557),\n",
       " ('48', 0.7656663681851701),\n",
       " ('554', 0.7655959467436475),\n",
       " ('5675', 0.7653096170735437),\n",
       " ('49', 0.765249834112297),\n",
       " ('1311', 0.7652206567637435),\n",
       " ('1816', 0.7650802928708152),\n",
       " ('297', 0.7648781639691447),\n",
       " ('260', 0.7647111985619743),\n",
       " ('1463', 0.7645392824880795),\n",
       " ('93', 0.7642576397860477),\n",
       " ('1690', 0.7641704685146452),\n",
       " ('73', 0.7641028825658019),\n",
       " ('32', 0.7640507450544006),\n",
       " ('5417', 0.7638789446965782),\n",
       " ('50', 0.7637340939420071),\n",
       " ('972', 0.7632315070927825),\n",
       " ('1812', 0.7631583674192),\n",
       " ('431', 0.7631272689941424),\n",
       " ('488', 0.7630567638287769),\n",
       " ('998', 0.7628722317614152),\n",
       " ('407', 0.7626622908263405),\n",
       " ('1141', 0.7626354492792977),\n",
       " ('31', 0.7624513501424313),\n",
       " ('5294', 0.7624478139006663),\n",
       " ('1149', 0.7623264975209698),\n",
       " ('2031', 0.7619759731240406),\n",
       " ('5888', 0.7614544194108419),\n",
       " ('1679', 0.7613039828534846),\n",
       " ('682', 0.7612335992892241),\n",
       " ('47', 0.7607594928441687),\n",
       " ('5309', 0.7607412925471619),\n",
       " ('5990', 0.7603411222856455),\n",
       " ('5322', 0.759802052290826),\n",
       " ('350', 0.7596846274327473),\n",
       " ('6355', 0.7595163431744582),\n",
       " ('1172', 0.7595121635941988),\n",
       " ('139', 0.7592405273233931),\n",
       " ('962', 0.7591017012491497),\n",
       " ('5852', 0.7588400593670318),\n",
       " ('726', 0.7587578771035713),\n",
       " ('5229', 0.7584179547335652),\n",
       " ('2005', 0.7583467103927609),\n",
       " ('1835', 0.7582694929561916),\n",
       " ('5378', 0.7582372904794077),\n",
       " ('422', 0.7582317790963179),\n",
       " ('6361', 0.7582141924244129),\n",
       " ('798', 0.7581588024371173),\n",
       " ('101', 0.7580235640521844),\n",
       " ('6039', 0.7579259701273149),\n",
       " ('1671', 0.7578879513111245),\n",
       " ('1858', 0.7576045518810627),\n",
       " ('5571', 0.7575456095050778),\n",
       " ('597', 0.7573792045681524),\n",
       " ('1807', 0.7573490104021205),\n",
       " ('6253', 0.7569518910422075),\n",
       " ('5288', 0.7568164131262619),\n",
       " ('841', 0.7561751574580006),\n",
       " ('1905', 0.7560769995072089),\n",
       " ('2039', 0.7559601620010893),\n",
       " ('5567', 0.7553792378122454),\n",
       " ('494', 0.7549726365571472),\n",
       " ('1367', 0.7548382753423594),\n",
       " ('6301', 0.7543569036882345),\n",
       " ('1700', 0.7539197860269297),\n",
       " ('6373', 0.7535678597113422),\n",
       " ('6338', 0.7535215802099567),\n",
       " ('1833', 0.7534624917026983),\n",
       " ('1809', 0.7532625101764985),\n",
       " ('950', 0.7529128279818609),\n",
       " ('919', 0.7528564751853796),\n",
       " ('447', 0.7523818458248057),\n",
       " ('264', 0.7522780743890227),\n",
       " ('5278', 0.7520887152504138),\n",
       " ('37', 0.7519774445126916),\n",
       " ('992', 0.7517365564284366),\n",
       " ('1669', 0.7516787556533188),\n",
       " ('1295', 0.7515484913943995),\n",
       " ('24', 0.7515200483803107),\n",
       " ('338', 0.7513405762403383),\n",
       " ('2437', 0.7510132390458024),\n",
       " ('973', 0.750879448374595),\n",
       " ('6238', 0.7502442825678944),\n",
       " ('536', 0.7500829255102),\n",
       " ('658', 0.7500020791770338),\n",
       " ('384', 0.7495162167576749),\n",
       " ('5861', 0.7490208574298287),\n",
       " ('437', 0.7489337652725485),\n",
       " ('295', 0.7487852811834679),\n",
       " ('189', 0.7487699747417691),\n",
       " ('1748', 0.748720909344865),\n",
       " ('1204', 0.7485167048387137),\n",
       " ('1868', 0.7484737800068441),\n",
       " ('365', 0.7484207478799623),\n",
       " ('163', 0.7480764531602886),\n",
       " ('795', 0.7476560566694985),\n",
       " ('5329', 0.747592487621375),\n",
       " ('1530', 0.7470072238155924),\n",
       " ('428', 0.746987782480624),\n",
       " ('187', 0.7469077974252051),\n",
       " ('567', 0.7469024371928127),\n",
       " ('2001', 0.7468801276171421),\n",
       " ('392', 0.7466565770206869),\n",
       " ('2021', 0.7464949726679052),\n",
       " ('130', 0.7463446495806279),\n",
       " ('1621', 0.7462553293459604),\n",
       " ('5973', 0.7458521602665554),\n",
       " ('1326', 0.7456921729367094),\n",
       " ('343', 0.7455885232827835),\n",
       " ('1287', 0.7455323301358496),\n",
       " ('1000', 0.7452677206342387),\n",
       " ('1653', 0.7450851355530062),\n",
       " ('269', 0.7448788827361781),\n",
       " ('1390', 0.7446817301106022),\n",
       " ('5748', 0.7446254692000936),\n",
       " ('2760', 0.7445056736397394),\n",
       " ('2035', 0.7444670834323094),\n",
       " ('2003', 0.7443684580976734),\n",
       " ('285', 0.7441984045565333),\n",
       " ('808', 0.7439828456523322),\n",
       " ('1797', 0.7437584202973231),\n",
       " ('6366', 0.7437323314991672),\n",
       " ('268', 0.7436751271704146),\n",
       " ('226', 0.743557676074857),\n",
       " ('1068', 0.7435330909432515),\n",
       " ('1880', 0.743346355161919),\n",
       " ('1959', 0.7431088418558693),\n",
       " ('2435', 0.7430703973566596),\n",
       " ('5749', 0.7430416778394912),\n",
       " ('1075', 0.7429502439046752),\n",
       " ('399', 0.742926463162646),\n",
       " ('315', 0.7429134368618118),\n",
       " ('5211', 0.7423653512139313),\n",
       " ('5331', 0.7422708768975036),\n",
       " ('1074', 0.7421366744298361),\n",
       " ('815', 0.7419884138286209),\n",
       " ('580', 0.7419443831272764),\n",
       " ('284', 0.7417275714824013),\n",
       " ('5438', 0.7415145480391585),\n",
       " ('638', 0.7412983820058443),\n",
       " ('5499', 0.7412145897007689),\n",
       " ('279', 0.741110473944605),\n",
       " ('6383', 0.7410173422180046),\n",
       " ('1467', 0.7409099852053068),\n",
       " ('51', 0.7408043774577178),\n",
       " ('2314', 0.7406124935076691),\n",
       " ('1596', 0.7401884727545195),\n",
       " ('1972', 0.7400672089130391),\n",
       " ('571', 0.7400132349604677),\n",
       " ('1529', 0.7397788414886215),\n",
       " ('2811', 0.7395812081156722),\n",
       " ('2062', 0.7395647724452507),\n",
       " ('5345', 0.739483871994719),\n",
       " ('140', 0.7388889140108634),\n",
       " ('1468', 0.7386783628006345),\n",
       " ('1016', 0.7386176289853672),\n",
       " ('1138', 0.7385463997711824),\n",
       " ('196', 0.7385305002161078),\n",
       " ('1207', 0.7384311092855692),\n",
       " ('1445', 0.7384310905687778),\n",
       " ('468', 0.7383427601829133),\n",
       " ('686', 0.7382099185086816),\n",
       " ('243', 0.7380261760689454),\n",
       " ('449', 0.7379884125348635),\n",
       " ('1966', 0.7379299897684746),\n",
       " ('87', 0.7379123511288238),\n",
       " ('856', 0.7378174368700056),\n",
       " ('1386', 0.7376720952137221),\n",
       " ('257', 0.7376607571733242),\n",
       " ('835', 0.7376221509683877),\n",
       " ('2248', 0.7375647474793818),\n",
       " ('1049', 0.7375610345573609),\n",
       " ('4517', 0.7374072104895216),\n",
       " ('21', 0.7372921982210463),\n",
       " ('1914', 0.7372142049957044),\n",
       " ('1757', 0.7370485238169249),\n",
       " ('17', 0.7370406453334994),\n",
       " ('283', 0.7365298568243219),\n",
       " ('1375', 0.7362913608217776),\n",
       " ('1839', 0.7362223445088869),\n",
       " ('975', 0.7361605638527391),\n",
       " ('5339', 0.7361290351230559),\n",
       " ('10', 0.7358471919495008),\n",
       " ('1513', 0.7355884474766211),\n",
       " ('128', 0.7354841971641592),\n",
       " ('88', 0.7353299754261898),\n",
       " ('6093', 0.7352733565419554),\n",
       " ('6289', 0.7352733565419554),\n",
       " ('57', 0.734669194342495),\n",
       " ('855', 0.7344532535932549),\n",
       " ('91', 0.7343632346597163),\n",
       " ('1064', 0.7340249008597552),\n",
       " ('5385', 0.7340247900241096),\n",
       " ('1660', 0.7340120423642011),\n",
       " ('963', 0.7339712457303208),\n",
       " ('267', 0.7339146369078844),\n",
       " ('207', 0.7337617781037906),\n",
       " ('1093', 0.733390611440194),\n",
       " ('3754', 0.7333708268997653),\n",
       " ('1137', 0.733008196353537),\n",
       " ('379', 0.7329348599851981),\n",
       " ('1416', 0.7328032086666968),\n",
       " ('1766', 0.7328011261006891),\n",
       " ('5609', 0.7326637873231032),\n",
       " ('2793', 0.7326611018196112),\n",
       " ('988', 0.7323374044769396),\n",
       " ('1029', 0.7323374044769396),\n",
       " ('875', 0.7320780237258935),\n",
       " ('71', 0.7319757263230723),\n",
       " ('322', 0.7319397412943898),\n",
       " ('696', 0.7318807367738408),\n",
       " ('874', 0.7318234575141458),\n",
       " ('3795', 0.7317314612482748),\n",
       " ('1140', 0.7316985040111098),\n",
       " ('679', 0.731507437535246),\n",
       " ('1524', 0.7314680263039239),\n",
       " ('5579', 0.7310908797934855),\n",
       " ('344', 0.7310108997047023),\n",
       " ('1153', 0.7306443498816048),\n",
       " ('753', 0.7305790005141866),\n",
       " ('1399', 0.7305708517137647),\n",
       " ('1856', 0.7298637699227765),\n",
       " ('76', 0.7295291351818087),\n",
       " ('605', 0.729520448167897),\n",
       " ('1374', 0.7292846451876881),\n",
       " ('1294', 0.7289200847897683),\n",
       " ('1240', 0.7287628461804398),\n",
       " ('65', 0.7285572096295498),\n",
       " ('1827', 0.7285398687109123),\n",
       " ('1109', 0.727723146469794),\n",
       " ('544', 0.7269114177725825),\n",
       " ('5589', 0.7269071774566029),\n",
       " ('1080', 0.7268783658967692),\n",
       " ('14', 0.7267238193376773),\n",
       " ('1532', 0.7265463855772358),\n",
       " ('316', 0.7265262636602134),\n",
       " ('237', 0.7264437990525047),\n",
       " ('1412', 0.7263788621045857),\n",
       " ('485', 0.7263712999944322),\n",
       " ('1867', 0.7262721396530483),\n",
       " ('1678', 0.7261072628492974),\n",
       " ('455', 0.7260873964673983),\n",
       " ('92', 0.7260412115794559),\n",
       " ('53', 0.7259537895586444),\n",
       " ('607', 0.725735185094465),\n",
       " ('997', 0.7256459410447942),\n",
       " ('2040', 0.7254525180579777),\n",
       " ('1785', 0.7252081424876636),\n",
       " ('981', 0.7248011976847977),\n",
       " ('310', 0.7245976329848491),\n",
       " ('5212', 0.7244663529989773),\n",
       " ('5242', 0.7244317128572499),\n",
       " ('5860', 0.7241306175124126),\n",
       " ('1206', 0.723444469188068),\n",
       " ('1150', 0.7231238818789166),\n",
       " ('1119', 0.7229364136810769),\n",
       " ('1476', 0.7228632253132413),\n",
       " ('1293', 0.7226964168733937),\n",
       " ('2644', 0.722460241492508),\n",
       " ('1078', 0.7216416323417),\n",
       " ('890', 0.7216222198996736),\n",
       " ('1579', 0.7215846769910472),\n",
       " ('2038', 0.7215381100700935),\n",
       " ('991', 0.7212880056077025),\n",
       " ('842', 0.7212261820125738),\n",
       " ('332', 0.7212226568881711),\n",
       " ('5909', 0.7209865234969973),\n",
       " ('456', 0.7209799254725042),\n",
       " ('11', 0.720958111656302),\n",
       " ('102', 0.7209424628585928),\n",
       " ('1462', 0.7207705661683881),\n",
       " ('425', 0.7206898350728805),\n",
       " ('426', 0.7206898350728805),\n",
       " ('81', 0.7205163464983266),\n",
       " ('360', 0.7201950648472508),\n",
       " ('5794', 0.7198117195732507),\n",
       " ('19', 0.7197663616961995),\n",
       " ('85', 0.7196628917700271),\n",
       " ('5515', 0.7188567846325306),\n",
       " ('628', 0.718829303702619),\n",
       " ('38', 0.7187212180205009),\n",
       " ('1955', 0.7184970983476914),\n",
       " ('833', 0.7184621160839574),\n",
       " ('1258', 0.7183131993175771),\n",
       " ('5613', 0.7180431805273065),\n",
       " ('915', 0.7180379215713235),\n",
       " ('5363', 0.7179773140928918),\n",
       " ('1023', 0.7179376875771069),\n",
       " ('1107', 0.7178717451817971),\n",
       " ('777', 0.7175295430810986),\n",
       " ('1341', 0.7172950762189056),\n",
       " ('1128', 0.7170188323273916),\n",
       " ('172', 0.7170073010779157),\n",
       " ('430', 0.7169853238670133),\n",
       " ('5523', 0.7169377182330045),\n",
       " ('132', 0.7160843043735938),\n",
       " ('1688', 0.7159035378446788),\n",
       " ('72', 0.715875591795995),\n",
       " ('1096', 0.7156390439427568),\n",
       " ('1717', 0.7155613682922971),\n",
       " ('1158', 0.7153063427327038),\n",
       " ('521', 0.7150313658395642),\n",
       " ('1044', 0.7149554887322561),\n",
       " ('273', 0.7149198362171221),\n",
       " ('6183', 0.7148666903117766),\n",
       " ('135', 0.7148354513539387),\n",
       " ('5789', 0.7146835178906367),\n",
       " ('84', 0.7145150765454735),\n",
       " ('579', 0.7145017625543671),\n",
       " ('1398', 0.7142945473938391),\n",
       " ('1768', 0.7141538007083675),\n",
       " ('1013', 0.7140967607211508),\n",
       " ('1885', 0.7139584305134838),\n",
       " ('355', 0.7134970320436708),\n",
       " ('712', 0.7134214250563838),\n",
       " ('15', 0.7133070123906585),\n",
       " ('1461', 0.7132919708792147),\n",
       " ('1185', 0.7132919662260848),\n",
       " ('1393', 0.7132919662260848),\n",
       " ('862', 0.713151356244909),\n",
       " ('533', 0.7128920275144198),\n",
       " ('4087', 0.7127794350172273),\n",
       " ('1176', 0.7126303013697358),\n",
       " ('193', 0.7121729493124314),\n",
       " ('1824', 0.7120270302188564),\n",
       " ('1365', 0.7117906206968925),\n",
       " ('5204', 0.7113898284078511),\n",
       " ('720', 0.7113745710071154),\n",
       " ('5876', 0.7113159698364134),\n",
       " ('546', 0.7112722681582352),\n",
       " ('6347', 0.7112265026675317),\n",
       " ('300', 0.7111129479235266),\n",
       " ('109', 0.7108739631776234),\n",
       " ('68', 0.7108216553726796),\n",
       " ('5260', 0.7105596840996161),\n",
       " ('307', 0.7105300475055627),\n",
       " ('1590', 0.7104417572383905),\n",
       " ('1840', 0.7104228178277836),\n",
       " ('241', 0.7103537757217716),\n",
       " ('651', 0.7103087026269386),\n",
       " ('947', 0.7102975934333098),\n",
       " ('2061', 0.7102843252894814),\n",
       " ('900', 0.7100243347899281),\n",
       " ('4477', 0.7097850583610923),\n",
       " ('1229', 0.7096485383606106),\n",
       " ('303', 0.7095395171967905),\n",
       " ('5244', 0.709405737420039),\n",
       " ('5376', 0.7093944409030144),\n",
       " ('6046', 0.7091526988087631),\n",
       " ('7', 0.7090376355438454),\n",
       " ('333', 0.7090045512778196),\n",
       " ('5808', 0.7084066253274633),\n",
       " ('5241', 0.7084021679888456),\n",
       " ('1452', 0.7082638276758247),\n",
       " ('1616', 0.7082043681142418),\n",
       " ('1116', 0.7081695962821063),\n",
       " ('477', 0.7080104145970625),\n",
       " ('6038', 0.7079940707797676),\n",
       " ('361', 0.7078815634629805),\n",
       " ('6257', 0.707745506077515),\n",
       " ('2652', 0.7075709759730328),\n",
       " ('1310', 0.7072523473988268),\n",
       " ('957', 0.7072177062520366),\n",
       " ('1572', 0.7069821807337182),\n",
       " ('1536', 0.7067737960455589),\n",
       " ('1708', 0.7067320665004321),\n",
       " ('585', 0.7066873371686802),\n",
       " ('5658', 0.7065959370602758),\n",
       " ('12', 0.7065005834617933),\n",
       " ('347', 0.7063279069242058),\n",
       " ('1762', 0.7063235672359576),\n",
       " ('610', 0.7061016404796145),\n",
       " ('2041', 0.7058639996286167),\n",
       " ('245', 0.7058634311475113),\n",
       " ('1999', 0.7057423085477954),\n",
       " ('4329', 0.7056215687558791),\n",
       " ('6115', 0.7055265467169515),\n",
       " ('555', 0.7054396824211725),\n",
       " ('20', 0.7054384692387274),\n",
       " ('5302', 0.7054288980836858),\n",
       " ('1674', 0.7053917493710647),\n",
       " ('4', 0.7053813851804588),\n",
       " ('5461', 0.7052227214618922),\n",
       " ('627', 0.7050694352276511),\n",
       " ('164', 0.7047050747505232),\n",
       " ('6275', 0.7046146353344275),\n",
       " ('2065', 0.704491731185431),\n",
       " ('823', 0.7042559381526973),\n",
       " ('5273', 0.7042019742437481),\n",
       " ('1722', 0.7041991120637188),\n",
       " ('0', 0.704098193799922),\n",
       " ('459', 0.7038529036450433),\n",
       " ('6322', 0.7035813472372305),\n",
       " ('983', 0.7033389439592523),\n",
       " ('119', 0.7032140824195151),\n",
       " ('2056', 0.7029766439369647),\n",
       " ('323', 0.7029134348529974),\n",
       " ('596', 0.7025710806024839),\n",
       " ('440', 0.7024154057557531),\n",
       " ('1179', 0.7022690665003541),\n",
       " ('1167', 0.7022170068935728),\n",
       " ('600', 0.7019731157303976),\n",
       " ('2698', 0.7017765294676259),\n",
       " ('296', 0.7017513322286157),\n",
       " ('78', 0.7013821086978856),\n",
       " ('2042', 0.7011688404419805),\n",
       " ('706', 0.701075946187959),\n",
       " ('79', 0.7007118384599014),\n",
       " ('115', 0.7003942753469012),\n",
       " ('1095', 0.7002482081423677),\n",
       " ('849', 0.7002247415788783),\n",
       " ('299', 0.7002198429453801),\n",
       " ('5279', 0.7000539803079889),\n",
       " ('1314', 0.6998208137101359),\n",
       " ('1617', 0.6996123075565408),\n",
       " ('2064', 0.6993420145920225),\n",
       " ('162', 0.6993324749384091),\n",
       " ('2', 0.6990116211160851),\n",
       " ('583', 0.6988380786962516),\n",
       " ('1410', 0.698291495212087),\n",
       " ('2591', 0.6978639110977267),\n",
       " ('5497', 0.6977609398175388),\n",
       " ('5683', 0.6977605694079607),\n",
       " ('971', 0.6970901814228011),\n",
       " ('16', 0.6968606467674385),\n",
       " ('1182', 0.6968513920670293),\n",
       " ('223', 0.6967433769686937),\n",
       " ('141', 0.6964800917990206),\n",
       " ('854', 0.696280682667195),\n",
       " ('5', 0.695859852959333),\n",
       " ('762', 0.6957354615467564),\n",
       " ('5348', 0.6956409793069536),\n",
       " ('747', 0.6955745674456529),\n",
       " ('1729', 0.6955588191739888),\n",
       " ('1228', 0.6954389024075749),\n",
       " ('860', 0.6953676911454787),\n",
       " ('281', 0.6953620613233726),\n",
       " ('761', 0.6952842101927919),\n",
       " ('42', 0.6952758597443626),\n",
       " ('2082', 0.6952438243290705),\n",
       " ('1053', 0.6951123258857316),\n",
       " ('870', 0.6949932483067035),\n",
       " ('74', 0.6949475376845087),\n",
       " ('1920', 0.6947246673135065),\n",
       " ('94', 0.6939204194312162),\n",
       " ('2059', 0.693774843668933),\n",
       " ('5610', 0.693760404353405),\n",
       " ('667', 0.6937176260361095),\n",
       " ('913', 0.693645359960831),\n",
       " ('622', 0.6935798078121467),\n",
       " ('2034', 0.6932441939771092),\n",
       " ('487', 0.6929499843252448),\n",
       " ('2967', 0.6928368776685541),\n",
       " ('412', 0.6926009727590102),\n",
       " ('413', 0.6926009727590102),\n",
       " ('2046', 0.6925480919827385),\n",
       " ('291', 0.6923688076049836),\n",
       " ('377', 0.6921454825460782),\n",
       " ('202', 0.692143574907037),\n",
       " ('336', 0.6920537545311368),\n",
       " ('1967', 0.6920134791892405),\n",
       " ('2948', 0.6919820962418505),\n",
       " ('2653', 0.6918092006713528),\n",
       " ('1735', 0.6915353411279598),\n",
       " ('2893', 0.6909404320268742),\n",
       " ('434', 0.6908946999172826),\n",
       " ('6224', 0.6907682665897447),\n",
       " ('381', 0.6906484879118034),\n",
       " ('1829', 0.6905874439867343),\n",
       " ('568', 0.6902687474970901),\n",
       " ('1351', 0.6897850848749225),\n",
       " ('2028', 0.6897212506583673),\n",
       " ('2033', 0.6896115956670552),\n",
       " ('757', 0.6896052032594812),\n",
       " ('2044', 0.6895537199522901),\n",
       " ('5529', 0.6893920354872418),\n",
       " ('2052', 0.6892337888567887),\n",
       " ('1906', 0.689004144762168),\n",
       " ('1122', 0.688990675622914),\n",
       " ('236', 0.6889600850273219),\n",
       " ('698', 0.6889460720993009),\n",
       " ('5350', 0.6886651916478532),\n",
       " ('850', 0.6880931041134692),\n",
       " ('816', 0.6880930941160918),\n",
       " ('293', 0.687877225824932),\n",
       " ('569', 0.68760734514305),\n",
       " ('878', 0.687400024206901),\n",
       " ('1912', 0.6872062971561917),\n",
       " ('103', 0.6870106296698537),\n",
       " ('527', 0.6865561548380467),\n",
       " ('1600', 0.6864490022581524),\n",
       " ('137', 0.6862403155290208),\n",
       " ('1963', 0.6861867155829745),\n",
       " ('1067', 0.6861650673402379),\n",
       " ('1487', 0.6860738806224199),\n",
       " ('134', 0.6858835432977891),\n",
       " ('743', 0.6857432893315355),\n",
       " ('1537', 0.6855373889491229),\n",
       " ('5210', 0.6854225189569907),\n",
       " ('1183', 0.685310989772438),\n",
       " ('1456', 0.6852550295017282),\n",
       " ('89', 0.6850705333073374),\n",
       " ('36', 0.6848116048642758),\n",
       " ('2145', 0.684663268299405),\n",
       " ('1362', 0.684224919150452),\n",
       " ('5457', 0.6841511539517335),\n",
       " ('1598', 0.684054788867593),\n",
       " ('586', 0.6840100134790719),\n",
       " ('1507', 0.6839611143570041),\n",
       " ('22', 0.6838890536204596),\n",
       " ('1975', 0.6838213028364448),\n",
       " ('5544', 0.6837416497494806),\n",
       " ('2073', 0.6836233957405048),\n",
       " ('1203', 0.6836120273115769),\n",
       " ('18', 0.683397825858383),\n",
       " ('1171', 0.6832644859123267),\n",
       " ('1520', 0.6831867480458227),\n",
       " ('13', 0.6831668876285427),\n",
       " ('1918', 0.682989465886048),\n",
       " ('1011', 0.6829773471921619),\n",
       " ('1175', 0.6825758253710439),\n",
       " ('603', 0.6824953648792635),\n",
       " ('1435', 0.6824583793367697),\n",
       " ('848', 0.6822150026661795),\n",
       " ('5283', 0.6821070940093586),\n",
       " ('1846', 0.6820272647301884),\n",
       " ('262', 0.681975692061406),\n",
       " ('1704', 0.6818685074116625),\n",
       " ('5537', 0.6817643334439498),\n",
       " ('865', 0.6815480491108574),\n",
       " ('309', 0.681269886622641),\n",
       " ('427', 0.6810357881844532),\n",
       " ('1916', 0.6807128225361733),\n",
       " ('5592', 0.6803299804419866),\n",
       " ('1160', 0.6801516465251818),\n",
       " ('376', 0.6800805145411656),\n",
       " ...]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_category(\"pheme_categories.json\", \"/Sensitive Subjects/War & Conflict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
